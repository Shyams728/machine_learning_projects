{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyams728/machine_learning_projects/blob/main/kannada_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHujqUzWb_Lr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "d0cb4f55-2a22-4353-b62c-34f1f0dff6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22772dfb-dc93-4f01-ad7e-3fef84240210\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22772dfb-dc93-4f01-ad7e-3fef84240210\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading kannada-mnist.zip to /content\n",
            " 48% 10.0M/20.8M [00:00<00:00, 28.3MB/s]\n",
            "100% 20.8M/20.8M [00:00<00:00, 53.2MB/s]\n",
            "Archive:  /content/kannada-mnist.zip\n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Dig_MNIST/X_dig_MNIST-idx3-ubyte/  (         \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Dig_MNIST/y_dig_MNIST-idx1-ubyte/y_dig_MNIST-idx1-ubyte  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_test-idx3-ubyte/  '        \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_test-idx3-ubyte/qтХЮ  cтХа┬а                    тХЮ   U┬а                    ├Ц┬▒тХЮ   U┬а                    ┬м┬╗  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_train-idx3-ubyte/  ╬й`        \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/X_kannada_MNIST_train-idx3-ubyte/тЦА                      -┬атХе   ┬а                     ┬атХЮ    ┬а                    F  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/y_kannada_MNIST_test-idx1-ubyte/y_kannada_MNIST_test-idx1-ubyte  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_Ubyte_gz/Kannada_MNIST/y_kannada_MNIST_train-idx1-ubyte/y_kannada_MNIST_train-idx1-ubyte  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Dig_MNIST/X_dig_MNIST.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Dig_MNIST/y_dig_MNIST.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz  \n",
            "  inflating: /content/Kannada_MNIST_datataset_paper/kannada_mnist_arxiv_submission.pdf  \n"
          ]
        }
      ],
      "source": [
        "# Install Kaggle library\n",
        "!pip install kaggle\n",
        "\n",
        "# Upload your Kaggle API key (kaggle.json) to Colab\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Move the API key to the appropriate directory\n",
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d higgstachyon/kannada-mnist -p /content\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip /content/kannada-mnist.zip -d /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHPgi1_ZQ0KV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f-gb7M3Q9nn"
      },
      "source": [
        "\n",
        "**Problem Statement:**\n",
        "You are given a dataset of Kannada digits, and the goal is to classify these digits into one of ten classes. Kannada is a language spoken in southwestern India, and the dataset contains handwritten Kannada digits.\n",
        "\n",
        "**Dataset:**\n",
        "- The dataset consists of 60,000 images for training and 10,000 images for testing.\n",
        "- Each image is in grayscale and has a size of 28x28 pixels.\n",
        "\n",
        "**Project Procedure:**\n",
        "\n",
        "1. **Data Loading:**\n",
        "   - Extract the dataset from the NPZ file, which contains the training and testing images along with their labels.\n",
        "\n",
        "2. **PCA Dimensionality Reduction:**\n",
        "   - Perform Principal Component Analysis (PCA) to reduce the dimensionality of the data from 28x28 (784 features) to 10 components.\n",
        "   - This step is intended to reduce computational complexity while retaining as much useful information as possible.\n",
        "\n",
        "3. **Model Selection:**\n",
        "   - Implement and train the following machine learning models:\n",
        "     - Decision Trees\n",
        "     - Random Forest\n",
        "     - Naive Bayes Model\n",
        "     - K-Nearest Neighbors (K-NN) Classifier\n",
        "     - Support Vector Machine (SVM)\n",
        "\n",
        "4. **Model Evaluation:**\n",
        "   - For each of the models, evaluate their performance using the following metrics:\n",
        "     - Precision: Measures the ratio of true positives to the total predicted positives.\n",
        "     - Recall: Measures the ratio of true positives to the total actual positives.\n",
        "     - F1-Score: Combines precision and recall into a single metric.\n",
        "     - Confusion Matrix: A table that shows the true positives, true negatives, false positives, and false negatives.\n",
        "     - ROC-AUC Curve: Receiver Operating Characteristic curve and Area Under the Curve (AUC) to assess the model's classification performance.\n",
        "\n",
        "5. **Experiment with Different Component Sizes:**\n",
        "   - Repeat the entire experiment with different PCA component sizes (e.g., 15, 20, 25, 30) to observe how the choice of components affects model performance.\n",
        "   - This step helps you understand how the trade-off between dimensionality reduction and model performance varies.\n",
        "\n",
        "Overall, the project involves preprocessing the Kannada MNIST dataset, reducing its dimensionality with PCA, training various machine learning models, and evaluating their performance using standard classification metrics. By experimenting with different component sizes, you can gain insights into how the dimensionality reduction affects the models' abilities to classify Kannada digits accurately."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix,roc_auc_score,roc_curve,auc\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function to load data from NPZ files\n",
        "def load_data(file_path):\n",
        "    data = np.load(file_path)\n",
        "    return data['arr_0']\n",
        "\n",
        "# Load training and testing data\n",
        "train_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz')\n",
        "test_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz')\n",
        "\n",
        "# Load labels\n",
        "y_train = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz')\n",
        "y_test = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz')\n",
        "\n",
        "# Flatten the image data\n",
        "def flatten_data(data):\n",
        "    return data.reshape(data.shape[0], -1)\n",
        "\n",
        "# Initialize PCA with the desired number of components\n",
        "def apply_pca(data, n_components):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    return pca.fit_transform(data)\n",
        "\n",
        "# Train a classifier and return evaluation metrics\n",
        "def train_and_evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate ROC-AUC score\n",
        "    y_prob = classifier.predict_proba(X_test)\n",
        "\n",
        "    # Define the class names based on your dataset\n",
        "    class_names = np.unique(y_train)\n",
        "    # Check the shape of y_prob\n",
        "    if y_prob.ndim == 1:\n",
        "    # If it's a 1D array, reshape it to a 2D array\n",
        "      y_prob = y_prob.reshape(-1, 1)\n",
        "\n",
        "    # Calculate ROC-AUC and prepare data for ROC curve plotting\n",
        "    n_classes = len(np.unique(y_test))\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Prepare ROC curve data\n",
        "    roc_auc_data = {\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'roc_auc': roc_auc,\n",
        "        'class_names': class_names,\n",
        "        'n_classes': n_classes\n",
        "    }\n",
        "\n",
        "\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "    return precision, recall, f1, confusion_matrix_result, roc_auc, roc_auc_data\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a list of classifiers to experiment with\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(random_state=42, criterion='entropy'),\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    MultinomialNB(),\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(probability=True)\n",
        "]\n",
        "\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "# Experiment with different PCA component sizes\n",
        "component_sizes = [10, 15, 20, 25]\n",
        "\n",
        "for n_components in component_sizes:\n",
        "    X_train_pca = apply_pca(flatten_data(X_train), n_components)\n",
        "    X_test_pca = apply_pca(flatten_data(X_test), n_components)\n",
        "\n",
        "    results = []\n",
        "    for classifier in classifiers:\n",
        "        model_name = classifier.__class__.__name__\n",
        "\n",
        "        if model_name == 'MultinomialNB':\n",
        "            # Use the MultinomialNB classifier without PCA for this specific case\n",
        "            precision, recall, f1, confusion_matrix_result,roc_auc, roc_auc_data = train_and_evaluate_classifier(classifier, flatten_data(X_train), y_train, flatten_data(X_test), y_test)\n",
        "        else:\n",
        "            # For other classifiers, use PCA as before\n",
        "            precision, recall, f1, confusion_matrix_result, roc_auc, roc_auc_data = train_and_evaluate_classifier(classifier, X_train_pca, y_train, X_test_pca, y_test)\n",
        "\n",
        "\n",
        "        # precision, recall, f1, confusion_matrix_result = train_and_evaluate_classifier(classifier, X_train_pca, y_train, X_test_pca, y_test)\n",
        "        print(f\"{model_name} (PCA-{n_components}) - Precision: {precision}, Recall: {recall}, F1-Score: {f1},roc_auc: {roc_auc}\")\n",
        "        results.append([model_name, precision, recall, f1, roc_auc, roc_auc_data, confusion_matrix_result])\n",
        "\n",
        "    results_dict[f'PCA-{n_components}'] = pd.DataFrame(results, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'roc_auc', 'roc_auc_data', 'Confusion Matrix'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUd6iZt_KFUO",
        "outputId": "8d9190f3-5291-47d2-b51f-6af18bb15e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier (PCA-10) - Precision: 0.8024370803121468, Recall: 0.8010833333333334, F1-Score: 0.7997721106443089,roc_auc: 0.8895329398310211\n",
            "RandomForestClassifier (PCA-10) - Precision: 0.9056743793288303, Recall: 0.9053333333333333, F1-Score: 0.9052263861102814,roc_auc: 0.9943956649729786\n",
            "MultinomialNB (PCA-10) - Precision: 0.9088156588820543, Recall: 0.9061666666666667, F1-Score: 0.9059850677491277,roc_auc: 0.9573476653990298\n",
            "KNeighborsClassifier (PCA-10) - Precision: 0.8881549542117659, Recall: 0.8871666666666667, F1-Score: 0.8872402586134548,roc_auc: 0.9685854498136646\n",
            "SVC (PCA-10) - Precision: 0.8883032149605326, Recall: 0.8859166666666667, F1-Score: 0.8865647140071691,roc_auc: 0.9915664574173962\n",
            "DecisionTreeClassifier (PCA-15) - Precision: 0.8192900780799323, Recall: 0.8189166666666666, F1-Score: 0.8172187269596508,roc_auc: 0.8994254692017989\n",
            "RandomForestClassifier (PCA-15) - Precision: 0.9352079472300946, Recall: 0.935, F1-Score: 0.9349634425565706,roc_auc: 0.9968024319781676\n",
            "MultinomialNB (PCA-15) - Precision: 0.9088156588820543, Recall: 0.9061666666666667, F1-Score: 0.9059850677491277,roc_auc: 0.9573476653990298\n",
            "KNeighborsClassifier (PCA-15) - Precision: 0.9289733085813385, Recall: 0.9288333333333333, F1-Score: 0.9287837969493932,roc_auc: 0.9813178108979491\n",
            "SVC (PCA-15) - Precision: 0.9138707410285452, Recall: 0.91275, F1-Score: 0.9131463911303838,roc_auc: 0.994529865301617\n",
            "DecisionTreeClassifier (PCA-20) - Precision: 0.8014414555544602, Recall: 0.8011666666666667, F1-Score: 0.799691535327935,roc_auc: 0.8895733437486812\n",
            "RandomForestClassifier (PCA-20) - Precision: 0.9283616215506956, Recall: 0.928, F1-Score: 0.928007811491635,roc_auc: 0.9962595071764617\n",
            "MultinomialNB (PCA-20) - Precision: 0.9088156588820543, Recall: 0.9061666666666667, F1-Score: 0.9059850677491277,roc_auc: 0.9573476653990298\n",
            "KNeighborsClassifier (PCA-20) - Precision: 0.8983213810711763, Recall: 0.897, F1-Score: 0.8969375425674762,roc_auc: 0.971383090503996\n",
            "SVC (PCA-20) - Precision: 0.8820455293052254, Recall: 0.8789166666666667, F1-Score: 0.8798722455638168,roc_auc: 0.9899303715279019\n",
            "DecisionTreeClassifier (PCA-25) - Precision: 0.7891825537333307, Recall: 0.7890833333333334, F1-Score: 0.7877258159719192,roc_auc: 0.8828586453417493\n",
            "RandomForestClassifier (PCA-25) - Precision: 0.9231371908746564, Recall: 0.9225833333333333, F1-Score: 0.9225688745626497,roc_auc: 0.9954274914493082\n",
            "MultinomialNB (PCA-25) - Precision: 0.9088156588820543, Recall: 0.9061666666666667, F1-Score: 0.9059850677491277,roc_auc: 0.9573476653990298\n",
            "KNeighborsClassifier (PCA-25) - Precision: 0.8770440727754188, Recall: 0.8745833333333334, F1-Score: 0.8746670671651113,roc_auc: 0.9643246584618487\n",
            "SVC (PCA-25) - Precision: 0.8670251332597088, Recall: 0.863, F1-Score: 0.8640426308683743,roc_auc: 0.9878752736084351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict['PCA-10']['Confusion Matrix'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxADN83Bycz-",
        "outputId": "c2223945-e714-4e06-a5e4-4a9c66625486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_data = results_dict['PCA-10']['roc_auc_data']\n",
        "plot_roc_curves(roc_auc_data)"
      ],
      "metadata": {
        "id": "sX98p4gQR5uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2UsPRv0R5m_",
        "outputId": "11fa3da1-afe5-46a3-e606-fd984e006ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    {'fpr': {0: [0.0, 0.03187655917952509, 1.0], 1...\n",
            "1    {'fpr': {0: [0.0, 9.239582370876836e-05, 9.239...\n",
            "2    {'fpr': {0: [0.0, 0.008038436662662848, 0.0080...\n",
            "3    {'fpr': {0: [0.0, 0.002125103945301672, 0.0050...\n",
            "4    {'fpr': {0: [0.0, 0.0, 0.0, 9.239582370876836e...\n",
            "Name: roc_auc_data, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_roc_curves(roc_auc_data):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown']\n",
        "    for i in range(roc_auc_data['n_classes']):\n",
        "        plt.plot(\n",
        "            roc_auc_data['fpr'][i],\n",
        "            roc_auc_data['tpr'][i],\n",
        "            color=colors[i],\n",
        "            lw=2,\n",
        "            label=f'Class {i} (AUC = {roc_auc_data[\"roc_auc\"][i]:.2f})'\n",
        "        )\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# conf_matrix = results_dict['PCA-10']['Confusion Matrix']\n",
        "# plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# plt.xticks(np.arange(len(class_names)), class_names, rotation=45)\n",
        "# plt.yticks(np.arange(len(class_names)), class_names)\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('True')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "CnzVJlphxTOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        ")\n",
        "\n",
        "def train_and_evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict using the classifier\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate ROC-AUC score\n",
        "    y_prob = classifier.predict_proba(X_test)\n",
        "\n",
        "    # Check the shape of y_prob\n",
        "    if y_prob.ndim == 1:\n",
        "        # If it's a 1D array, reshape it to a 2D array\n",
        "        y_prob = y_prob.reshape(-1, 1)\n",
        "\n",
        "    # Calculate ROC-AUC and prepare data for ROC curve plotting\n",
        "    n_classes = len(np.unique(y_test))\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_prob[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Prepare ROC curve data\n",
        "    roc_auc_data = {\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'roc_auc': roc_auc,\n",
        "        'class_names': np.unique(y_train),\n",
        "        'n_classes': n_classes\n",
        "    }\n",
        "\n",
        "    # Calculate other evaluation metrics\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "    return precision, recall, f1, confusion_matrix_result, roc_auc, roc_auc_data\n"
      ],
      "metadata": {
        "id": "Rw1UXQHywI3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function to load data from NPZ files\n",
        "def load_data(file_path):\n",
        "    data = np.load(file_path)\n",
        "    return data['arr_0']\n",
        "\n",
        "# ... (rest of your code for loading data, PCA, and training classifiers)\n",
        "\n",
        "# Now, let's visualize ROC curves and confusion matrices\n",
        "def plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown']\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Define the class names based on your dataset\n",
        "class_names = np.unique(y_train)\n",
        "\n",
        "# Assuming you want to visualize results for 'PCA-10', you can select it like this:\n",
        "n_classes = 10\n",
        "data = results_dict['PCA-10']['roc_auc_data']\n",
        "fpr, tpr, roc_auc = [], [], []\n",
        "\n",
        "for roc_data in data:\n",
        "    fpr_class, tpr_class, roc_auc_class = roc_data\n",
        "    fpr.append(fpr_class)\n",
        "    tpr.append(tpr_class)\n",
        "    roc_auc.append(roc_auc_class)\n",
        "\n",
        "# Now, you can plot ROC curves and confusion matrix\n",
        "plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes)\n",
        "\n",
        "conf_matrix = results_dict['PCA-10']['Confusion Matrix']\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xticks(np.arange(len(class_names)), class_names, rotation=45)\n",
        "plt.yticks(np.arange(len(class_names)), class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "CSeNU2L3oo4W",
        "outputId": "30116b82-400d-4418-d727-7929f4b2393a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-691102447361>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Now, you can plot ROC curves and confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mplot_roc_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PCA-10'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Confusion Matrix'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-691102447361>\u001b[0m in \u001b[0;36mplot_roc_curves\u001b[0;34m(fpr, tpr, roc_auc, class_names, n_classes)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'darkorange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'purple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'brown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Class {i} (AUC = {roc_auc[i]:.2f})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to dict.__format__"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict['PCA-10'].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlZvbAdvnTcg",
        "outputId": "4e34f5fb-c8ca-417f-9de4-6d8282bf5522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Model', 'Precision', 'Recall', 'F1-Score', 'roc_auc', 'roc_auc_data',\n",
              "       'Confusion Matrix'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "15, 20, 25"
      ],
      "metadata": {
        "id": "R4I7zJ98rwR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "for data in results_dict['PCA-10']['roc_auc_data']:\n",
        "  fpr, tpr, roc_auc, class_names, n_classes = data\n",
        "  pprint(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnmM8akceVO2",
        "outputId": "76c38992-d849-48d0-9690-84be9bb9dbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{0: array([0.        , 0.03446364, 1.        ]),\n",
            "  1: array([0.        , 0.01381933, 1.        ]),\n",
            "  2: array([0.        , 0.01800297, 1.        ]),\n",
            "  3: array([0.        , 0.02292899, 1.        ]),\n",
            "  4: array([0.        , 0.01465813, 1.        ]),\n",
            "  5: array([0.        , 0.01563078, 1.        ]),\n",
            "  6: array([0.        , 0.03129905, 1.        ]),\n",
            "  7: array([0.        , 0.02652815, 1.        ]),\n",
            "  8: array([0.        , 0.01969669, 1.        ]),\n",
            "  9: array([0.        , 0.01474133, 1.        ])},\n",
            " {0: array([0.        , 0.81478335, 1.        ]),\n",
            "  1: array([0.        , 0.79064039, 1.        ]),\n",
            "  2: array([0.        , 0.85784314, 1.        ]),\n",
            "  3: array([0.        , 0.56672297, 1.        ]),\n",
            "  4: array([0.        , 0.84684685, 1.        ]),\n",
            "  5: array([0.        , 0.91919192, 1.        ]),\n",
            "  6: array([0.        , 0.82463644, 1.        ]),\n",
            "  7: array([0.        , 0.78506973, 1.        ]),\n",
            "  8: array([0.        , 0.89123103, 1.        ]),\n",
            "  9: array([0.        , 0.79489292, 1.        ])},\n",
            " {0: 0.8901598526251286,\n",
            "  1: 0.8884105327890948,\n",
            "  2: 0.9199200838464562,\n",
            "  3: 0.7718969894450665,\n",
            "  4: 0.9160943576473775,\n",
            "  5: 0.9517805692888933,\n",
            "  6: 0.8966686961884822,\n",
            "  7: 0.8792707889544384,\n",
            "  8: 0.9357671695955933,\n",
            "  9: 0.890075792312385},\n",
            " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            " 10]\n",
            "[{0: array([0.00000000e+00, 9.23958237e-05, 9.23958237e-05, 9.23958237e-05,\n",
            "       9.23958237e-05, 9.23958237e-05, 9.23958237e-05, 9.23958237e-05,\n",
            "       9.23958237e-05, 9.23958237e-05, 9.23958237e-05, 9.23958237e-05,\n",
            "       9.23958237e-05, 1.84791647e-04, 1.84791647e-04, 1.84791647e-04,\n",
            "       1.84791647e-04, 1.84791647e-04, 2.77187471e-04, 3.69583295e-04,\n",
            "       3.69583295e-04, 3.69583295e-04, 3.69583295e-04, 3.69583295e-04,\n",
            "       4.61979119e-04, 4.61979119e-04, 5.54374942e-04, 5.54374942e-04,\n",
            "       6.46770766e-04, 6.46770766e-04, 8.31562413e-04, 9.23958237e-04,\n",
            "       9.23958237e-04, 1.10874988e-03, 1.10874988e-03, 1.20114571e-03,\n",
            "       1.47833318e-03, 1.66312483e-03, 1.84791647e-03, 1.84791647e-03,\n",
            "       1.94031230e-03, 2.21749977e-03, 2.40229142e-03, 2.49468724e-03,\n",
            "       3.04906218e-03, 3.14145801e-03, 3.51104130e-03, 3.69583295e-03,\n",
            "       3.88062460e-03, 4.25020789e-03, 4.61979119e-03, 4.89697866e-03,\n",
            "       5.54374942e-03, 5.72854107e-03, 5.91333272e-03, 6.37531184e-03,\n",
            "       6.74489513e-03, 7.48406172e-03, 7.94604084e-03, 8.31562413e-03,\n",
            "       9.14718655e-03, 9.88635314e-03, 1.05331239e-02, 1.12722905e-02,\n",
            "       1.19190613e-02, 1.27506237e-02, 1.34897903e-02, 1.45061443e-02,\n",
            "       1.62616650e-02, 1.70932274e-02, 1.79247898e-02, 1.96803104e-02,\n",
            "       2.18054144e-02, 2.39305183e-02, 2.59632265e-02, 2.78111429e-02,\n",
            "       3.03058302e-02, 3.24309341e-02, 3.50180172e-02, 3.76974961e-02,\n",
            "       4.10237457e-02, 4.44423912e-02, 4.75838492e-02, 5.29428070e-02,\n",
            "       5.75625982e-02, 6.28291601e-02, 6.75413471e-02, 7.42862423e-02,\n",
            "       8.00147833e-02, 8.81456158e-02, 9.61840525e-02, 1.05793218e-01,\n",
            "       1.16603530e-01, 1.27875820e-01, 1.40164465e-01, 1.55409775e-01,\n",
            "       1.74443315e-01, 1.97449875e-01, 2.32098309e-01, 2.82176846e-01,\n",
            "       3.90464751e-01, 1.00000000e+00]),\n",
            "  1: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 9.27471712e-05, 9.27471712e-05, 9.27471712e-05,\n",
            "       9.27471712e-05, 9.27471712e-05, 2.78241514e-04, 2.78241514e-04,\n",
            "       2.78241514e-04, 2.78241514e-04, 2.78241514e-04, 2.78241514e-04,\n",
            "       2.78241514e-04, 2.78241514e-04, 3.70988685e-04, 3.70988685e-04,\n",
            "       3.70988685e-04, 3.70988685e-04, 3.70988685e-04, 5.56483027e-04,\n",
            "       5.56483027e-04, 7.41977370e-04, 1.02021888e-03, 1.02021888e-03,\n",
            "       1.20571323e-03, 1.29846040e-03, 1.29846040e-03, 1.48395474e-03,\n",
            "       1.66944908e-03, 1.94769060e-03, 2.22593211e-03, 2.22593211e-03,\n",
            "       2.59692079e-03, 2.87516231e-03, 3.06065665e-03, 3.24615099e-03,\n",
            "       3.33889816e-03, 3.61713968e-03, 3.61713968e-03, 3.70988685e-03,\n",
            "       3.89538119e-03, 4.08087553e-03, 4.45186422e-03, 4.45186422e-03,\n",
            "       4.63735856e-03, 4.73010573e-03, 5.10109442e-03, 5.47208310e-03,\n",
            "       5.65757744e-03, 6.12131330e-03, 6.49230198e-03, 7.14153218e-03,\n",
            "       7.23427935e-03, 7.32702653e-03, 7.60526804e-03, 7.69801521e-03,\n",
            "       7.88350955e-03, 8.53273975e-03, 8.99647561e-03, 9.18196995e-03,\n",
            "       9.55295863e-03, 1.01094417e-02, 1.08514190e-02, 1.16861436e-02,\n",
            "       1.27063625e-02, 1.27991096e-02, 1.36338342e-02, 1.46540531e-02,\n",
            "       1.57670191e-02, 1.71582267e-02, 1.80856984e-02, 1.99406418e-02,\n",
            "       2.18883324e-02, 2.44852532e-02, 2.69894268e-02, 3.03283250e-02,\n",
            "       3.35744760e-02, 3.74698572e-02, 4.31274346e-02, 4.86922649e-02,\n",
            "       5.43498423e-02, 6.23260991e-02, 7.11370803e-02, 8.28232239e-02,\n",
            "       9.76627713e-02, 1.16861436e-01, 1.41810425e-01, 1.74921165e-01,\n",
            "       2.26581339e-01, 3.30736413e-01, 1.00000000e+00]),\n",
            "  2: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 9.27988122e-05, 9.27988122e-05, 9.27988122e-05,\n",
            "       9.27988122e-05, 9.27988122e-05, 9.27988122e-05, 9.27988122e-05,\n",
            "       1.85597624e-04, 1.85597624e-04, 1.85597624e-04, 2.78396437e-04,\n",
            "       2.78396437e-04, 3.71195249e-04, 3.71195249e-04, 3.71195249e-04,\n",
            "       3.71195249e-04, 3.71195249e-04, 4.63994061e-04, 7.42390497e-04,\n",
            "       7.42390497e-04, 8.35189310e-04, 8.35189310e-04, 9.27988122e-04,\n",
            "       1.02078693e-03, 1.20638456e-03, 1.29918337e-03, 1.39198218e-03,\n",
            "       1.48478099e-03, 1.67037862e-03, 1.85597624e-03, 1.94877506e-03,\n",
            "       2.22717149e-03, 2.22717149e-03, 2.41276912e-03, 2.87676318e-03,\n",
            "       2.87676318e-03, 3.24795843e-03, 3.34075724e-03, 3.71195249e-03,\n",
            "       4.17594655e-03, 4.45434298e-03, 4.73273942e-03, 5.01113586e-03,\n",
            "       5.56792873e-03, 6.12472160e-03, 6.77431329e-03, 7.05270973e-03,\n",
            "       7.79510022e-03, 7.98069785e-03, 8.25909428e-03, 8.81588716e-03,\n",
            "       9.65107647e-03, 1.03006682e-02, 1.10430586e-02, 1.21566444e-02,\n",
            "       1.28990349e-02, 1.39198218e-02, 1.45694135e-02, 1.54046028e-02,\n",
            "       1.68893838e-02, 1.86525612e-02, 1.95805494e-02, 2.08797327e-02,\n",
            "       2.17149220e-02, 2.31997030e-02, 2.48700817e-02, 2.66332591e-02,\n",
            "       2.99740163e-02, 3.22011878e-02, 3.50779510e-02, 3.88827023e-02,\n",
            "       4.33370453e-02, 4.69561990e-02, 5.28025241e-02, 5.98552339e-02,\n",
            "       6.71863400e-02, 7.64662212e-02, 8.79732739e-02, 1.05512249e-01,\n",
            "       1.30289532e-01, 1.86061618e-01, 3.06514477e-01, 1.00000000e+00]),\n",
            "  3: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 9.24556213e-05, 1.84911243e-04,\n",
            "       1.84911243e-04, 1.84911243e-04, 2.77366864e-04, 2.77366864e-04,\n",
            "       2.77366864e-04, 6.47189349e-04, 7.39644970e-04, 9.24556213e-04,\n",
            "       1.01701183e-03, 1.01701183e-03, 1.29437870e-03, 1.29437870e-03,\n",
            "       1.38683432e-03, 1.57174556e-03, 1.57174556e-03, 1.66420118e-03,\n",
            "       1.75665680e-03, 1.94156805e-03, 1.94156805e-03, 2.12647929e-03,\n",
            "       2.12647929e-03, 2.12647929e-03, 2.21893491e-03, 2.49630178e-03,\n",
            "       2.49630178e-03, 2.68121302e-03, 2.95857988e-03, 2.95857988e-03,\n",
            "       3.23594675e-03, 3.42085799e-03, 3.60576923e-03, 3.60576923e-03,\n",
            "       3.97559172e-03, 4.53032544e-03, 4.71523669e-03, 4.99260355e-03,\n",
            "       5.36242604e-03, 6.10207101e-03, 6.28698225e-03, 7.02662722e-03,\n",
            "       7.30399408e-03, 7.67381657e-03, 8.04363905e-03, 8.59837278e-03,\n",
            "       8.87573964e-03, 9.33801775e-03, 9.80029586e-03, 1.07248521e-02,\n",
            "       1.14644970e-02, 1.17418639e-02, 1.25739645e-02, 1.26664201e-02,\n",
            "       1.30362426e-02, 1.36834320e-02, 1.38683432e-02, 1.47928994e-02,\n",
            "       1.55325444e-02, 1.63646450e-02, 1.71042899e-02, 1.75665680e-02,\n",
            "       1.86760355e-02, 1.94156805e-02, 2.04326923e-02, 2.22818047e-02,\n",
            "       2.37610947e-02, 2.51479290e-02, 2.60724852e-02, 2.71819527e-02,\n",
            "       2.85687870e-02, 3.00480769e-02, 3.18971893e-02, 3.42085799e-02,\n",
            "       3.66124260e-02, 3.91087278e-02, 4.18823964e-02, 4.50258876e-02,\n",
            "       4.77071006e-02, 4.99260355e-02, 5.39016272e-02, 5.84319527e-02,\n",
            "       6.37019231e-02, 6.88794379e-02, 7.42418639e-02, 8.15458580e-02,\n",
            "       9.00517751e-02, 9.82803254e-02, 1.08820266e-01, 1.23058432e-01,\n",
            "       1.40717456e-01, 1.64663462e-01, 2.01645710e-01, 2.62296598e-01,\n",
            "       3.81379438e-01, 1.00000000e+00]),\n",
            "  4: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 9.27729845e-05, 9.27729845e-05, 9.27729845e-05,\n",
            "       9.27729845e-05, 9.27729845e-05, 9.27729845e-05, 9.27729845e-05,\n",
            "       9.27729845e-05, 1.85545969e-04, 3.71091938e-04, 4.63864923e-04,\n",
            "       5.56637907e-04, 5.56637907e-04, 6.49410892e-04, 7.42183876e-04,\n",
            "       7.42183876e-04, 8.34956861e-04, 8.34956861e-04, 1.02050283e-03,\n",
            "       1.29882178e-03, 1.39159477e-03, 1.39159477e-03, 1.57714074e-03,\n",
            "       1.57714074e-03, 1.94823267e-03, 1.94823267e-03, 1.94823267e-03,\n",
            "       2.69041655e-03, 2.69041655e-03, 3.06150849e-03, 3.33982744e-03,\n",
            "       3.80369236e-03, 3.89646535e-03, 4.08201132e-03, 4.45310326e-03,\n",
            "       4.82419519e-03, 5.19528713e-03, 5.19528713e-03, 5.56637907e-03,\n",
            "       6.03024399e-03, 6.40133593e-03, 7.23629279e-03, 7.42183876e-03,\n",
            "       7.79293070e-03, 8.53511457e-03, 9.64839039e-03, 1.02978013e-02,\n",
            "       1.11327581e-02, 1.18749420e-02, 1.29882178e-02, 1.39159477e-02,\n",
            "       1.51219965e-02, 1.62352723e-02, 1.80907320e-02, 2.02245106e-02,\n",
            "       2.14305594e-02, 2.40282030e-02, 2.67186195e-02, 2.91307171e-02,\n",
            "       3.38621393e-02, 3.81296966e-02, 4.37888487e-02, 4.98190927e-02,\n",
            "       5.65915205e-02, 6.69820948e-02, 7.59810743e-02, 8.93403841e-02,\n",
            "       1.08451619e-01, 1.37767882e-01, 1.83968828e-01, 2.84070879e-01,\n",
            "       1.00000000e+00]),\n",
            "  5: array([0.00000000e+00, 0.00000000e+00, 9.24898261e-05, 9.24898261e-05,\n",
            "       1.84979652e-04, 1.84979652e-04, 1.84979652e-04, 1.84979652e-04,\n",
            "       1.84979652e-04, 1.84979652e-04, 1.84979652e-04, 1.84979652e-04,\n",
            "       1.84979652e-04, 2.77469478e-04, 2.77469478e-04, 2.77469478e-04,\n",
            "       3.69959304e-04, 3.69959304e-04, 3.69959304e-04, 3.69959304e-04,\n",
            "       6.47428783e-04, 7.39918609e-04, 7.39918609e-04, 7.39918609e-04,\n",
            "       8.32408435e-04, 8.32408435e-04, 1.01738809e-03, 1.01738809e-03,\n",
            "       1.10987791e-03, 1.10987791e-03, 1.10987791e-03, 1.10987791e-03,\n",
            "       1.20236774e-03, 1.29485757e-03, 1.29485757e-03, 1.38734739e-03,\n",
            "       1.57232704e-03, 1.66481687e-03, 1.75730670e-03, 1.75730670e-03,\n",
            "       1.84979652e-03, 1.84979652e-03, 1.94228635e-03, 2.03477617e-03,\n",
            "       2.03477617e-03, 2.49722531e-03, 2.68220496e-03, 2.86718461e-03,\n",
            "       3.05216426e-03, 3.14465409e-03, 3.14465409e-03, 3.14465409e-03,\n",
            "       3.32963374e-03, 3.79208287e-03, 4.06955235e-03, 4.16204218e-03,\n",
            "       4.71698113e-03, 4.90196078e-03, 5.36440991e-03, 5.64187939e-03,\n",
            "       6.10432852e-03, 6.19681835e-03, 6.56677765e-03, 7.58416574e-03,\n",
            "       7.67665557e-03, 8.23159452e-03, 8.78653348e-03, 9.61894192e-03,\n",
            "       1.07288198e-02, 1.11912690e-02, 1.17462079e-02, 1.23011469e-02,\n",
            "       1.32260451e-02, 1.47058824e-02, 1.60007399e-02, 1.74805771e-02,\n",
            "       1.84979652e-02, 2.00702923e-02, 2.14576397e-02, 2.32149464e-02,\n",
            "       2.54347022e-02, 2.86718461e-02, 3.18165002e-02, 3.40362560e-02,\n",
            "       3.76433592e-02, 4.19903811e-02, 4.81871994e-02, 5.29966704e-02,\n",
            "       6.03033666e-02, 6.98298187e-02, 8.30558639e-02, 9.81317055e-02,\n",
            "       1.16814650e-01, 1.42249353e-01, 1.81280059e-01, 2.42693304e-01,\n",
            "       3.70236774e-01, 1.00000000e+00]),\n",
            "  6: array([0.00000000e+00, 9.23275782e-05, 9.23275782e-05, 1.84655156e-04,\n",
            "       2.76982735e-04, 4.61637891e-04, 4.61637891e-04, 4.61637891e-04,\n",
            "       5.53965469e-04, 8.30948204e-04, 8.30948204e-04, 9.23275782e-04,\n",
            "       1.20025852e-03, 1.56956883e-03, 1.56956883e-03, 1.66189641e-03,\n",
            "       1.84655156e-03, 2.12353430e-03, 2.21586188e-03, 2.30818946e-03,\n",
            "       2.40051703e-03, 2.49284461e-03, 2.76982735e-03, 2.86215493e-03,\n",
            "       2.95448250e-03, 3.13913766e-03, 3.32379282e-03, 3.41612040e-03,\n",
            "       3.69310313e-03, 3.78543071e-03, 3.97008586e-03, 4.06241344e-03,\n",
            "       4.15474102e-03, 4.70870649e-03, 5.44732712e-03, 5.72430985e-03,\n",
            "       6.09362016e-03, 6.64758563e-03, 7.29387868e-03, 7.66318899e-03,\n",
            "       7.75551657e-03, 7.94017173e-03, 8.21715446e-03, 8.77111993e-03,\n",
            "       9.32508540e-03, 1.02483612e-02, 1.06176715e-02, 1.07099991e-02,\n",
            "       1.10793094e-02, 1.17256024e-02, 1.25565506e-02, 1.32951713e-02,\n",
            "       1.37568092e-02, 1.39414643e-02, 1.47724125e-02, 1.53263780e-02,\n",
            "       1.56033607e-02, 1.62496538e-02, 1.70806020e-02, 1.82808605e-02,\n",
            "       1.92041363e-02, 1.96657742e-02, 2.05890499e-02, 2.16046533e-02,\n",
            "       2.23432739e-02, 2.31742221e-02, 2.40051703e-02, 2.53900840e-02,\n",
            "       2.64980150e-02, 2.76059459e-02, 3.00987905e-02, 3.10220663e-02,\n",
            "       3.24993075e-02, 3.33302557e-02, 3.53614625e-02, 3.79466347e-02,\n",
            "       3.97008586e-02, 4.20090481e-02, 4.35786169e-02, 4.59791340e-02,\n",
            "       4.81949958e-02, 5.03185301e-02, 5.34576678e-02, 5.60428400e-02,\n",
            "       5.87203398e-02, 6.15824947e-02, 6.41676669e-02, 6.76761149e-02,\n",
            "       7.29387868e-02, 7.80168036e-02, 8.39257686e-02, 8.96500785e-02,\n",
            "       9.79595605e-02, 1.06730680e-01, 1.15501800e-01, 1.31566799e-01,\n",
            "       1.52894470e-01, 1.82346967e-01, 2.36266273e-01, 3.55091866e-01,\n",
            "       1.00000000e+00]),\n",
            "  7: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 9.27557740e-05, 1.85511548e-04,\n",
            "       1.85511548e-04, 2.78267322e-04, 2.78267322e-04, 3.71023096e-04,\n",
            "       4.63778870e-04, 4.63778870e-04, 4.63778870e-04, 5.56534644e-04,\n",
            "       6.49290418e-04, 8.34801966e-04, 9.27557740e-04, 9.27557740e-04,\n",
            "       9.27557740e-04, 1.02031351e-03, 1.11306929e-03, 1.20582506e-03,\n",
            "       1.39133661e-03, 1.76235971e-03, 1.85511548e-03, 2.13338280e-03,\n",
            "       2.41165013e-03, 2.59716167e-03, 2.78267322e-03, 2.96818477e-03,\n",
            "       3.06094054e-03, 3.06094054e-03, 3.43196364e-03, 3.52471941e-03,\n",
            "       3.89574251e-03, 4.17400983e-03, 4.35952138e-03, 4.73054448e-03,\n",
            "       4.91605602e-03, 5.47259067e-03, 5.84361376e-03, 6.21463686e-03,\n",
            "       6.86392728e-03, 7.14219460e-03, 7.42046192e-03, 7.79148502e-03,\n",
            "       8.44077544e-03, 8.99731008e-03, 9.27557740e-03, 9.73935627e-03,\n",
            "       1.02031351e-02, 1.07596698e-02, 1.14089602e-02, 1.17799833e-02,\n",
            "       1.24292737e-02, 1.30785641e-02, 1.36350988e-02, 1.41916334e-02,\n",
            "       1.50264354e-02, 1.57684816e-02, 1.68815509e-02, 1.71598182e-02,\n",
            "       1.79018644e-02, 1.90149337e-02, 2.04990261e-02, 2.11483165e-02,\n",
            "       2.25396531e-02, 2.39309897e-02, 2.54150821e-02, 2.68064187e-02,\n",
            "       2.83832669e-02, 3.01456266e-02, 3.24645209e-02, 3.42268806e-02,\n",
            "       3.71023096e-02, 3.86791578e-02, 4.18328541e-02, 4.51720620e-02,\n",
            "       4.84185141e-02, 5.19432335e-02, 5.56534644e-02, 5.89926723e-02,\n",
            "       6.39087283e-02, 6.87320286e-02, 7.55959558e-02, 8.40367313e-02,\n",
            "       9.28485298e-02, 1.02587886e-01, 1.12976533e-01, 1.27539189e-01,\n",
            "       1.41730823e-01, 1.57128281e-01, 1.74566367e-01, 1.98868380e-01,\n",
            "       2.34950376e-01, 2.91345886e-01, 4.11186346e-01, 1.00000000e+00]),\n",
            "  8: array([0.00000000e+00, 9.24727205e-05, 9.24727205e-05, 1.84945441e-04,\n",
            "       1.84945441e-04, 1.84945441e-04, 1.84945441e-04, 1.84945441e-04,\n",
            "       1.84945441e-04, 1.84945441e-04, 1.84945441e-04, 2.77418162e-04,\n",
            "       2.77418162e-04, 2.77418162e-04, 3.69890882e-04, 3.69890882e-04,\n",
            "       3.69890882e-04, 3.69890882e-04, 3.69890882e-04, 4.62363603e-04,\n",
            "       6.47309044e-04, 6.47309044e-04, 6.47309044e-04, 7.39781764e-04,\n",
            "       8.32254485e-04, 8.32254485e-04, 9.24727205e-04, 9.24727205e-04,\n",
            "       9.24727205e-04, 9.24727205e-04, 1.10967265e-03, 1.20214537e-03,\n",
            "       1.20214537e-03, 1.20214537e-03, 1.29461809e-03, 1.29461809e-03,\n",
            "       1.47956353e-03, 1.57203625e-03, 1.84945441e-03, 1.94192713e-03,\n",
            "       1.94192713e-03, 2.03439985e-03, 2.21934529e-03, 2.31181801e-03,\n",
            "       2.40429073e-03, 2.40429073e-03, 2.49676345e-03, 2.77418162e-03,\n",
            "       2.95912706e-03, 3.42149066e-03, 3.42149066e-03, 3.69890882e-03,\n",
            "       3.79138154e-03, 3.79138154e-03, 3.88385426e-03, 3.97632698e-03,\n",
            "       4.06879970e-03, 4.16127242e-03, 4.71610875e-03, 5.08599963e-03,\n",
            "       5.36341779e-03, 5.64083595e-03, 6.01072684e-03, 6.56556316e-03,\n",
            "       6.93545404e-03, 7.49029036e-03, 7.86018125e-03, 8.41501757e-03,\n",
            "       9.15479933e-03, 9.80210838e-03, 1.02644720e-02, 1.13741446e-02,\n",
            "       1.21139264e-02, 1.35934899e-02, 1.49805807e-02, 1.65526170e-02,\n",
            "       1.84020714e-02, 2.19160348e-02, 2.37654892e-02, 2.55224709e-02,\n",
            "       2.83891252e-02, 3.25503976e-02, 3.48622156e-02, 3.80062881e-02,\n",
            "       4.15202515e-02, 4.60514148e-02, 5.14148326e-02, 5.88126503e-02,\n",
            "       6.53782134e-02, 7.47179582e-02, 8.37802848e-02, 9.29350842e-02,\n",
            "       1.05233956e-01, 1.22433882e-01, 1.40188644e-01, 1.64324024e-01,\n",
            "       2.01960422e-01, 2.64841872e-01, 3.90234881e-01, 1.00000000e+00]),\n",
            "  9: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
            "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27127758e-05,\n",
            "       9.27127758e-05, 1.85425552e-04, 1.85425552e-04, 2.78138327e-04,\n",
            "       2.78138327e-04, 2.78138327e-04, 2.78138327e-04, 2.78138327e-04,\n",
            "       2.78138327e-04, 2.78138327e-04, 3.70851103e-04, 4.63563879e-04,\n",
            "       4.63563879e-04, 5.56276655e-04, 5.56276655e-04, 5.56276655e-04,\n",
            "       5.56276655e-04, 6.48989431e-04, 7.41702207e-04, 7.41702207e-04,\n",
            "       7.41702207e-04, 7.41702207e-04, 7.41702207e-04, 7.41702207e-04,\n",
            "       7.41702207e-04, 1.11255331e-03, 1.11255331e-03, 1.11255331e-03,\n",
            "       1.39069164e-03, 1.48340441e-03, 1.57611719e-03, 1.57611719e-03,\n",
            "       1.57611719e-03, 1.57611719e-03, 1.57611719e-03, 1.57611719e-03,\n",
            "       1.57611719e-03, 1.66882996e-03, 1.76154274e-03, 1.85425552e-03,\n",
            "       1.85425552e-03, 1.85425552e-03, 1.94696829e-03, 2.13239384e-03,\n",
            "       2.13239384e-03, 2.31781940e-03, 2.50324495e-03, 2.68867050e-03,\n",
            "       2.78138327e-03, 3.52308548e-03, 3.80122381e-03, 3.98664936e-03,\n",
            "       4.26478769e-03, 4.54292602e-03, 4.63563879e-03, 4.72835157e-03,\n",
            "       5.00648989e-03, 5.47005377e-03, 5.84090488e-03, 6.02633043e-03,\n",
            "       6.67531986e-03, 7.04617096e-03, 7.69516039e-03, 8.43686260e-03,\n",
            "       9.73484146e-03, 1.03838309e-02, 1.13109587e-02, 1.27016503e-02,\n",
            "       1.39069164e-02, 1.50194697e-02, 1.71518635e-02, 1.90061190e-02,\n",
            "       2.11385129e-02, 2.38271834e-02, 2.67939922e-02, 2.98535138e-02,\n",
            "       3.38401632e-02, 3.80122381e-02, 4.57073985e-02, 5.18264417e-02,\n",
            "       6.13758576e-02, 7.21305396e-02, 8.38123493e-02, 9.72557018e-02,\n",
            "       1.14871129e-01, 1.37400334e-01, 1.67810124e-01, 2.15928055e-01,\n",
            "       2.84720935e-01, 4.39922121e-01, 1.00000000e+00])},\n",
            " {0: array([0.        , 0.08581138, 0.13508921, 0.18861512, 0.23109601,\n",
            "       0.26508071, 0.2982158 , 0.32795242, 0.35514019, 0.38317757,\n",
            "       0.41291419, 0.42990654, 0.44859813, 0.46559048, 0.48003398,\n",
            "       0.49787596, 0.51826678, 0.5335599 , 0.55140187, 0.56584537,\n",
            "       0.57519116, 0.58623619, 0.60662702, 0.63041631, 0.64231096,\n",
            "       0.65080714, 0.66270178, 0.68224299, 0.69498726, 0.70858114,\n",
            "       0.72217502, 0.72982158, 0.7357689 , 0.74681393, 0.75446049,\n",
            "       0.75700935, 0.7646559 , 0.76890399, 0.7740017 , 0.77994902,\n",
            "       0.7884452 , 0.79694138, 0.80458794, 0.81138488, 0.81818182,\n",
            "       0.82497876, 0.83007647, 0.83432455, 0.84197111, 0.84876805,\n",
            "       0.85726423, 0.86236194, 0.86576041, 0.86830926, 0.8751062 ,\n",
            "       0.87850467, 0.884452  , 0.88785047, 0.89039932, 0.89209856,\n",
            "       0.89719626, 0.90314359, 0.90654206, 0.90994053, 0.91163976,\n",
            "       0.91503823, 0.9184367 , 0.92183517, 0.92438403, 0.92863212,\n",
            "       0.93203059, 0.93797791, 0.93967715, 0.94307562, 0.94477485,\n",
            "       0.9473237 , 0.95157179, 0.95751912, 0.96091759, 0.96261682,\n",
            "       0.96346644, 0.96516568, 0.96686491, 0.96941376, 0.97366185,\n",
            "       0.97621071, 0.97790994, 0.98130841, 0.98130841, 0.98300765,\n",
            "       0.98300765, 0.98980459, 0.98980459, 0.99150382, 0.99320306,\n",
            "       0.99405268, 0.99490229, 0.99660153, 0.99830076, 0.99830076,\n",
            "       0.99915038, 1.        ]),\n",
            "  1: array([0.        , 0.04269294, 0.1182266 , 0.15517241, 0.18472906,\n",
            "       0.21100164, 0.23234811, 0.25041051, 0.27504105, 0.29720854,\n",
            "       0.31444992, 0.33497537, 0.34811166, 0.35714286, 0.38095238,\n",
            "       0.3998358 , 0.42446634, 0.44417077, 0.45812808, 0.47701149,\n",
            "       0.49425287, 0.52052545, 0.5500821 , 0.56321839, 0.57799672,\n",
            "       0.59852217, 0.61330049, 0.64614122, 0.67323481, 0.68965517,\n",
            "       0.71264368, 0.727422  , 0.74137931, 0.74876847, 0.76518883,\n",
            "       0.78243021, 0.79638752, 0.80788177, 0.81527094, 0.83004926,\n",
            "       0.84154351, 0.8546798 , 0.86453202, 0.86945813, 0.87931034,\n",
            "       0.89901478, 0.90229885, 0.90558292, 0.90804598, 0.91625616,\n",
            "       0.92364532, 0.92692939, 0.93431856, 0.93842365, 0.9408867 ,\n",
            "       0.94745484, 0.9499179 , 0.95155993, 0.95402299, 0.95566502,\n",
            "       0.95812808, 0.96059113, 0.96305419, 0.96469622, 0.96633826,\n",
            "       0.9679803 , 0.97372742, 0.97619048, 0.97865353, 0.97865353,\n",
            "       0.97865353, 0.98029557, 0.98111658, 0.9819376 , 0.98357964,\n",
            "       0.98522167, 0.98768473, 0.98850575, 0.99014778, 0.99014778,\n",
            "       0.99343186, 0.99425287, 0.99507389, 0.99507389, 0.99589491,\n",
            "       0.99589491, 0.99671593, 0.99671593, 0.99753695, 0.99917898,\n",
            "       0.99917898, 1.        , 1.        , 1.        , 1.        ]),\n",
            "  2: array([0.        , 0.37173203, 0.49754902, 0.55392157, 0.57924837,\n",
            "       0.59558824, 0.6127451 , 0.62663399, 0.63970588, 0.65441176,\n",
            "       0.66503268, 0.67156863, 0.68137255, 0.69362745, 0.69852941,\n",
            "       0.70833333, 0.71813725, 0.72712418, 0.73202614, 0.74101307,\n",
            "       0.74754902, 0.75      , 0.75735294, 0.76143791, 0.76715686,\n",
            "       0.78022876, 0.78513072, 0.78921569, 0.79656863, 0.80065359,\n",
            "       0.80147059, 0.80637255, 0.80800654, 0.81535948, 0.82271242,\n",
            "       0.82352941, 0.83333333, 0.83578431, 0.84150327, 0.84640523,\n",
            "       0.84885621, 0.85212418, 0.85702614, 0.85866013, 0.8619281 ,\n",
            "       0.86846405, 0.87336601, 0.87581699, 0.87826797, 0.87908497,\n",
            "       0.88153595, 0.88316993, 0.88643791, 0.89133987, 0.89379085,\n",
            "       0.89705882, 0.90114379, 0.90114379, 0.90359477, 0.90686275,\n",
            "       0.90767974, 0.90931373, 0.91339869, 0.91584967, 0.91830065,\n",
            "       0.91993464, 0.92728758, 0.92728758, 0.93137255, 0.93137255,\n",
            "       0.93464052, 0.93627451, 0.93872549, 0.94035948, 0.94199346,\n",
            "       0.94526144, 0.94934641, 0.95506536, 0.95915033, 0.96405229,\n",
            "       0.96650327, 0.96732026, 0.97058824, 0.97222222, 0.97712418,\n",
            "       0.97794118, 0.97957516, 0.98202614, 0.98529412, 0.98856209,\n",
            "       0.99101307, 0.99346405, 0.99509804, 0.99591503, 0.99591503,\n",
            "       0.99673203, 1.        , 1.        , 1.        , 1.        ]),\n",
            "  3: array([0.        , 0.0464527 , 0.09628378, 0.13175676, 0.15540541,\n",
            "       0.17820946, 0.19932432, 0.21199324, 0.22381757, 0.23902027,\n",
            "       0.25591216, 0.26266892, 0.27364865, 0.28378378, 0.29138514,\n",
            "       0.30067568, 0.30574324, 0.31418919, 0.32010135, 0.33192568,\n",
            "       0.34037162, 0.34628378, 0.35388514, 0.3589527 , 0.36739865,\n",
            "       0.375     , 0.38513514, 0.38851351, 0.40033784, 0.41300676,\n",
            "       0.41807432, 0.4222973 , 0.42905405, 0.43327703, 0.44003378,\n",
            "       0.44425676, 0.44932432, 0.45608108, 0.46114865, 0.46706081,\n",
            "       0.47043919, 0.47719595, 0.4839527 , 0.48986486, 0.49662162,\n",
            "       0.50168919, 0.50760135, 0.51689189, 0.52702703, 0.53547297,\n",
            "       0.54138514, 0.54898649, 0.56081081, 0.56841216, 0.57516892,\n",
            "       0.58361486, 0.59121622, 0.59797297, 0.60557432, 0.61739865,\n",
            "       0.62753378, 0.64527027, 0.65540541, 0.6714527 , 0.69003378,\n",
            "       0.69679054, 0.71283784, 0.72381757, 0.73817568, 0.75337838,\n",
            "       0.76266892, 0.78462838, 0.80067568, 0.81165541, 0.8277027 ,\n",
            "       0.84206081, 0.85304054, 0.86739865, 0.88513514, 0.89273649,\n",
            "       0.90962838, 0.92314189, 0.93412162, 0.94256757, 0.95185811,\n",
            "       0.95861486, 0.96199324, 0.96790541, 0.97719595, 0.98057432,\n",
            "       0.98141892, 0.98226351, 0.9839527 , 0.98817568, 0.98902027,\n",
            "       0.98986486, 0.99493243, 0.99493243, 0.99577703, 0.99746622,\n",
            "       0.99915541, 1.        ]),\n",
            "  4: array([0.        , 0.1957412 , 0.27436527, 0.32268632, 0.35544636,\n",
            "       0.39475839, 0.42506143, 0.44963145, 0.47502048, 0.49467649,\n",
            "       0.50941851, 0.52252252, 0.54054054, 0.55773956, 0.57575758,\n",
            "       0.58968059, 0.6044226 , 0.62080262, 0.63636364, 0.64946765,\n",
            "       0.66666667, 0.67649468, 0.68796069, 0.7018837 , 0.71007371,\n",
            "       0.71908272, 0.72727273, 0.73628174, 0.74938575, 0.76003276,\n",
            "       0.77067977, 0.77805078, 0.78378378, 0.79197379, 0.7952498 ,\n",
            "       0.8018018 , 0.80589681, 0.81408681, 0.82063882, 0.82719083,\n",
            "       0.83783784, 0.84193284, 0.84438984, 0.84602785, 0.85094185,\n",
            "       0.85667486, 0.86076986, 0.86486486, 0.86650287, 0.87141687,\n",
            "       0.87387387, 0.87878788, 0.87960688, 0.88452088, 0.89107289,\n",
            "       0.8951679 , 0.9033579 , 0.90909091, 0.91072891, 0.91646192,\n",
            "       0.91646192, 0.92055692, 0.92301392, 0.93038493, 0.93284193,\n",
            "       0.93366093, 0.93775594, 0.93939394, 0.94348894, 0.94758395,\n",
            "       0.94840295, 0.95085995, 0.95331695, 0.95495495, 0.95741196,\n",
            "       0.95986896, 0.95986896, 0.96560197, 0.96560197, 0.96887797,\n",
            "       0.96969697, 0.97133497, 0.97461097, 0.97706798, 0.97952498,\n",
            "       0.98198198, 0.98280098, 0.98443898, 0.98771499, 0.98771499,\n",
            "       0.98935299, 0.99017199, 0.99180999, 0.99262899, 0.99262899,\n",
            "       0.99426699, 0.995086  , 0.997543  , 0.999181  , 1.        ,\n",
            "       1.        ]),\n",
            "  5: array([0.        , 0.27272727, 0.36531987, 0.43097643, 0.47895623,\n",
            "       0.52693603, 0.56565657, 0.59680135, 0.61868687, 0.64983165,\n",
            "       0.66919192, 0.68686869, 0.69781145, 0.71380471, 0.72727273,\n",
            "       0.73821549, 0.75      , 0.76346801, 0.76936027, 0.78030303,\n",
            "       0.79040404, 0.8013468 , 0.82154882, 0.82407407, 0.83838384,\n",
            "       0.8459596 , 0.85016835, 0.85606061, 0.86363636, 0.86447811,\n",
            "       0.87121212, 0.87457912, 0.87962963, 0.88383838, 0.88973064,\n",
            "       0.89309764, 0.89478114, 0.89646465, 0.8989899 , 0.9023569 ,\n",
            "       0.90824916, 0.91582492, 0.92003367, 0.92255892, 0.92424242,\n",
            "       0.92592593, 0.92845118, 0.93350168, 0.93602694, 0.93939394,\n",
            "       0.94107744, 0.94444444, 0.9452862 , 0.94612795, 0.9469697 ,\n",
            "       0.94949495, 0.95117845, 0.9537037 , 0.95791246, 0.95875421,\n",
            "       0.96043771, 0.96296296, 0.96548822, 0.96885522, 0.96969697,\n",
            "       0.97053872, 0.97306397, 0.97474747, 0.97643098, 0.97811448,\n",
            "       0.97895623, 0.98148148, 0.98316498, 0.98653199, 0.98737374,\n",
            "       0.98737374, 0.98905724, 0.99074074, 0.99074074, 0.99242424,\n",
            "       0.99326599, 0.99410774, 0.99410774, 0.99410774, 0.99494949,\n",
            "       0.99579125, 0.99579125, 0.99579125, 0.99579125, 0.99747475,\n",
            "       0.99747475, 0.9983165 , 0.9983165 , 0.99915825, 0.99915825,\n",
            "       1.        , 1.        , 1.        ]),\n",
            "  6: array([0.        , 0.03934987, 0.09153122, 0.14285714, 0.18477331,\n",
            "       0.23438837, 0.28314799, 0.31993157, 0.34816082, 0.37467921,\n",
            "       0.4011976 , 0.42857143, 0.45423439, 0.47989735, 0.50042772,\n",
            "       0.52437981, 0.54491018, 0.56116339, 0.56971771, 0.58254919,\n",
            "       0.59281437, 0.60136869, 0.61591104, 0.62532079, 0.63216424,\n",
            "       0.64242943, 0.65355004, 0.66552609, 0.67408041, 0.68434559,\n",
            "       0.69289991, 0.69888794, 0.70402053, 0.71941831, 0.72540633,\n",
            "       0.73396065, 0.73994867, 0.7459367 , 0.75278015, 0.75449102,\n",
            "       0.76304534, 0.76903336, 0.77587682, 0.78015398, 0.78699743,\n",
            "       0.79298546, 0.80068435, 0.8075278 , 0.81522669, 0.82207015,\n",
            "       0.82463644, 0.8314799 , 0.83661249, 0.84260051, 0.84773311,\n",
            "       0.8528657 , 0.85970915, 0.86398631, 0.86826347, 0.87254063,\n",
            "       0.87938409, 0.88195038, 0.88879384, 0.8956373 , 0.90333618,\n",
            "       0.91017964, 0.91274594, 0.91873396, 0.92130026, 0.92215569,\n",
            "       0.92814371, 0.93156544, 0.93242087, 0.93413174, 0.9384089 ,\n",
            "       0.94525235, 0.94781865, 0.95124038, 0.95380667, 0.95893926,\n",
            "       0.96065013, 0.96407186, 0.96834902, 0.96920445, 0.97005988,\n",
            "       0.97177074, 0.97433704, 0.97690334, 0.9786142 , 0.98203593,\n",
            "       0.98545766, 0.98631309, 0.98802395, 0.98973482, 0.99315654,\n",
            "       0.99486741, 0.99657827, 0.9974337 , 0.99828914, 0.99914457,\n",
            "       1.        ]),\n",
            "  7: array([0.        , 0.08531583, 0.17145201, 0.22723544, 0.27235439,\n",
            "       0.30516817, 0.33470057, 0.35684988, 0.39294504, 0.41263331,\n",
            "       0.43970468, 0.45693191, 0.47662018, 0.48728466, 0.50779327,\n",
            "       0.51845775, 0.53240361, 0.54634947, 0.56111567, 0.56931911,\n",
            "       0.58326497, 0.59064807, 0.59639048, 0.60459393, 0.61525841,\n",
            "       0.6242822 , 0.63740771, 0.64397047, 0.6538146 , 0.66201805,\n",
            "       0.66694011, 0.67104184, 0.68088597, 0.68744873, 0.69483183,\n",
            "       0.70467596, 0.71698113, 0.7219032 , 0.72682527, 0.73338802,\n",
            "       0.74159147, 0.74323216, 0.74651354, 0.75307629, 0.76374077,\n",
            "       0.77112387, 0.78096801, 0.79081214, 0.79491386, 0.79573421,\n",
            "       0.80393765, 0.80885972, 0.81788351, 0.82362592, 0.83182937,\n",
            "       0.84249385, 0.85069729, 0.85397867, 0.86300246, 0.86792453,\n",
            "       0.87120591, 0.87694832, 0.87940935, 0.8876128 , 0.89663659,\n",
            "       0.90073831, 0.90730107, 0.91058244, 0.91550451, 0.91878589,\n",
            "       0.92370796, 0.92780968, 0.93273175, 0.93601313, 0.94011485,\n",
            "       0.94421657, 0.9466776 , 0.95077933, 0.95406071, 0.95734208,\n",
            "       0.95898277, 0.96144381, 0.96390484, 0.96718622, 0.9704676 ,\n",
            "       0.97292863, 0.97538966, 0.98113208, 0.98277276, 0.98605414,\n",
            "       0.98769483, 0.99015587, 0.9926169 , 0.9926169 , 0.99343724,\n",
            "       0.99589828, 0.99671862, 0.99753897, 0.99835931, 1.        ]),\n",
            "  8: array([0.        , 0.25463744, 0.36340641, 0.43086003, 0.47217538,\n",
            "       0.50590219, 0.54384486, 0.58094435, 0.60202361, 0.62731872,\n",
            "       0.63996627, 0.65598651, 0.67369309, 0.68549747, 0.69645868,\n",
            "       0.70489039, 0.71669477, 0.72006745, 0.72934233, 0.73693086,\n",
            "       0.74536256, 0.74957841, 0.75801012, 0.76053963, 0.76391231,\n",
            "       0.77571669, 0.77993255, 0.79089376, 0.80016863, 0.80354132,\n",
            "       0.80438449, 0.81028668, 0.81703204, 0.82040472, 0.82630691,\n",
            "       0.83220911, 0.83305228, 0.83895447, 0.84401349, 0.84822934,\n",
            "       0.84991568, 0.85413153, 0.85750422, 0.85919056, 0.86256324,\n",
            "       0.8693086 , 0.87099494, 0.87605396, 0.88026981, 0.88448567,\n",
            "       0.88785835, 0.89038786, 0.89376054, 0.9005059 , 0.90387858,\n",
            "       0.90472175, 0.91146712, 0.91146712, 0.91315346, 0.91905565,\n",
            "       0.92242833, 0.92411467, 0.93001686, 0.93338954, 0.9376054 ,\n",
            "       0.93844857, 0.94182125, 0.94435076, 0.94772344, 0.95109612,\n",
            "       0.95278246, 0.95362563, 0.95531197, 0.95615514, 0.95784148,\n",
            "       0.95868465, 0.96037099, 0.96711636, 0.9688027 , 0.96964587,\n",
            "       0.97386172, 0.97554806, 0.97807757, 0.97976391, 0.98145025,\n",
            "       0.98313659, 0.9856661 , 0.98735245, 0.98819562, 0.98903879,\n",
            "       0.9915683 , 0.99409781, 0.99494098, 0.99662732, 0.99747049,\n",
            "       0.99747049, 0.99747049, 0.99831366, 1.        , 1.        ]),\n",
            "  9: array([0.        , 0.20016474, 0.2907743 , 0.35008237, 0.38714992,\n",
            "       0.42257002, 0.45716639, 0.47611203, 0.49341021, 0.51894563,\n",
            "       0.53789127, 0.55601318, 0.57166392, 0.59390445, 0.60708402,\n",
            "       0.62191104, 0.64085667, 0.65156507, 0.66392092, 0.67133443,\n",
            "       0.68369028, 0.69192751, 0.6985173 , 0.70757825, 0.71499176,\n",
            "       0.7199341 , 0.72899506, 0.73723229, 0.74052718, 0.7446458 ,\n",
            "       0.75041186, 0.75700165, 0.76112026, 0.77265239, 0.77594728,\n",
            "       0.77841845, 0.78336079, 0.78995058, 0.79159802, 0.79736409,\n",
            "       0.79983526, 0.80560132, 0.80889621, 0.81383855, 0.81960461,\n",
            "       0.82537068, 0.82784185, 0.83113674, 0.83855025, 0.84349259,\n",
            "       0.8476112 , 0.85749588, 0.8583196 , 0.86079077, 0.86738056,\n",
            "       0.86985173, 0.87397035, 0.87891269, 0.88138386, 0.88550247,\n",
            "       0.88714992, 0.89044481, 0.89456343, 0.89950577, 0.90197694,\n",
            "       0.90362438, 0.91186161, 0.91515651, 0.91762768, 0.92009885,\n",
            "       0.92339374, 0.9291598 , 0.93410214, 0.93410214, 0.94069193,\n",
            "       0.94233937, 0.94563427, 0.94728171, 0.94975288, 0.94975288,\n",
            "       0.95140033, 0.95222405, 0.95222405, 0.95304778, 0.95716639,\n",
            "       0.95881384, 0.96128501, 0.96293245, 0.9645799 , 0.97116969,\n",
            "       0.97281713, 0.9752883 , 0.9785832 , 0.98517298, 0.98682043,\n",
            "       0.98846787, 0.99423394, 0.99917628, 1.        ])},\n",
            " {0: 0.9938846838889238,\n",
            "  1: 0.9978322823510204,\n",
            "  2: 0.9974345374130845,\n",
            "  3: 0.9854627591256195,\n",
            "  4: 0.9978572935711816,\n",
            "  5: 0.9986835770455822,\n",
            "  6: 0.9910648386806588,\n",
            "  7: 0.9908773288528515,\n",
            "  8: 0.9966732042125144,\n",
            "  9: 0.9922584832189876},\n",
            " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            " 10]\n",
            "[{0: array([0.        , 0.00803844, 0.00803844, 0.00859281, 0.00859281,\n",
            "       0.00905479, 0.00905479, 0.00960917, 0.00960917, 0.00970156,\n",
            "       0.00970156, 0.01025594, 0.01025594, 0.01071792, 0.01071792,\n",
            "       0.01182667, 0.01182667, 0.01219625, 0.01219625, 0.01256583,\n",
            "       1.        ]),\n",
            "  1: array([0.        , 0.00389538, 0.00389538, 0.00398813, 0.00398813,\n",
            "       0.00408088, 0.00408088, 0.00417362, 0.00417362, 0.00426637,\n",
            "       0.00426637, 0.00435912, 0.00435912, 1.        ]),\n",
            "  2: array([0.00000000e+00, 5.56792873e-04, 5.56792873e-04, 6.49591685e-04,\n",
            "       6.49591685e-04, 1.00000000e+00]),\n",
            "  3: array([0.        , 0.02579512, 0.02616494, 0.02616494, 0.02634985,\n",
            "       0.02634985, 0.02653476, 0.02653476, 0.02681213, 0.02681213,\n",
            "       0.02690459, 0.02690459, 0.02782914, 0.02782914, 0.0279216 ,\n",
            "       0.0279216 , 0.02829142, 0.02829142, 0.02856879, 0.02856879,\n",
            "       0.02995562, 0.02995562, 0.03014053, 0.03014053, 0.0304179 ,\n",
            "       0.0304179 , 0.03088018, 0.03088018, 0.0320821 , 0.0320821 ,\n",
            "       0.03226701, 0.03226701, 0.0329142 , 0.0329142 , 0.03309911,\n",
            "       0.03309911, 0.03383876, 0.03383876, 0.0345784 , 0.0345784 ,\n",
            "       0.03504068, 0.03504068, 0.03522559, 0.03522559, 0.03642751,\n",
            "       0.03642751, 0.03846154, 1.        ]),\n",
            "  4: array([0.        , 0.01604973, 0.01604973, 0.0161425 , 0.0161425 ,\n",
            "       0.01632805, 0.01632805, 0.01651359, 0.01651359, 0.01762687,\n",
            "       0.01762687, 0.01892569, 0.01892569, 0.01901846, 0.01901846,\n",
            "       0.01929678, 0.01929678, 0.01938955, 0.01938955, 0.02180165,\n",
            "       0.02180165, 0.02189442, 0.02189442, 0.02217274, 1.        ]),\n",
            "  5: array([0.        , 0.00665927, 0.00684425, 0.00684425, 0.00702923,\n",
            "       0.00702923, 0.00721421, 0.00721421, 0.00739919, 0.00739919,\n",
            "       0.00776915, 0.00776915, 0.00823159, 0.00823159, 0.00841657,\n",
            "       0.00841657, 0.00860155, 0.00860155, 0.00878653, 0.00878653,\n",
            "       0.00934147, 0.00934147, 0.00961894, 1.        ]),\n",
            "  6: array([0.        , 0.02003508, 0.02003508, 0.02049672, 0.02049672,\n",
            "       0.02077371, 0.02077371, 0.02095836, 0.02095836, 0.02151233,\n",
            "       0.02151233, 0.02188164, 0.02188164, 0.02206629, 0.02206629,\n",
            "       0.02215862, 0.02215862, 0.02225095, 0.02225095, 0.02262026,\n",
            "       0.02262026, 0.02280491, 0.02280491, 0.02298957, 0.02298957,\n",
            "       0.02308189, 0.02308189, 0.02326655, 1.        ]),\n",
            "  7: array([0.        , 0.01660328, 0.01669604, 0.01669604, 0.0167888 ,\n",
            "       0.0167888 , 0.01688155, 0.01688155, 0.01725257, 0.01725257,\n",
            "       0.01743809, 0.01743809, 0.01780911, 0.01780911, 0.01799462,\n",
            "       0.01799462, 0.01818013, 0.01818013, 0.0184584 , 0.0184584 ,\n",
            "       0.01855115, 0.01855115, 0.01864391, 0.01864391, 0.01892218,\n",
            "       0.01892218, 0.0192932 , 0.0192932 , 0.01966422, 0.01966422,\n",
            "       0.01975698, 0.01975698, 0.01984974, 0.01984974, 0.01994249,\n",
            "       0.01994249, 0.020128  , 0.020128  , 0.02022076, 0.02022076,\n",
            "       0.02031351, 0.02031351, 0.02049903, 0.02049903, 0.02059178,\n",
            "       0.02059178, 0.02077729, 0.02077729, 0.02087005, 0.02087005,\n",
            "       0.02133383, 0.02133383, 0.02151934, 0.02151934, 0.02170485,\n",
            "       0.02170485, 0.02179761, 0.02179761, 0.02198312, 0.02198312,\n",
            "       0.02235414, 0.02235414, 0.02272516, 0.02272516, 0.02281792,\n",
            "       0.02281792, 0.02291068, 0.02291068, 0.02300343, 0.02300343,\n",
            "       0.02337446, 0.02337446, 0.02346721, 0.02346721, 0.02355997,\n",
            "       0.02355997, 0.02374548, 0.02374548, 1.        ]),\n",
            "  8: array([0.        , 0.00342149, 0.00342149, 0.00360644, 0.00360644,\n",
            "       0.00369891, 0.00369891, 0.00379138, 0.00379138, 0.00388385,\n",
            "       0.00388385, 0.00397633, 0.00397633, 0.00416127, 0.00416127,\n",
            "       0.00425375, 0.00425375, 0.00434622, 0.00434622, 1.        ]),\n",
            "  9: array([0.        , 0.00213239, 0.00213239, 0.00222511, 0.00222511,\n",
            "       0.00231782, 0.00231782, 0.00250324, 0.00250324, 0.00259596,\n",
            "       0.00259596, 0.00278138, 0.00278138, 0.00296681, 0.00296681,\n",
            "       0.00315223, 0.00315223, 0.00324495, 1.        ])},\n",
            " {0: array([0.        , 0.92013594, 0.92098556, 0.92098556, 0.92268479,\n",
            "       0.92268479, 0.92438403, 0.92438403, 0.92608326, 0.92608326,\n",
            "       0.9277825 , 0.9277825 , 0.93033135, 0.93033135, 0.93118097,\n",
            "       0.93118097, 0.93203059, 0.93203059, 0.93372982, 0.93372982,\n",
            "       1.        ]),\n",
            "  1: array([0.        , 0.92118227, 0.92364532, 0.92364532, 0.92692939,\n",
            "       0.92692939, 0.93924466, 0.93924466, 0.94417077, 0.94417077,\n",
            "       0.94581281, 0.94581281, 0.94745484, 1.        ]),\n",
            "  2: array([0.        , 0.98120915, 0.98284314, 0.98284314, 0.98366013,\n",
            "       1.        ]),\n",
            "  3: array([0.        , 0.91131757, 0.91131757, 0.91300676, 0.91300676,\n",
            "       0.91385135, 0.91385135, 0.91554054, 0.91554054, 0.91722973,\n",
            "       0.91722973, 0.91891892, 0.91891892, 0.91976351, 0.91976351,\n",
            "       0.92060811, 0.92060811, 0.9214527 , 0.9214527 , 0.9222973 ,\n",
            "       0.9222973 , 0.92314189, 0.92314189, 0.92398649, 0.92398649,\n",
            "       0.92483108, 0.92483108, 0.92567568, 0.92567568, 0.92736486,\n",
            "       0.92736486, 0.92820946, 0.92820946, 0.92905405, 0.92905405,\n",
            "       0.92989865, 0.92989865, 0.93074324, 0.93074324, 0.93158784,\n",
            "       0.93158784, 0.93243243, 0.93243243, 0.93327703, 0.93327703,\n",
            "       0.93496622, 0.93496622, 1.        ]),\n",
            "  4: array([0.        , 0.96969697, 0.97051597, 0.97051597, 0.97133497,\n",
            "       0.97133497, 0.97215397, 0.97215397, 0.97297297, 0.97297297,\n",
            "       0.97379197, 0.97379197, 0.97542998, 0.97542998, 0.97624898,\n",
            "       0.97624898, 0.97706798, 0.97706798, 0.97788698, 0.97788698,\n",
            "       0.97870598, 0.97870598, 0.97952498, 0.97952498, 1.        ]),\n",
            "  5: array([0.        , 0.93265993, 0.93265993, 0.93434343, 0.93434343,\n",
            "       0.93771044, 0.93771044, 0.93939394, 0.93939394, 0.94023569,\n",
            "       0.94023569, 0.94191919, 0.94191919, 0.94276094, 0.94276094,\n",
            "       0.94612795, 0.94612795, 0.9486532 , 0.9486532 , 0.94949495,\n",
            "       0.94949495, 0.95117845, 0.95117845, 1.        ]),\n",
            "  6: array([0.        , 0.88109495, 0.88195038, 0.88195038, 0.88280582,\n",
            "       0.88280582, 0.88622754, 0.88622754, 0.88708298, 0.88708298,\n",
            "       0.88793841, 0.88793841, 0.88879384, 0.88879384, 0.89221557,\n",
            "       0.89221557, 0.89392643, 0.89392643, 0.89649273, 0.89649273,\n",
            "       0.89734816, 0.89734816, 0.89820359, 0.89820359, 0.89905902,\n",
            "       0.89905902, 0.90076989, 0.90076989, 1.        ]),\n",
            "  7: array([0.        , 0.70467596, 0.70467596, 0.70549631, 0.70549631,\n",
            "       0.70631665, 0.70631665, 0.707137  , 0.707137  , 0.71369975,\n",
            "       0.71369975, 0.7145201 , 0.7145201 , 0.71534044, 0.71534044,\n",
            "       0.71698113, 0.71698113, 0.71862182, 0.71862182, 0.7219032 ,\n",
            "       0.7219032 , 0.72272354, 0.72272354, 0.72354389, 0.72354389,\n",
            "       0.72518458, 0.72518458, 0.72600492, 0.72600492, 0.72764561,\n",
            "       0.72764561, 0.7292863 , 0.7292863 , 0.73010664, 0.73010664,\n",
            "       0.73092699, 0.73092699, 0.73256768, 0.73256768, 0.73338802,\n",
            "       0.73338802, 0.73420837, 0.73420837, 0.7366694 , 0.7366694 ,\n",
            "       0.73748975, 0.73748975, 0.73913043, 0.73913043, 0.74241181,\n",
            "       0.74241181, 0.74323216, 0.74323216, 0.7440525 , 0.7440525 ,\n",
            "       0.74569319, 0.74569319, 0.74651354, 0.74651354, 0.74733388,\n",
            "       0.74733388, 0.75061526, 0.75061526, 0.7514356 , 0.7514356 ,\n",
            "       0.75307629, 0.75307629, 0.75553733, 0.75553733, 0.75717801,\n",
            "       0.75717801, 0.7588187 , 0.7588187 , 0.75963905, 0.75963905,\n",
            "       0.76127974, 0.76127974, 0.76210008, 1.        ]),\n",
            "  8: array([0.        , 0.91062395, 0.91146712, 0.91146712, 0.91231029,\n",
            "       0.91231029, 0.91736931, 0.91736931, 0.91905565, 0.91905565,\n",
            "       0.92074199, 0.92074199, 0.92158516, 0.92158516, 0.92242833,\n",
            "       0.92242833, 0.92495784, 0.92495784, 0.9317032 , 1.        ]),\n",
            "  9: array([0.        , 0.92257002, 0.92339374, 0.92339374, 0.92421746,\n",
            "       0.92421746, 0.92504119, 0.92504119, 0.92586491, 0.92586491,\n",
            "       0.92833608, 0.92833608, 0.9291598 , 0.9291598 , 0.93080725,\n",
            "       0.93080725, 0.93163097, 0.93163097, 1.        ])},\n",
            " {0: 0.9626146636489786,\n",
            "  1: 0.971711046721121,\n",
            "  2: 0.9915501526024911,\n",
            "  3: 0.9537631702407845,\n",
            "  4: 0.9815720636761549,\n",
            "  5: 0.9721022501497898,\n",
            "  6: 0.9399748322445813,\n",
            "  7: 0.8712153038048358,\n",
            "  8: 0.964060820228353,\n",
            "  9: 0.9646971667769954},\n",
            " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            " 10]\n",
            "[{0: array([0.        , 0.0021251 , 0.00526656, 0.00979396, 0.01810958,\n",
            "       0.04130093, 1.        ]),\n",
            "  1: array([0.        , 0.00194769, 0.00370989, 0.00639955, 0.01029494,\n",
            "       0.02355778, 1.        ]),\n",
            "  2: array([0.        , 0.00315516, 0.00603192, 0.0081663 , 0.01345583,\n",
            "       0.02505568, 1.        ]),\n",
            "  3: array([0.        , 0.00822855, 0.01525518, 0.02302145, 0.03337648,\n",
            "       0.06231509, 1.        ]),\n",
            "  4: array([0.00000000e+00, 5.56637907e-04, 2.69041655e-03, 5.00974116e-03,\n",
            "       1.00194823e-02, 2.27293812e-02, 1.00000000e+00]),\n",
            "  5: array([0.        , 0.00379208, 0.0073067 , 0.01202368, 0.01859046,\n",
            "       0.03940067, 1.        ]),\n",
            "  6: array([0.        , 0.00424707, 0.01043302, 0.0150494 , 0.02335888,\n",
            "       0.04367094, 1.        ]),\n",
            "  7: array([0.        , 0.00306094, 0.00751322, 0.01326408, 0.02504406,\n",
            "       0.05518969, 1.        ]),\n",
            "  8: array([0.        , 0.00258924, 0.00693545, 0.01091178, 0.01812465,\n",
            "       0.03643425, 1.        ]),\n",
            "  9: array([0.        , 0.00241053, 0.00389394, 0.00667532, 0.01168181,\n",
            "       0.02697942, 1.        ])},\n",
            " {0: array([0.        , 0.70773152, 0.80543755, 0.87085811, 0.90569244,\n",
            "       0.93797791, 1.        ]),\n",
            "  1: array([0.        , 0.75205255, 0.87110016, 0.91954023, 0.94909688,\n",
            "       0.97619048, 1.        ]),\n",
            "  2: array([0.        , 0.8251634 , 0.85130719, 0.87091503, 0.88970588,\n",
            "       0.91830065, 1.        ]),\n",
            "  3: array([0.        , 0.55827703, 0.71537162, 0.80152027, 0.86148649,\n",
            "       0.92060811, 1.        ]),\n",
            "  4: array([0.        , 0.73955774, 0.85749386, 0.90827191, 0.93529894,\n",
            "       0.97297297, 1.        ]),\n",
            "  5: array([0.        , 0.89814815, 0.9486532 , 0.96632997, 0.97979798,\n",
            "       0.99158249, 1.        ]),\n",
            "  6: array([0.        , 0.6364414 , 0.74508127, 0.81522669, 0.86740804,\n",
            "       0.91103507, 1.        ]),\n",
            "  7: array([0.        , 0.61936013, 0.75963905, 0.82772765, 0.87120591,\n",
            "       0.94585726, 1.        ]),\n",
            "  8: array([0.        , 0.82124789, 0.89123103, 0.92074199, 0.94940978,\n",
            "       0.96795953, 1.        ]),\n",
            "  9: array([0.        , 0.80889621, 0.85914333, 0.88550247, 0.907743  ,\n",
            "       0.93822076, 1.        ])},\n",
            " {0: 0.9646573806639641,\n",
            "  1: 0.9857954813700022,\n",
            "  2: 0.9558119956718147,\n",
            "  3: 0.9475204636149649,\n",
            "  4: 0.9847665391778946,\n",
            "  5: 0.9929235162078299,\n",
            "  6: 0.9480680276546765,\n",
            "  7: 0.9652100788926284,\n",
            "  8: 0.9808140156832486,\n",
            "  9: 0.9662110808721172},\n",
            " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            " 10]\n",
            "[{0: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.23958237e-05,\n",
            "       9.23958237e-05, 1.84791647e-04, 1.84791647e-04, 2.77187471e-04,\n",
            "       2.77187471e-04, 3.69583295e-04, 3.69583295e-04, 4.61979119e-04,\n",
            "       4.61979119e-04, 5.54374942e-04, 5.54374942e-04, 6.46770766e-04,\n",
            "       6.46770766e-04, 7.39166590e-04, 7.39166590e-04, 8.31562413e-04,\n",
            "       8.31562413e-04, 9.23958237e-04, 9.23958237e-04, 1.01635406e-03,\n",
            "       1.01635406e-03, 1.10874988e-03, 1.10874988e-03, 1.20114571e-03,\n",
            "       1.20114571e-03, 1.29354153e-03, 1.29354153e-03, 1.38593736e-03,\n",
            "       1.38593736e-03, 1.47833318e-03, 1.47833318e-03, 1.66312483e-03,\n",
            "       1.66312483e-03, 1.75552065e-03, 1.75552065e-03, 1.84791647e-03,\n",
            "       1.84791647e-03, 1.94031230e-03, 1.94031230e-03, 2.03270812e-03,\n",
            "       2.03270812e-03, 2.12510395e-03, 2.12510395e-03, 2.21749977e-03,\n",
            "       2.21749977e-03, 2.30989559e-03, 2.30989559e-03, 2.40229142e-03,\n",
            "       2.40229142e-03, 2.49468724e-03, 2.49468724e-03, 2.58708306e-03,\n",
            "       2.58708306e-03, 2.86427053e-03, 2.86427053e-03, 2.95666636e-03,\n",
            "       2.95666636e-03, 3.04906218e-03, 3.04906218e-03, 3.23385383e-03,\n",
            "       3.23385383e-03, 3.41864548e-03, 3.41864548e-03, 3.51104130e-03,\n",
            "       3.51104130e-03, 3.60343712e-03, 3.60343712e-03, 3.69583295e-03,\n",
            "       3.69583295e-03, 3.78822877e-03, 3.78822877e-03, 3.97302042e-03,\n",
            "       3.97302042e-03, 4.06541624e-03, 4.06541624e-03, 4.15781207e-03,\n",
            "       4.15781207e-03, 4.25020789e-03, 4.25020789e-03, 4.52739536e-03,\n",
            "       4.52739536e-03, 4.61979119e-03, 4.61979119e-03, 4.71218701e-03,\n",
            "       4.71218701e-03, 4.89697866e-03, 4.89697866e-03, 4.98937448e-03,\n",
            "       4.98937448e-03, 5.08177030e-03, 5.08177030e-03, 5.17416613e-03,\n",
            "       5.17416613e-03, 5.26656195e-03, 5.26656195e-03, 5.45135360e-03,\n",
            "       5.45135360e-03, 5.63614525e-03, 5.63614525e-03, 5.72854107e-03,\n",
            "       5.72854107e-03, 5.91333272e-03, 5.91333272e-03, 6.00572854e-03,\n",
            "       6.00572854e-03, 6.09812436e-03, 6.09812436e-03, 6.19052019e-03,\n",
            "       6.19052019e-03, 6.28291601e-03, 6.28291601e-03, 6.46770766e-03,\n",
            "       6.46770766e-03, 6.56010348e-03, 6.56010348e-03, 6.65249931e-03,\n",
            "       6.65249931e-03, 6.74489513e-03, 6.74489513e-03, 6.83729095e-03,\n",
            "       6.83729095e-03, 7.02208260e-03, 7.02208260e-03, 7.20687425e-03,\n",
            "       7.20687425e-03, 7.66885337e-03, 7.66885337e-03, 7.76124919e-03,\n",
            "       7.76124919e-03, 7.85364502e-03, 7.85364502e-03, 7.94604084e-03,\n",
            "       7.94604084e-03, 8.03843666e-03, 8.03843666e-03, 8.22322831e-03,\n",
            "       8.22322831e-03, 8.86999908e-03, 8.86999908e-03, 9.05479072e-03,\n",
            "       9.05479072e-03, 9.33197819e-03, 9.33197819e-03, 9.42437402e-03,\n",
            "       9.42437402e-03, 9.51676984e-03, 9.51676984e-03, 9.79395731e-03,\n",
            "       9.79395731e-03, 9.88635314e-03, 9.88635314e-03, 1.00711448e-02,\n",
            "       1.00711448e-02, 1.01635406e-02, 1.01635406e-02, 1.02559364e-02,\n",
            "       1.02559364e-02, 1.04407281e-02, 1.04407281e-02, 1.05331239e-02,\n",
            "       1.05331239e-02, 1.06255197e-02, 1.06255197e-02, 1.09951030e-02,\n",
            "       1.09951030e-02, 1.10874988e-02, 1.10874988e-02, 1.13646863e-02,\n",
            "       1.13646863e-02, 1.18266654e-02, 1.18266654e-02, 1.20114571e-02,\n",
            "       1.20114571e-02, 1.21962487e-02, 1.21962487e-02, 1.23810404e-02,\n",
            "       1.23810404e-02, 1.26582278e-02, 1.26582278e-02, 1.33973944e-02,\n",
            "       1.33973944e-02, 1.34897903e-02, 1.34897903e-02, 1.36745819e-02,\n",
            "       1.36745819e-02, 1.38593736e-02, 1.38593736e-02, 1.40441652e-02,\n",
            "       1.40441652e-02, 1.44137485e-02, 1.44137485e-02, 1.45985401e-02,\n",
            "       1.45985401e-02, 1.49681234e-02, 1.49681234e-02, 1.50605193e-02,\n",
            "       1.50605193e-02, 1.51529151e-02, 1.51529151e-02, 1.54301026e-02,\n",
            "       1.54301026e-02, 1.55224984e-02, 1.55224984e-02, 1.56148942e-02,\n",
            "       1.56148942e-02, 1.58920817e-02, 1.58920817e-02, 1.63540608e-02,\n",
            "       1.63540608e-02, 1.64464566e-02, 1.64464566e-02, 1.68160399e-02,\n",
            "       1.68160399e-02, 1.70008316e-02, 1.70008316e-02, 1.70932274e-02,\n",
            "       1.70932274e-02, 1.73704149e-02, 1.73704149e-02, 1.77399982e-02,\n",
            "       1.77399982e-02, 1.80171856e-02, 1.80171856e-02, 1.81095814e-02,\n",
            "       1.81095814e-02, 1.82019773e-02, 1.82019773e-02, 1.85715606e-02,\n",
            "       1.85715606e-02, 1.86639564e-02, 1.86639564e-02, 1.91259355e-02,\n",
            "       1.91259355e-02, 1.93107272e-02, 1.93107272e-02, 1.98651021e-02,\n",
            "       1.98651021e-02, 1.99574979e-02, 1.99574979e-02, 2.00498937e-02,\n",
            "       2.00498937e-02, 2.01422896e-02, 2.01422896e-02, 2.06042687e-02,\n",
            "       2.06042687e-02, 2.06966645e-02, 2.06966645e-02, 2.14358311e-02,\n",
            "       2.14358311e-02, 2.19902060e-02, 2.19902060e-02, 2.21749977e-02,\n",
            "       2.21749977e-02, 2.22673935e-02, 2.22673935e-02, 2.28217685e-02,\n",
            "       2.28217685e-02, 2.33761434e-02, 2.33761434e-02, 2.48544766e-02,\n",
            "       2.48544766e-02, 2.57784348e-02, 2.57784348e-02, 2.76263513e-02,\n",
            "       2.76263513e-02, 2.79035388e-02, 2.79035388e-02, 2.86427053e-02,\n",
            "       2.86427053e-02, 2.91046845e-02, 2.91046845e-02, 2.97514552e-02,\n",
            "       2.97514552e-02, 2.99362469e-02, 2.99362469e-02, 3.21537467e-02,\n",
            "       3.21537467e-02, 3.22461425e-02, 3.22461425e-02, 3.28005174e-02,\n",
            "       3.28005174e-02, 3.41864548e-02, 3.41864548e-02, 3.50180172e-02,\n",
            "       3.50180172e-02, 3.54799963e-02, 3.54799963e-02, 3.55723921e-02,\n",
            "       3.55723921e-02, 3.62191629e-02, 3.62191629e-02, 3.63115587e-02,\n",
            "       3.63115587e-02, 3.71431211e-02, 3.71431211e-02, 3.90834334e-02,\n",
            "       3.90834334e-02, 3.91758293e-02, 3.91758293e-02, 3.97302042e-02,\n",
            "       3.97302042e-02, 4.20400998e-02, 4.20400998e-02, 4.25020789e-02,\n",
            "       4.25020789e-02, 4.25944747e-02, 4.25944747e-02, 4.40728079e-02,\n",
            "       4.40728079e-02, 4.52739536e-02, 4.52739536e-02, 4.53663494e-02,\n",
            "       4.53663494e-02, 4.56435369e-02, 4.56435369e-02, 4.64750993e-02,\n",
            "       4.64750993e-02, 4.70294743e-02, 4.70294743e-02, 4.72142659e-02,\n",
            "       4.72142659e-02, 4.73066617e-02, 4.73066617e-02, 4.73990576e-02,\n",
            "       4.73990576e-02, 4.76762450e-02, 4.76762450e-02, 4.77686409e-02,\n",
            "       4.77686409e-02, 4.80458283e-02, 4.80458283e-02, 4.84154116e-02,\n",
            "       4.84154116e-02, 5.19264529e-02, 5.19264529e-02, 5.26656195e-02,\n",
            "       5.26656195e-02, 5.28504112e-02, 5.28504112e-02, 5.32199945e-02,\n",
            "       5.32199945e-02, 5.50679109e-02, 5.50679109e-02, 5.57146817e-02,\n",
            "       5.57146817e-02, 5.64538483e-02, 5.64538483e-02, 5.68234316e-02,\n",
            "       5.68234316e-02, 5.79321815e-02, 5.79321815e-02, 5.93181188e-02,\n",
            "       5.93181188e-02, 5.96877021e-02, 5.96877021e-02, 6.09812436e-02,\n",
            "       6.09812436e-02, 6.17204102e-02, 6.17204102e-02, 6.31987434e-02,\n",
            "       6.31987434e-02, 6.39379100e-02, 6.39379100e-02, 6.68021805e-02,\n",
            "       6.68021805e-02, 6.88348887e-02, 6.88348887e-02, 6.99436385e-02,\n",
            "       6.99436385e-02, 7.20687425e-02, 7.20687425e-02, 7.90908251e-02,\n",
            "       7.90908251e-02, 8.06615541e-02, 8.06615541e-02, 8.30638455e-02,\n",
            "       8.30638455e-02, 8.52813453e-02, 8.52813453e-02, 8.62976993e-02,\n",
            "       8.62976993e-02, 8.81456158e-02, 8.81456158e-02, 9.11022822e-02,\n",
            "       9.11022822e-02, 9.33197819e-02, 9.33197819e-02, 9.34121778e-02,\n",
            "       9.34121778e-02, 1.00064677e-01, 1.00064677e-01, 1.12722905e-01,\n",
            "       1.12722905e-01, 1.17435092e-01, 1.17435092e-01, 1.20668946e-01,\n",
            "       1.20668946e-01, 1.21962487e-01, 1.21962487e-01, 1.29354153e-01,\n",
            "       1.29354153e-01, 1.32033632e-01, 1.32033632e-01, 1.37300194e-01,\n",
            "       1.37300194e-01, 1.42104777e-01, 1.42104777e-01, 1.43398318e-01,\n",
            "       1.43398318e-01, 1.50050818e-01, 1.50050818e-01, 1.50789984e-01,\n",
            "       1.50789984e-01, 1.51344359e-01, 1.51344359e-01, 1.53654255e-01,\n",
            "       1.53654255e-01, 1.60306754e-01, 1.60306754e-01, 1.66959253e-01,\n",
            "       1.66959253e-01, 1.71394253e-01, 1.71394253e-01, 1.72410607e-01,\n",
            "       1.72410607e-01, 1.73519357e-01, 1.73519357e-01, 1.74905294e-01,\n",
            "       1.74905294e-01, 1.76106440e-01, 1.76106440e-01, 1.91259355e-01,\n",
            "       1.91259355e-01, 1.93384459e-01, 1.93384459e-01, 1.93569251e-01,\n",
            "       1.93569251e-01, 2.06412270e-01, 2.06412270e-01, 2.08722166e-01,\n",
            "       2.08722166e-01, 2.33207059e-01, 2.33207059e-01, 2.41799871e-01,\n",
            "       2.41799871e-01, 2.53441744e-01, 2.53441744e-01, 2.57137577e-01,\n",
            "       2.57137577e-01, 2.62404139e-01, 2.62404139e-01, 2.91693615e-01,\n",
            "       2.91693615e-01, 3.23200591e-01, 3.23200591e-01, 3.40386215e-01,\n",
            "       3.40386215e-01, 3.52212880e-01, 3.52212880e-01, 4.22988081e-01,\n",
            "       4.22988081e-01, 6.56657119e-01, 6.56657119e-01, 8.54199390e-01,\n",
            "       8.54199390e-01, 1.00000000e+00]),\n",
            "  1: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27471712e-05,\n",
            "       9.27471712e-05, 1.85494342e-04, 1.85494342e-04, 2.78241514e-04,\n",
            "       2.78241514e-04, 3.70988685e-04, 3.70988685e-04, 4.63735856e-04,\n",
            "       4.63735856e-04, 5.56483027e-04, 5.56483027e-04, 6.49230198e-04,\n",
            "       6.49230198e-04, 7.41977370e-04, 7.41977370e-04, 8.34724541e-04,\n",
            "       8.34724541e-04, 9.27471712e-04, 9.27471712e-04, 1.02021888e-03,\n",
            "       1.02021888e-03, 1.11296605e-03, 1.11296605e-03, 1.20571323e-03,\n",
            "       1.20571323e-03, 1.29846040e-03, 1.29846040e-03, 1.39120757e-03,\n",
            "       1.39120757e-03, 1.48395474e-03, 1.48395474e-03, 1.57670191e-03,\n",
            "       1.57670191e-03, 1.66944908e-03, 1.66944908e-03, 1.76219625e-03,\n",
            "       1.76219625e-03, 1.85494342e-03, 1.85494342e-03, 1.94769060e-03,\n",
            "       1.94769060e-03, 2.04043777e-03, 2.04043777e-03, 2.13318494e-03,\n",
            "       2.13318494e-03, 2.22593211e-03, 2.22593211e-03, 2.31867928e-03,\n",
            "       2.31867928e-03, 2.41142645e-03, 2.41142645e-03, 2.50417362e-03,\n",
            "       2.50417362e-03, 2.59692079e-03, 2.59692079e-03, 2.68966797e-03,\n",
            "       2.68966797e-03, 2.78241514e-03, 2.78241514e-03, 3.24615099e-03,\n",
            "       3.24615099e-03, 3.33889816e-03, 3.33889816e-03, 3.43164533e-03,\n",
            "       3.43164533e-03, 3.61713968e-03, 3.61713968e-03, 3.70988685e-03,\n",
            "       3.70988685e-03, 3.80263402e-03, 3.80263402e-03, 3.98812836e-03,\n",
            "       3.98812836e-03, 4.08087553e-03, 4.08087553e-03, 4.17362270e-03,\n",
            "       4.17362270e-03, 4.26636988e-03, 4.26636988e-03, 4.35911705e-03,\n",
            "       4.35911705e-03, 4.45186422e-03, 4.45186422e-03, 4.54461139e-03,\n",
            "       4.54461139e-03, 4.63735856e-03, 4.63735856e-03, 5.00834725e-03,\n",
            "       5.00834725e-03, 5.10109442e-03, 5.10109442e-03, 5.19384159e-03,\n",
            "       5.19384159e-03, 5.28658876e-03, 5.28658876e-03, 5.37933593e-03,\n",
            "       5.37933593e-03, 5.47208310e-03, 5.47208310e-03, 5.56483027e-03,\n",
            "       5.56483027e-03, 5.84307179e-03, 5.84307179e-03, 5.93581896e-03,\n",
            "       5.93581896e-03, 6.02856613e-03, 6.02856613e-03, 6.12131330e-03,\n",
            "       6.12131330e-03, 6.21406047e-03, 6.21406047e-03, 6.30680764e-03,\n",
            "       6.30680764e-03, 6.58504916e-03, 6.58504916e-03, 6.77054350e-03,\n",
            "       6.77054350e-03, 6.86329067e-03, 6.86329067e-03, 6.95603784e-03,\n",
            "       6.95603784e-03, 7.23427935e-03, 7.23427935e-03, 7.69801521e-03,\n",
            "       7.69801521e-03, 8.16175107e-03, 8.16175107e-03, 8.25449824e-03,\n",
            "       8.25449824e-03, 8.34724541e-03, 8.34724541e-03, 8.43999258e-03,\n",
            "       8.43999258e-03, 8.81098127e-03, 8.81098127e-03, 9.18196995e-03,\n",
            "       9.18196995e-03, 9.83120015e-03, 9.83120015e-03, 1.01094417e-02,\n",
            "       1.01094417e-02, 1.02949360e-02, 1.02949360e-02, 1.07586719e-02,\n",
            "       1.07586719e-02, 1.18716379e-02, 1.18716379e-02, 1.19643851e-02,\n",
            "       1.19643851e-02, 1.20571323e-02, 1.20571323e-02, 1.22426266e-02,\n",
            "       1.22426266e-02, 1.27991096e-02, 1.27991096e-02, 1.41903172e-02,\n",
            "       1.41903172e-02, 1.49322946e-02, 1.49322946e-02, 1.50250417e-02,\n",
            "       1.50250417e-02, 1.70654795e-02, 1.70654795e-02, 1.91059173e-02,\n",
            "       1.91059173e-02, 1.99406418e-02, 1.99406418e-02, 2.12391022e-02,\n",
            "       2.12391022e-02, 2.28158041e-02, 2.28158041e-02, 2.64329438e-02,\n",
            "       2.64329438e-02, 2.77314042e-02, 2.77314042e-02, 2.94936004e-02,\n",
            "       2.94936004e-02, 3.19050269e-02, 3.19050269e-02, 3.29252458e-02,\n",
            "       3.29252458e-02, 3.34817288e-02, 3.34817288e-02, 3.58004081e-02,\n",
            "       3.58004081e-02, 4.47968837e-02, 4.47968837e-02, 4.64663328e-02,\n",
            "       4.64663328e-02, 5.97291783e-02, 5.97291783e-02, 8.12465220e-02,\n",
            "       8.12465220e-02, 1.07308477e-01, 1.07308477e-01, 1.54795029e-01,\n",
            "       1.54795029e-01, 1.69263587e-01, 1.69263587e-01, 1.00000000e+00]),\n",
            "  2: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27988122e-05,\n",
            "       9.27988122e-05, 1.85597624e-04, 1.85597624e-04, 2.78396437e-04,\n",
            "       2.78396437e-04, 3.71195249e-04, 3.71195249e-04, 4.63994061e-04,\n",
            "       4.63994061e-04, 5.56792873e-04, 5.56792873e-04, 6.49591685e-04,\n",
            "       6.49591685e-04, 7.42390497e-04, 7.42390497e-04, 8.35189310e-04,\n",
            "       8.35189310e-04, 9.27988122e-04, 9.27988122e-04, 1.02078693e-03,\n",
            "       1.02078693e-03, 1.11358575e-03, 1.11358575e-03, 1.20638456e-03,\n",
            "       1.20638456e-03, 1.29918337e-03, 1.29918337e-03, 1.39198218e-03,\n",
            "       1.39198218e-03, 1.48478099e-03, 1.48478099e-03, 1.57757981e-03,\n",
            "       1.57757981e-03, 1.67037862e-03, 1.67037862e-03, 1.76317743e-03,\n",
            "       1.76317743e-03, 1.85597624e-03, 1.85597624e-03, 1.94877506e-03,\n",
            "       1.94877506e-03, 2.04157387e-03, 2.04157387e-03, 2.13437268e-03,\n",
            "       2.13437268e-03, 2.22717149e-03, 2.22717149e-03, 2.31997030e-03,\n",
            "       2.31997030e-03, 2.41276912e-03, 2.41276912e-03, 2.50556793e-03,\n",
            "       2.50556793e-03, 2.59836674e-03, 2.59836674e-03, 2.69116555e-03,\n",
            "       2.69116555e-03, 2.87676318e-03, 2.87676318e-03, 2.96956199e-03,\n",
            "       2.96956199e-03, 3.06236080e-03, 3.06236080e-03, 3.15515961e-03,\n",
            "       3.15515961e-03, 3.43355605e-03, 3.43355605e-03, 3.61915367e-03,\n",
            "       3.61915367e-03, 3.71195249e-03, 3.71195249e-03, 3.89755011e-03,\n",
            "       3.89755011e-03, 4.26874536e-03, 4.26874536e-03, 4.36154417e-03,\n",
            "       4.36154417e-03, 4.45434298e-03, 4.45434298e-03, 4.54714180e-03,\n",
            "       4.54714180e-03, 4.63994061e-03, 4.63994061e-03, 4.73273942e-03,\n",
            "       4.73273942e-03, 4.91833705e-03, 4.91833705e-03, 5.01113586e-03,\n",
            "       5.01113586e-03, 5.10393467e-03, 5.10393467e-03, 5.28953229e-03,\n",
            "       5.28953229e-03, 5.38233111e-03, 5.38233111e-03, 5.47512992e-03,\n",
            "       5.47512992e-03, 5.56792873e-03, 5.56792873e-03, 5.66072754e-03,\n",
            "       5.66072754e-03, 5.84632517e-03, 5.84632517e-03, 5.93912398e-03,\n",
            "       5.93912398e-03, 6.12472160e-03, 6.12472160e-03, 6.21752042e-03,\n",
            "       6.21752042e-03, 6.31031923e-03, 6.31031923e-03, 6.40311804e-03,\n",
            "       6.40311804e-03, 6.58871566e-03, 6.58871566e-03, 6.77431329e-03,\n",
            "       6.77431329e-03, 6.95991091e-03, 6.95991091e-03, 7.33110616e-03,\n",
            "       7.33110616e-03, 7.51670379e-03, 7.51670379e-03, 7.60950260e-03,\n",
            "       7.60950260e-03, 8.35189310e-03, 8.35189310e-03, 8.44469191e-03,\n",
            "       8.44469191e-03, 8.63028953e-03, 8.63028953e-03, 8.81588716e-03,\n",
            "       8.81588716e-03, 8.90868597e-03, 8.90868597e-03, 9.09428359e-03,\n",
            "       9.09428359e-03, 9.37268003e-03, 9.37268003e-03, 9.65107647e-03,\n",
            "       9.65107647e-03, 9.83667409e-03, 9.83667409e-03, 1.00222717e-02,\n",
            "       1.00222717e-02, 1.02078693e-02, 1.02078693e-02, 1.03934670e-02,\n",
            "       1.03934670e-02, 1.05790646e-02, 1.05790646e-02, 1.06718634e-02,\n",
            "       1.06718634e-02, 1.08574610e-02, 1.08574610e-02, 1.10430586e-02,\n",
            "       1.10430586e-02, 1.13214551e-02, 1.13214551e-02, 1.14142539e-02,\n",
            "       1.14142539e-02, 1.15998515e-02, 1.15998515e-02, 1.16926503e-02,\n",
            "       1.16926503e-02, 1.20638456e-02, 1.20638456e-02, 1.23422420e-02,\n",
            "       1.23422420e-02, 1.25278396e-02, 1.25278396e-02, 1.31774313e-02,\n",
            "       1.31774313e-02, 1.33630290e-02, 1.33630290e-02, 1.34558278e-02,\n",
            "       1.34558278e-02, 1.35486266e-02, 1.35486266e-02, 1.37342242e-02,\n",
            "       1.37342242e-02, 1.38270230e-02, 1.38270230e-02, 1.41982183e-02,\n",
            "       1.41982183e-02, 1.48478099e-02, 1.48478099e-02, 1.49406088e-02,\n",
            "       1.49406088e-02, 1.54046028e-02, 1.54046028e-02, 1.54974016e-02,\n",
            "       1.54974016e-02, 1.58685969e-02, 1.58685969e-02, 1.64253898e-02,\n",
            "       1.64253898e-02, 1.65181886e-02, 1.65181886e-02, 1.66109874e-02,\n",
            "       1.66109874e-02, 1.70749814e-02, 1.70749814e-02, 1.74461767e-02,\n",
            "       1.74461767e-02, 1.76317743e-02, 1.76317743e-02, 1.80957684e-02,\n",
            "       1.80957684e-02, 1.82813660e-02, 1.82813660e-02, 1.87453601e-02,\n",
            "       1.87453601e-02, 1.88381589e-02, 1.88381589e-02, 1.91165553e-02,\n",
            "       1.91165553e-02, 1.95805494e-02, 1.95805494e-02, 2.00445434e-02,\n",
            "       2.00445434e-02, 2.06941351e-02, 2.06941351e-02, 2.11581292e-02,\n",
            "       2.11581292e-02, 2.12509280e-02, 2.12509280e-02, 2.19005197e-02,\n",
            "       2.19005197e-02, 2.24573125e-02, 2.24573125e-02, 2.31997030e-02,\n",
            "       2.31997030e-02, 2.38492947e-02, 2.38492947e-02, 2.47772829e-02,\n",
            "       2.47772829e-02, 2.48700817e-02, 2.48700817e-02, 2.50556793e-02,\n",
            "       2.50556793e-02, 2.60764662e-02, 2.60764662e-02, 2.64476615e-02,\n",
            "       2.64476615e-02, 2.68188567e-02, 2.68188567e-02, 2.70972532e-02,\n",
            "       2.70972532e-02, 2.79324425e-02, 2.79324425e-02, 2.83964365e-02,\n",
            "       2.83964365e-02, 2.86748330e-02, 2.86748330e-02, 2.96956199e-02,\n",
            "       2.96956199e-02, 3.01596140e-02, 3.01596140e-02, 3.11804009e-02,\n",
            "       3.11804009e-02, 3.28507795e-02, 3.28507795e-02, 3.43355605e-02,\n",
            "       3.43355605e-02, 3.45211581e-02, 3.45211581e-02, 3.54491463e-02,\n",
            "       3.54491463e-02, 3.58203415e-02, 3.58203415e-02, 3.59131403e-02,\n",
            "       3.59131403e-02, 3.61915367e-02, 3.61915367e-02, 3.66555308e-02,\n",
            "       3.66555308e-02, 3.76763177e-02, 3.76763177e-02, 3.84187082e-02,\n",
            "       3.84187082e-02, 3.86043059e-02, 3.86043059e-02, 3.86971047e-02,\n",
            "       3.86971047e-02, 3.88827023e-02, 3.88827023e-02, 3.92538976e-02,\n",
            "       3.92538976e-02, 3.93466964e-02, 3.93466964e-02, 4.11098738e-02,\n",
            "       4.11098738e-02, 4.14810690e-02, 4.14810690e-02, 4.20378619e-02,\n",
            "       4.20378619e-02, 4.24090572e-02, 4.24090572e-02, 4.25018560e-02,\n",
            "       4.25018560e-02, 4.26874536e-02, 4.26874536e-02, 4.28730512e-02,\n",
            "       4.28730512e-02, 4.31514477e-02, 4.31514477e-02, 4.38010393e-02,\n",
            "       4.38010393e-02, 4.40794358e-02, 4.40794358e-02, 4.45434298e-02,\n",
            "       4.45434298e-02, 4.46362287e-02, 4.46362287e-02, 4.52858203e-02,\n",
            "       4.52858203e-02, 4.53786192e-02, 4.53786192e-02, 4.54714180e-02,\n",
            "       4.54714180e-02, 4.63994061e-02, 4.63994061e-02, 4.64922049e-02,\n",
            "       4.64922049e-02, 4.72345954e-02, 4.72345954e-02, 4.85337788e-02,\n",
            "       4.85337788e-02, 4.90905716e-02, 4.90905716e-02, 4.94617669e-02,\n",
            "       4.94617669e-02, 5.00185598e-02, 5.00185598e-02, 5.01113586e-02,\n",
            "       5.01113586e-02, 5.08537491e-02, 5.08537491e-02, 5.12249443e-02,\n",
            "       5.12249443e-02, 5.14105419e-02, 5.14105419e-02, 5.35449146e-02,\n",
            "       5.35449146e-02, 5.46585004e-02, 5.46585004e-02, 5.59576837e-02,\n",
            "       5.59576837e-02, 5.60504826e-02, 5.60504826e-02, 5.76280624e-02,\n",
            "       5.76280624e-02, 5.91128434e-02, 5.91128434e-02, 5.94840386e-02,\n",
            "       5.94840386e-02, 5.97624350e-02, 5.97624350e-02, 5.98552339e-02,\n",
            "       5.98552339e-02, 6.11544172e-02, 6.11544172e-02, 6.48663697e-02,\n",
            "       6.48663697e-02, 6.58871566e-02, 6.58871566e-02, 6.60727543e-02,\n",
            "       6.60727543e-02, 6.61655531e-02, 6.61655531e-02, 6.62583519e-02,\n",
            "       6.62583519e-02, 6.77431329e-02, 6.77431329e-02, 6.81143281e-02,\n",
            "       6.81143281e-02, 6.82071269e-02, 6.82071269e-02, 6.89495174e-02,\n",
            "       6.89495174e-02, 6.90423163e-02, 6.90423163e-02, 6.93207127e-02,\n",
            "       6.93207127e-02, 7.14550854e-02, 7.14550854e-02, 7.22902747e-02,\n",
            "       7.22902747e-02, 7.40534521e-02, 7.40534521e-02, 7.66518189e-02,\n",
            "       7.66518189e-02, 7.73942094e-02, 7.73942094e-02, 8.11061618e-02,\n",
            "       8.11061618e-02, 8.31477357e-02, 8.31477357e-02, 8.64884929e-02,\n",
            "       8.64884929e-02, 8.79732739e-02, 8.79732739e-02, 8.92724573e-02,\n",
            "       8.92724573e-02, 8.93652561e-02, 8.93652561e-02, 9.23348181e-02,\n",
            "       9.23348181e-02, 9.27060134e-02, 9.27060134e-02, 9.28916110e-02,\n",
            "       9.28916110e-02, 9.30772086e-02, 9.30772086e-02, 9.50259837e-02,\n",
            "       9.50259837e-02, 9.55827765e-02, 9.55827765e-02, 9.88307350e-02,\n",
            "       9.88307350e-02, 9.95731255e-02, 9.95731255e-02, 1.00315516e-01,\n",
            "       1.00315516e-01, 1.00965108e-01, 1.00965108e-01, 1.05233853e-01,\n",
            "       1.05233853e-01, 1.05605048e-01, 1.05605048e-01, 1.07275427e-01,\n",
            "       1.07275427e-01, 1.09595397e-01, 1.09595397e-01, 1.17019302e-01,\n",
            "       1.17019302e-01, 1.22030438e-01, 1.22030438e-01, 1.22123237e-01,\n",
            "       1.22123237e-01, 1.22494432e-01, 1.22494432e-01, 1.24072012e-01,\n",
            "       1.24072012e-01, 1.26206385e-01, 1.26206385e-01, 1.26391982e-01,\n",
            "       1.26391982e-01, 1.28990349e-01, 1.28990349e-01, 1.33723088e-01,\n",
            "       1.33723088e-01, 1.36692650e-01, 1.36692650e-01, 1.51911656e-01,\n",
            "       1.51911656e-01, 1.58871566e-01, 1.58871566e-01, 1.59521158e-01,\n",
            "       1.59521158e-01, 1.66388270e-01, 1.66388270e-01, 1.67873051e-01,\n",
            "       1.67873051e-01, 1.73904974e-01, 1.73904974e-01, 1.76967335e-01,\n",
            "       1.76967335e-01, 1.86804009e-01, 1.86804009e-01, 1.87824796e-01,\n",
            "       1.87824796e-01, 1.94227914e-01, 1.94227914e-01, 2.02765405e-01,\n",
            "       2.02765405e-01, 2.02951002e-01, 2.02951002e-01, 2.17334818e-01,\n",
            "       2.17334818e-01, 2.17984410e-01, 2.17984410e-01, 2.26800297e-01,\n",
            "       2.26800297e-01, 2.35430586e-01, 2.35430586e-01, 2.51113586e-01,\n",
            "       2.51113586e-01, 2.54268745e-01, 2.54268745e-01, 3.45397179e-01,\n",
            "       3.45397179e-01, 3.53749072e-01, 3.53749072e-01, 1.00000000e+00]),\n",
            "  3: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.24556213e-05,\n",
            "       9.24556213e-05, 1.84911243e-04, 1.84911243e-04, 2.77366864e-04,\n",
            "       2.77366864e-04, 3.69822485e-04, 3.69822485e-04, 4.62278107e-04,\n",
            "       4.62278107e-04, 5.54733728e-04, 5.54733728e-04, 6.47189349e-04,\n",
            "       6.47189349e-04, 7.39644970e-04, 7.39644970e-04, 8.32100592e-04,\n",
            "       8.32100592e-04, 9.24556213e-04, 9.24556213e-04, 1.01701183e-03,\n",
            "       1.01701183e-03, 1.20192308e-03, 1.20192308e-03, 1.38683432e-03,\n",
            "       1.38683432e-03, 1.57174556e-03, 1.57174556e-03, 1.66420118e-03,\n",
            "       1.66420118e-03, 1.75665680e-03, 1.75665680e-03, 1.94156805e-03,\n",
            "       1.94156805e-03, 2.12647929e-03, 2.12647929e-03, 2.21893491e-03,\n",
            "       2.21893491e-03, 2.68121302e-03, 2.68121302e-03, 2.77366864e-03,\n",
            "       2.77366864e-03, 2.86612426e-03, 2.86612426e-03, 2.95857988e-03,\n",
            "       2.95857988e-03, 3.05103550e-03, 3.05103550e-03, 3.23594675e-03,\n",
            "       3.23594675e-03, 3.32840237e-03, 3.32840237e-03, 3.42085799e-03,\n",
            "       3.42085799e-03, 3.51331361e-03, 3.51331361e-03, 3.69822485e-03,\n",
            "       3.69822485e-03, 3.88313609e-03, 3.88313609e-03, 4.06804734e-03,\n",
            "       4.06804734e-03, 4.16050296e-03, 4.16050296e-03, 4.25295858e-03,\n",
            "       4.25295858e-03, 4.34541420e-03, 4.34541420e-03, 4.43786982e-03,\n",
            "       4.43786982e-03, 4.53032544e-03, 4.53032544e-03, 4.71523669e-03,\n",
            "       4.71523669e-03, 4.80769231e-03, 4.80769231e-03, 4.90014793e-03,\n",
            "       4.90014793e-03, 4.99260355e-03, 4.99260355e-03, 5.08505917e-03,\n",
            "       5.08505917e-03, 5.17751479e-03, 5.17751479e-03, 5.26997041e-03,\n",
            "       5.26997041e-03, 5.45488166e-03, 5.45488166e-03, 5.54733728e-03,\n",
            "       5.54733728e-03, 5.63979290e-03, 5.63979290e-03, 5.73224852e-03,\n",
            "       5.73224852e-03, 6.00961538e-03, 6.00961538e-03, 6.10207101e-03,\n",
            "       6.10207101e-03, 6.19452663e-03, 6.19452663e-03, 6.28698225e-03,\n",
            "       6.28698225e-03, 6.37943787e-03, 6.37943787e-03, 6.74926036e-03,\n",
            "       6.74926036e-03, 6.93417160e-03, 6.93417160e-03, 7.02662722e-03,\n",
            "       7.02662722e-03, 7.11908284e-03, 7.11908284e-03, 7.21153846e-03,\n",
            "       7.21153846e-03, 7.30399408e-03, 7.30399408e-03, 7.39644970e-03,\n",
            "       7.39644970e-03, 7.58136095e-03, 7.58136095e-03, 7.76627219e-03,\n",
            "       7.76627219e-03, 7.85872781e-03, 7.85872781e-03, 7.95118343e-03,\n",
            "       7.95118343e-03, 8.04363905e-03, 8.04363905e-03, 8.41346154e-03,\n",
            "       8.41346154e-03, 8.50591716e-03, 8.50591716e-03, 8.59837278e-03,\n",
            "       8.59837278e-03, 8.69082840e-03, 8.69082840e-03, 8.78328402e-03,\n",
            "       8.78328402e-03, 8.96819527e-03, 8.96819527e-03, 9.33801775e-03,\n",
            "       9.33801775e-03, 9.43047337e-03, 9.43047337e-03, 9.52292899e-03,\n",
            "       9.52292899e-03, 9.61538462e-03, 9.61538462e-03, 9.70784024e-03,\n",
            "       9.70784024e-03, 9.89275148e-03, 9.89275148e-03, 9.98520710e-03,\n",
            "       9.98520710e-03, 1.00776627e-02, 1.00776627e-02, 1.02625740e-02,\n",
            "       1.02625740e-02, 1.03550296e-02, 1.03550296e-02, 1.04474852e-02,\n",
            "       1.04474852e-02, 1.05399408e-02, 1.05399408e-02, 1.06323964e-02,\n",
            "       1.06323964e-02, 1.07248521e-02, 1.07248521e-02, 1.08173077e-02,\n",
            "       1.08173077e-02, 1.10022189e-02, 1.10022189e-02, 1.11871302e-02,\n",
            "       1.11871302e-02, 1.12795858e-02, 1.12795858e-02, 1.13720414e-02,\n",
            "       1.13720414e-02, 1.14644970e-02, 1.14644970e-02, 1.15569527e-02,\n",
            "       1.15569527e-02, 1.18343195e-02, 1.18343195e-02, 1.20192308e-02,\n",
            "       1.20192308e-02, 1.21116864e-02, 1.21116864e-02, 1.22041420e-02,\n",
            "       1.22041420e-02, 1.22965976e-02, 1.22965976e-02, 1.23890533e-02,\n",
            "       1.23890533e-02, 1.24815089e-02, 1.24815089e-02, 1.26664201e-02,\n",
            "       1.26664201e-02, 1.27588757e-02, 1.27588757e-02, 1.28513314e-02,\n",
            "       1.28513314e-02, 1.29437870e-02, 1.29437870e-02, 1.33136095e-02,\n",
            "       1.33136095e-02, 1.34060651e-02, 1.34060651e-02, 1.35909763e-02,\n",
            "       1.35909763e-02, 1.36834320e-02, 1.36834320e-02, 1.37758876e-02,\n",
            "       1.37758876e-02, 1.39607988e-02, 1.39607988e-02, 1.40532544e-02,\n",
            "       1.40532544e-02, 1.42381657e-02, 1.42381657e-02, 1.43306213e-02,\n",
            "       1.43306213e-02, 1.44230769e-02, 1.44230769e-02, 1.46079882e-02,\n",
            "       1.46079882e-02, 1.47004438e-02, 1.47004438e-02, 1.47928994e-02,\n",
            "       1.47928994e-02, 1.48853550e-02, 1.48853550e-02, 1.50702663e-02,\n",
            "       1.50702663e-02, 1.51627219e-02, 1.51627219e-02, 1.52551775e-02,\n",
            "       1.52551775e-02, 1.53476331e-02, 1.53476331e-02, 1.54400888e-02,\n",
            "       1.54400888e-02, 1.57174556e-02, 1.57174556e-02, 1.63646450e-02,\n",
            "       1.63646450e-02, 1.65495562e-02, 1.65495562e-02, 1.66420118e-02,\n",
            "       1.66420118e-02, 1.67344675e-02, 1.67344675e-02, 1.68269231e-02,\n",
            "       1.68269231e-02, 1.70118343e-02, 1.70118343e-02, 1.72892012e-02,\n",
            "       1.72892012e-02, 1.73816568e-02, 1.73816568e-02, 1.74741124e-02,\n",
            "       1.74741124e-02, 1.75665680e-02, 1.75665680e-02, 1.77514793e-02,\n",
            "       1.77514793e-02, 1.91383136e-02, 1.91383136e-02, 1.92307692e-02,\n",
            "       1.92307692e-02, 1.94156805e-02, 1.94156805e-02, 1.95081361e-02,\n",
            "       1.95081361e-02, 1.96005917e-02, 1.96005917e-02, 1.96930473e-02,\n",
            "       1.96930473e-02, 1.97855030e-02, 1.97855030e-02, 1.98779586e-02,\n",
            "       1.98779586e-02, 1.99704142e-02, 1.99704142e-02, 2.00628698e-02,\n",
            "       2.00628698e-02, 2.02477811e-02, 2.02477811e-02, 2.03402367e-02,\n",
            "       2.03402367e-02, 2.07100592e-02, 2.07100592e-02, 2.08025148e-02,\n",
            "       2.08025148e-02, 2.08949704e-02, 2.08949704e-02, 2.09874260e-02,\n",
            "       2.09874260e-02, 2.15421598e-02, 2.15421598e-02, 2.16346154e-02,\n",
            "       2.16346154e-02, 2.17270710e-02, 2.17270710e-02, 2.18195266e-02,\n",
            "       2.18195266e-02, 2.19119822e-02, 2.19119822e-02, 2.20044379e-02,\n",
            "       2.20044379e-02, 2.21893491e-02, 2.21893491e-02, 2.25591716e-02,\n",
            "       2.25591716e-02, 2.28365385e-02, 2.28365385e-02, 2.29289941e-02,\n",
            "       2.29289941e-02, 2.31139053e-02, 2.31139053e-02, 2.35761834e-02,\n",
            "       2.35761834e-02, 2.43158284e-02, 2.43158284e-02, 2.45007396e-02,\n",
            "       2.45007396e-02, 2.45931953e-02, 2.45931953e-02, 2.47781065e-02,\n",
            "       2.47781065e-02, 2.48705621e-02, 2.48705621e-02, 2.50554734e-02,\n",
            "       2.50554734e-02, 2.51479290e-02, 2.51479290e-02, 2.56102071e-02,\n",
            "       2.56102071e-02, 2.57951183e-02, 2.57951183e-02, 2.58875740e-02,\n",
            "       2.58875740e-02, 2.59800296e-02, 2.59800296e-02, 2.60724852e-02,\n",
            "       2.60724852e-02, 2.61649408e-02, 2.61649408e-02, 2.63498521e-02,\n",
            "       2.63498521e-02, 2.64423077e-02, 2.64423077e-02, 2.65347633e-02,\n",
            "       2.65347633e-02, 2.67196746e-02, 2.67196746e-02, 2.71819527e-02,\n",
            "       2.71819527e-02, 2.72744083e-02, 2.72744083e-02, 2.75517751e-02,\n",
            "       2.75517751e-02, 2.81065089e-02, 2.81065089e-02, 2.82914201e-02,\n",
            "       2.82914201e-02, 2.84763314e-02, 2.84763314e-02, 2.93084320e-02,\n",
            "       2.93084320e-02, 2.94008876e-02, 2.94008876e-02, 2.94933432e-02,\n",
            "       2.94933432e-02, 2.98631657e-02, 2.98631657e-02, 2.99556213e-02,\n",
            "       2.99556213e-02, 3.00480769e-02, 3.00480769e-02, 3.02329882e-02,\n",
            "       3.02329882e-02, 3.05103550e-02, 3.05103550e-02, 3.07877219e-02,\n",
            "       3.07877219e-02, 3.08801775e-02, 3.08801775e-02, 3.09726331e-02,\n",
            "       3.09726331e-02, 3.10650888e-02, 3.10650888e-02, 3.11575444e-02,\n",
            "       3.11575444e-02, 3.13424556e-02, 3.13424556e-02, 3.14349112e-02,\n",
            "       3.14349112e-02, 3.20821006e-02, 3.20821006e-02, 3.23594675e-02,\n",
            "       3.23594675e-02, 3.24519231e-02, 3.24519231e-02, 3.32840237e-02,\n",
            "       3.32840237e-02, 3.34689349e-02, 3.34689349e-02, 3.36538462e-02,\n",
            "       3.36538462e-02, 3.39312130e-02, 3.39312130e-02, 3.44859467e-02,\n",
            "       3.44859467e-02, 3.45784024e-02, 3.45784024e-02, 3.46708580e-02,\n",
            "       3.46708580e-02, 3.47633136e-02, 3.47633136e-02, 3.50406805e-02,\n",
            "       3.50406805e-02, 3.51331361e-02, 3.51331361e-02, 3.54105030e-02,\n",
            "       3.54105030e-02, 3.56878698e-02, 3.56878698e-02, 3.57803254e-02,\n",
            "       3.57803254e-02, 3.60576923e-02, 3.60576923e-02, 3.61501479e-02,\n",
            "       3.61501479e-02, 3.66124260e-02, 3.66124260e-02, 3.67048817e-02,\n",
            "       3.67048817e-02, 3.74445266e-02, 3.74445266e-02, 3.76294379e-02,\n",
            "       3.76294379e-02, 3.78143491e-02, 3.78143491e-02, 3.79068047e-02,\n",
            "       3.79068047e-02, 3.80917160e-02, 3.80917160e-02, 3.89238166e-02,\n",
            "       3.89238166e-02, 3.93860947e-02, 3.93860947e-02, 3.98483728e-02,\n",
            "       3.98483728e-02, 4.06804734e-02, 4.06804734e-02, 4.08653846e-02,\n",
            "       4.08653846e-02, 4.14201183e-02, 4.14201183e-02, 4.15125740e-02,\n",
            "       4.15125740e-02, 4.30843195e-02, 4.30843195e-02, 4.33616864e-02,\n",
            "       4.33616864e-02, 4.36390533e-02, 4.36390533e-02, 4.39164201e-02,\n",
            "       4.39164201e-02, 4.40088757e-02, 4.40088757e-02, 4.47485207e-02,\n",
            "       4.47485207e-02, 4.53957101e-02, 4.53957101e-02, 4.56730769e-02,\n",
            "       4.56730769e-02, 4.57655325e-02, 4.57655325e-02, 4.60428994e-02,\n",
            "       4.60428994e-02, 4.64127219e-02, 4.64127219e-02, 4.65976331e-02,\n",
            "       4.65976331e-02, 4.70599112e-02, 4.70599112e-02, 4.71523669e-02,\n",
            "       4.71523669e-02, 4.73372781e-02, 4.73372781e-02, 4.75221893e-02,\n",
            "       4.75221893e-02, 4.80769231e-02, 4.80769231e-02, 4.84467456e-02,\n",
            "       4.84467456e-02, 4.86316568e-02, 4.86316568e-02, 4.89090237e-02,\n",
            "       4.89090237e-02, 4.94637574e-02, 4.94637574e-02, 4.99260355e-02,\n",
            "       4.99260355e-02, 5.03883136e-02, 5.03883136e-02, 5.07581361e-02,\n",
            "       5.07581361e-02, 5.08505917e-02, 5.08505917e-02, 5.09430473e-02,\n",
            "       5.09430473e-02, 5.11279586e-02, 5.11279586e-02, 5.14977811e-02,\n",
            "       5.14977811e-02, 5.28846154e-02, 5.28846154e-02, 5.33468935e-02,\n",
            "       5.33468935e-02, 5.37167160e-02, 5.37167160e-02, 5.42714497e-02,\n",
            "       5.42714497e-02, 5.45488166e-02, 5.45488166e-02, 5.50110947e-02,\n",
            "       5.50110947e-02, 5.55658284e-02, 5.55658284e-02, 5.58431953e-02,\n",
            "       5.58431953e-02, 5.59356509e-02, 5.59356509e-02, 5.61205621e-02,\n",
            "       5.61205621e-02, 5.63979290e-02, 5.63979290e-02, 5.68602071e-02,\n",
            "       5.68602071e-02, 5.70451183e-02, 5.70451183e-02, 5.80621302e-02,\n",
            "       5.80621302e-02, 5.85244083e-02, 5.85244083e-02, 5.95414201e-02,\n",
            "       5.95414201e-02, 5.98187870e-02, 5.98187870e-02, 6.10207101e-02,\n",
            "       6.10207101e-02, 6.14829882e-02, 6.14829882e-02, 6.16678994e-02,\n",
            "       6.16678994e-02, 6.18528107e-02, 6.18528107e-02, 6.22226331e-02,\n",
            "       6.22226331e-02, 6.26849112e-02, 6.26849112e-02, 6.28698225e-02,\n",
            "       6.28698225e-02, 6.30547337e-02, 6.30547337e-02, 6.39792899e-02,\n",
            "       6.39792899e-02, 6.40717456e-02, 6.40717456e-02, 6.45340237e-02,\n",
            "       6.45340237e-02, 6.47189349e-02, 6.47189349e-02, 6.51812130e-02,\n",
            "       6.51812130e-02, 6.53661243e-02, 6.53661243e-02, 6.58284024e-02,\n",
            "       6.58284024e-02, 6.61057692e-02, 6.61057692e-02, 6.64755917e-02,\n",
            "       6.64755917e-02, 6.65680473e-02, 6.65680473e-02, 6.70303254e-02,\n",
            "       6.70303254e-02, 6.77699704e-02, 6.77699704e-02, 6.78624260e-02,\n",
            "       6.78624260e-02, 7.00813609e-02, 7.00813609e-02, 7.09134615e-02,\n",
            "       7.09134615e-02, 7.15606509e-02, 7.15606509e-02, 7.23927515e-02,\n",
            "       7.23927515e-02, 7.35022189e-02, 7.35022189e-02, 7.39644970e-02,\n",
            "       7.39644970e-02, 7.40569527e-02, 7.40569527e-02, 7.47965976e-02,\n",
            "       7.47965976e-02, 7.52588757e-02, 7.52588757e-02, 7.53513314e-02,\n",
            "       7.53513314e-02, 7.65532544e-02, 7.65532544e-02, 7.68306213e-02,\n",
            "       7.68306213e-02, 7.97892012e-02, 7.97892012e-02, 8.03439349e-02,\n",
            "       8.03439349e-02, 8.08986686e-02, 8.08986686e-02, 8.09911243e-02,\n",
            "       8.09911243e-02, 8.16383136e-02, 8.16383136e-02, 8.21005917e-02,\n",
            "       8.21005917e-02, 8.33025148e-02, 8.33025148e-02, 8.34874260e-02,\n",
            "       8.34874260e-02, 8.35798817e-02, 8.35798817e-02, 8.36723373e-02,\n",
            "       8.36723373e-02, 8.44119822e-02, 8.44119822e-02, 8.50591716e-02,\n",
            "       8.50591716e-02, 8.71856509e-02, 8.71856509e-02, 8.73705621e-02,\n",
            "       8.73705621e-02, 8.82026627e-02, 8.82026627e-02, 8.95894970e-02,\n",
            "       8.95894970e-02, 9.01442308e-02, 9.01442308e-02, 9.05140533e-02,\n",
            "       9.05140533e-02, 9.11612426e-02, 9.11612426e-02, 9.24556213e-02,\n",
            "       9.24556213e-02, 9.26405325e-02, 9.26405325e-02, 9.35650888e-02,\n",
            "       9.35650888e-02, 9.54142012e-02, 9.54142012e-02, 9.78180473e-02,\n",
            "       9.78180473e-02, 9.98520710e-02, 9.98520710e-02, 1.00406805e-01,\n",
            "       1.00406805e-01, 1.01793639e-01, 1.01793639e-01, 1.01978550e-01,\n",
            "       1.01978550e-01, 1.04382396e-01, 1.04382396e-01, 1.06601331e-01,\n",
            "       1.06601331e-01, 1.07895710e-01, 1.07895710e-01, 1.11316568e-01,\n",
            "       1.11316568e-01, 1.13535503e-01, 1.13535503e-01, 1.14922337e-01,\n",
            "       1.14922337e-01, 1.17141272e-01, 1.17141272e-01, 1.21764053e-01,\n",
            "       1.21764053e-01, 1.27681213e-01, 1.27681213e-01, 1.27773669e-01,\n",
            "       1.27773669e-01, 1.28605769e-01, 1.28605769e-01, 1.33968195e-01,\n",
            "       1.33968195e-01, 1.34892751e-01, 1.34892751e-01, 1.36094675e-01,\n",
            "       1.36094675e-01, 1.38406065e-01, 1.38406065e-01, 1.39885355e-01,\n",
            "       1.39885355e-01, 1.39977811e-01, 1.39977811e-01, 1.40532544e-01,\n",
            "       1.40532544e-01, 1.45894970e-01, 1.45894970e-01, 1.46172337e-01,\n",
            "       1.46172337e-01, 1.48576183e-01, 1.48576183e-01, 1.48668639e-01,\n",
            "       1.48668639e-01, 1.51534763e-01, 1.51534763e-01, 1.52551775e-01,\n",
            "       1.52551775e-01, 1.56989645e-01, 1.56989645e-01, 1.58746302e-01,\n",
            "       1.58746302e-01, 1.60687870e-01, 1.60687870e-01, 1.65495562e-01,\n",
            "       1.65495562e-01, 1.65865385e-01, 1.65865385e-01, 1.69656065e-01,\n",
            "       1.69656065e-01, 1.76775148e-01, 1.76775148e-01, 1.81860207e-01,\n",
            "       1.81860207e-01, 1.83524408e-01, 1.83524408e-01, 1.83986686e-01,\n",
            "       1.83986686e-01, 2.07193047e-01, 2.07193047e-01, 2.10521450e-01,\n",
            "       2.10521450e-01, 2.42326183e-01, 2.42326183e-01, 3.06397929e-01,\n",
            "       3.06397929e-01, 3.13609467e-01, 3.13609467e-01, 3.37463018e-01,\n",
            "       3.37463018e-01, 3.39404586e-01, 3.39404586e-01, 3.68897929e-01,\n",
            "       3.68897929e-01, 3.81749260e-01, 3.81749260e-01, 3.89053254e-01,\n",
            "       3.89053254e-01, 3.93676036e-01, 3.93676036e-01, 1.00000000e+00]),\n",
            "  4: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27729845e-05,\n",
            "       9.27729845e-05, 1.85545969e-04, 1.85545969e-04, 2.78318954e-04,\n",
            "       2.78318954e-04, 3.71091938e-04, 3.71091938e-04, 4.63864923e-04,\n",
            "       4.63864923e-04, 5.56637907e-04, 5.56637907e-04, 6.49410892e-04,\n",
            "       6.49410892e-04, 7.42183876e-04, 7.42183876e-04, 8.34956861e-04,\n",
            "       8.34956861e-04, 9.27729845e-04, 9.27729845e-04, 1.02050283e-03,\n",
            "       1.02050283e-03, 1.11327581e-03, 1.11327581e-03, 1.20604880e-03,\n",
            "       1.20604880e-03, 1.29882178e-03, 1.29882178e-03, 1.39159477e-03,\n",
            "       1.39159477e-03, 1.48436775e-03, 1.48436775e-03, 1.66991372e-03,\n",
            "       1.66991372e-03, 1.76268671e-03, 1.76268671e-03, 1.85545969e-03,\n",
            "       1.85545969e-03, 2.04100566e-03, 2.04100566e-03, 2.22655163e-03,\n",
            "       2.22655163e-03, 2.31932461e-03, 2.31932461e-03, 2.41209760e-03,\n",
            "       2.41209760e-03, 2.50487058e-03, 2.50487058e-03, 2.59764357e-03,\n",
            "       2.59764357e-03, 2.78318954e-03, 2.78318954e-03, 2.87596252e-03,\n",
            "       2.87596252e-03, 2.96873550e-03, 2.96873550e-03, 3.15428147e-03,\n",
            "       3.15428147e-03, 3.24705446e-03, 3.24705446e-03, 3.43260043e-03,\n",
            "       3.43260043e-03, 3.52537341e-03, 3.52537341e-03, 3.61814640e-03,\n",
            "       3.61814640e-03, 3.71091938e-03, 3.71091938e-03, 3.80369236e-03,\n",
            "       3.80369236e-03, 3.89646535e-03, 3.89646535e-03, 3.98923833e-03,\n",
            "       3.98923833e-03, 4.08201132e-03, 4.08201132e-03, 4.17478430e-03,\n",
            "       4.17478430e-03, 4.26755729e-03, 4.26755729e-03, 4.36033027e-03,\n",
            "       4.36033027e-03, 4.45310326e-03, 4.45310326e-03, 4.54587624e-03,\n",
            "       4.54587624e-03, 4.63864923e-03, 4.63864923e-03, 4.82419519e-03,\n",
            "       4.82419519e-03, 4.91696818e-03, 4.91696818e-03, 5.00974116e-03,\n",
            "       5.00974116e-03, 5.47360609e-03, 5.47360609e-03, 5.65915205e-03,\n",
            "       5.65915205e-03, 5.84469802e-03, 5.84469802e-03, 6.03024399e-03,\n",
            "       6.03024399e-03, 6.12301698e-03, 6.12301698e-03, 6.40133593e-03,\n",
            "       6.40133593e-03, 6.67965488e-03, 6.67965488e-03, 6.95797384e-03,\n",
            "       6.95797384e-03, 7.32906578e-03, 7.32906578e-03, 7.51461175e-03,\n",
            "       7.51461175e-03, 7.70015771e-03, 7.70015771e-03, 7.79293070e-03,\n",
            "       7.79293070e-03, 7.88570368e-03, 7.88570368e-03, 7.97847667e-03,\n",
            "       7.97847667e-03, 8.07124965e-03, 8.07124965e-03, 8.53511457e-03,\n",
            "       8.53511457e-03, 8.62788756e-03, 8.62788756e-03, 8.81343353e-03,\n",
            "       8.81343353e-03, 8.90620651e-03, 8.90620651e-03, 8.99897950e-03,\n",
            "       8.99897950e-03, 9.18452547e-03, 9.18452547e-03, 9.27729845e-03,\n",
            "       9.27729845e-03, 9.55561740e-03, 9.55561740e-03, 9.74116337e-03,\n",
            "       9.74116337e-03, 9.83393636e-03, 9.83393636e-03, 9.92670934e-03,\n",
            "       9.92670934e-03, 1.02978013e-02, 1.02978013e-02, 1.05761202e-02,\n",
            "       1.05761202e-02, 1.06688932e-02, 1.06688932e-02, 1.07616662e-02,\n",
            "       1.07616662e-02, 1.10399852e-02, 1.10399852e-02, 1.11327581e-02,\n",
            "       1.11327581e-02, 1.15038501e-02, 1.15038501e-02, 1.20604880e-02,\n",
            "       1.20604880e-02, 1.28954448e-02, 1.28954448e-02, 1.32665368e-02,\n",
            "       1.32665368e-02, 1.34520828e-02, 1.34520828e-02, 1.49364505e-02,\n",
            "       1.49364505e-02, 1.54930884e-02, 1.54930884e-02, 1.57714074e-02,\n",
            "       1.57714074e-02, 1.58641804e-02, 1.58641804e-02, 1.59569533e-02,\n",
            "       1.59569533e-02, 1.61424993e-02, 1.61424993e-02, 1.64208183e-02,\n",
            "       1.64208183e-02, 1.67919102e-02, 1.67919102e-02, 1.74413211e-02,\n",
            "       1.74413211e-02, 1.75340941e-02, 1.75340941e-02, 1.77196400e-02,\n",
            "       1.77196400e-02, 1.79979590e-02, 1.79979590e-02, 1.82762779e-02,\n",
            "       1.82762779e-02, 1.95750997e-02, 1.95750997e-02, 1.96678727e-02,\n",
            "       1.96678727e-02, 1.98534187e-02, 1.98534187e-02, 2.02245106e-02,\n",
            "       2.02245106e-02, 2.03172836e-02, 2.03172836e-02, 2.12450135e-02,\n",
            "       2.12450135e-02, 2.19871973e-02, 2.19871973e-02, 2.25438352e-02,\n",
            "       2.25438352e-02, 2.28221542e-02, 2.28221542e-02, 2.29149272e-02,\n",
            "       2.29149272e-02, 2.31932461e-02, 2.31932461e-02, 2.42137490e-02,\n",
            "       2.42137490e-02, 2.63475276e-02, 2.63475276e-02, 2.66258466e-02,\n",
            "       2.66258466e-02, 2.67186195e-02, 2.67186195e-02, 2.69041655e-02,\n",
            "       2.69041655e-02, 3.20994526e-02, 3.20994526e-02, 3.23777716e-02,\n",
            "       3.23777716e-02, 3.30271825e-02, 3.30271825e-02, 3.42332313e-02,\n",
            "       3.42332313e-02, 3.66453289e-02, 3.66453289e-02, 3.67381019e-02,\n",
            "       3.67381019e-02, 3.78513777e-02, 3.78513777e-02, 3.82224696e-02,\n",
            "       3.82224696e-02, 3.88718805e-02, 3.88718805e-02, 4.91696818e-02,\n",
            "       4.91696818e-02, 5.13034604e-02, 5.13034604e-02, 5.34372391e-02,\n",
            "       5.34372391e-02, 5.84469802e-02, 5.84469802e-02, 6.19723537e-02,\n",
            "       6.19723537e-02, 6.25289916e-02, 6.25289916e-02, 6.33639484e-02,\n",
            "       6.33639484e-02, 6.45699972e-02, 6.45699972e-02, 6.86520085e-02,\n",
            "       6.86520085e-02, 7.03219223e-02, 7.03219223e-02, 8.28462752e-02,\n",
            "       8.28462752e-02, 8.29390481e-02, 8.29390481e-02, 9.40718063e-02,\n",
            "       9.40718063e-02, 1.13461360e-01, 1.13461360e-01, 1.19120512e-01,\n",
            "       1.19120512e-01, 1.24779664e-01, 1.24779664e-01, 1.47416272e-01,\n",
            "       1.47416272e-01, 1.52611560e-01, 1.52611560e-01, 1.91483440e-01,\n",
            "       1.91483440e-01, 2.88060117e-01, 2.88060117e-01, 1.00000000e+00]),\n",
            "  5: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.24898261e-05,\n",
            "       9.24898261e-05, 1.84979652e-04, 1.84979652e-04, 2.77469478e-04,\n",
            "       2.77469478e-04, 3.69959304e-04, 3.69959304e-04, 4.62449131e-04,\n",
            "       4.62449131e-04, 5.54938957e-04, 5.54938957e-04, 6.47428783e-04,\n",
            "       6.47428783e-04, 7.39918609e-04, 7.39918609e-04, 8.32408435e-04,\n",
            "       8.32408435e-04, 9.24898261e-04, 9.24898261e-04, 1.01738809e-03,\n",
            "       1.01738809e-03, 1.20236774e-03, 1.20236774e-03, 1.38734739e-03,\n",
            "       1.38734739e-03, 1.47983722e-03, 1.47983722e-03, 1.57232704e-03,\n",
            "       1.57232704e-03, 1.66481687e-03, 1.66481687e-03, 1.75730670e-03,\n",
            "       1.75730670e-03, 1.84979652e-03, 1.84979652e-03, 2.03477617e-03,\n",
            "       2.03477617e-03, 2.21975583e-03, 2.21975583e-03, 2.40473548e-03,\n",
            "       2.40473548e-03, 2.49722531e-03, 2.49722531e-03, 2.58971513e-03,\n",
            "       2.58971513e-03, 2.68220496e-03, 2.68220496e-03, 2.77469478e-03,\n",
            "       2.77469478e-03, 2.86718461e-03, 2.86718461e-03, 2.95967444e-03,\n",
            "       2.95967444e-03, 3.05216426e-03, 3.05216426e-03, 3.23714391e-03,\n",
            "       3.23714391e-03, 3.32963374e-03, 3.32963374e-03, 3.60710322e-03,\n",
            "       3.60710322e-03, 3.69959304e-03, 3.69959304e-03, 3.88457270e-03,\n",
            "       3.88457270e-03, 3.97706252e-03, 3.97706252e-03, 4.06955235e-03,\n",
            "       4.06955235e-03, 4.25453200e-03, 4.25453200e-03, 4.34702183e-03,\n",
            "       4.34702183e-03, 4.62449131e-03, 4.62449131e-03, 4.71698113e-03,\n",
            "       4.71698113e-03, 4.80947096e-03, 4.80947096e-03, 4.90196078e-03,\n",
            "       4.90196078e-03, 5.08694044e-03, 5.08694044e-03, 5.17943026e-03,\n",
            "       5.17943026e-03, 5.27192009e-03, 5.27192009e-03, 5.64187939e-03,\n",
            "       5.64187939e-03, 5.82685905e-03, 5.82685905e-03, 6.19681835e-03,\n",
            "       6.19681835e-03, 6.28930818e-03, 6.28930818e-03, 6.47428783e-03,\n",
            "       6.47428783e-03, 6.65926748e-03, 6.65926748e-03, 7.02922679e-03,\n",
            "       7.02922679e-03, 7.58416574e-03, 7.58416574e-03, 7.76914539e-03,\n",
            "       7.76914539e-03, 7.86163522e-03, 7.86163522e-03, 8.41657418e-03,\n",
            "       8.41657418e-03, 8.78653348e-03, 8.78653348e-03, 9.06400296e-03,\n",
            "       9.06400296e-03, 9.52645209e-03, 9.52645209e-03, 1.05438402e-02,\n",
            "       1.05438402e-02, 1.07288198e-02, 1.07288198e-02, 1.09137995e-02,\n",
            "       1.09137995e-02, 1.11912690e-02, 1.11912690e-02, 1.14687384e-02,\n",
            "       1.14687384e-02, 1.16537181e-02, 1.16537181e-02, 1.20236774e-02,\n",
            "       1.20236774e-02, 1.21161672e-02, 1.21161672e-02, 1.33185350e-02,\n",
            "       1.33185350e-02, 1.36884943e-02, 1.36884943e-02, 1.37809841e-02,\n",
            "       1.37809841e-02, 1.38734739e-02, 1.38734739e-02, 1.39659637e-02,\n",
            "       1.39659637e-02, 1.43359230e-02, 1.43359230e-02, 1.53533111e-02,\n",
            "       1.53533111e-02, 1.56307806e-02, 1.56307806e-02, 1.59082501e-02,\n",
            "       1.59082501e-02, 1.60007399e-02, 1.60007399e-02, 1.72955975e-02,\n",
            "       1.72955975e-02, 1.87754347e-02, 1.87754347e-02, 1.88679245e-02,\n",
            "       1.88679245e-02, 1.91453940e-02, 1.91453940e-02, 2.06252312e-02,\n",
            "       2.06252312e-02, 2.10876804e-02, 2.10876804e-02, 2.20125786e-02,\n",
            "       2.20125786e-02, 2.35849057e-02, 2.35849057e-02, 2.59896411e-02,\n",
            "       2.59896411e-02, 3.93081761e-02, 3.93081761e-02, 4.43951165e-02,\n",
            "       4.43951165e-02, 5.48464669e-02, 5.48464669e-02, 5.91009989e-02,\n",
            "       5.91009989e-02, 6.38179800e-02, 6.38179800e-02, 1.21531632e-01,\n",
            "       1.21531632e-01, 1.44839068e-01, 1.44839068e-01, 1.00000000e+00]),\n",
            "  6: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.23275782e-05,\n",
            "       9.23275782e-05, 1.84655156e-04, 1.84655156e-04, 2.76982735e-04,\n",
            "       2.76982735e-04, 3.69310313e-04, 3.69310313e-04, 4.61637891e-04,\n",
            "       4.61637891e-04, 5.53965469e-04, 5.53965469e-04, 6.46293048e-04,\n",
            "       6.46293048e-04, 8.30948204e-04, 8.30948204e-04, 9.23275782e-04,\n",
            "       9.23275782e-04, 1.01560336e-03, 1.01560336e-03, 1.10793094e-03,\n",
            "       1.10793094e-03, 1.20025852e-03, 1.20025852e-03, 1.29258610e-03,\n",
            "       1.29258610e-03, 1.38491367e-03, 1.38491367e-03, 1.47724125e-03,\n",
            "       1.47724125e-03, 1.56956883e-03, 1.56956883e-03, 1.66189641e-03,\n",
            "       1.66189641e-03, 1.75422399e-03, 1.75422399e-03, 1.84655156e-03,\n",
            "       1.84655156e-03, 1.93887914e-03, 1.93887914e-03, 2.03120672e-03,\n",
            "       2.03120672e-03, 2.12353430e-03, 2.12353430e-03, 2.21586188e-03,\n",
            "       2.21586188e-03, 2.30818946e-03, 2.30818946e-03, 2.40051703e-03,\n",
            "       2.40051703e-03, 2.49284461e-03, 2.49284461e-03, 2.58517219e-03,\n",
            "       2.58517219e-03, 2.67749977e-03, 2.67749977e-03, 2.76982735e-03,\n",
            "       2.76982735e-03, 2.86215493e-03, 2.86215493e-03, 2.95448250e-03,\n",
            "       2.95448250e-03, 3.04681008e-03, 3.04681008e-03, 3.23146524e-03,\n",
            "       3.23146524e-03, 3.32379282e-03, 3.32379282e-03, 3.41612040e-03,\n",
            "       3.41612040e-03, 3.50844797e-03, 3.50844797e-03, 3.60077555e-03,\n",
            "       3.60077555e-03, 3.69310313e-03, 3.69310313e-03, 3.78543071e-03,\n",
            "       3.78543071e-03, 3.87775829e-03, 3.87775829e-03, 3.97008586e-03,\n",
            "       3.97008586e-03, 4.15474102e-03, 4.15474102e-03, 4.24706860e-03,\n",
            "       4.24706860e-03, 4.33939618e-03, 4.33939618e-03, 4.43172376e-03,\n",
            "       4.43172376e-03, 4.52405133e-03, 4.52405133e-03, 4.61637891e-03,\n",
            "       4.61637891e-03, 4.80103407e-03, 4.80103407e-03, 4.89336165e-03,\n",
            "       4.89336165e-03, 4.98568923e-03, 4.98568923e-03, 5.07801680e-03,\n",
            "       5.07801680e-03, 5.17034438e-03, 5.17034438e-03, 5.35499954e-03,\n",
            "       5.35499954e-03, 5.44732712e-03, 5.44732712e-03, 5.53965469e-03,\n",
            "       5.53965469e-03, 5.63198227e-03, 5.63198227e-03, 5.72430985e-03,\n",
            "       5.72430985e-03, 5.81663743e-03, 5.81663743e-03, 5.90896501e-03,\n",
            "       5.90896501e-03, 6.00129259e-03, 6.00129259e-03, 6.18594774e-03,\n",
            "       6.18594774e-03, 6.37060290e-03, 6.37060290e-03, 6.46293048e-03,\n",
            "       6.46293048e-03, 6.55525806e-03, 6.55525806e-03, 6.64758563e-03,\n",
            "       6.64758563e-03, 6.73991321e-03, 6.73991321e-03, 6.92456837e-03,\n",
            "       6.92456837e-03, 7.01689595e-03, 7.01689595e-03, 7.20155110e-03,\n",
            "       7.20155110e-03, 7.29387868e-03, 7.29387868e-03, 7.47853384e-03,\n",
            "       7.47853384e-03, 7.66318899e-03, 7.66318899e-03, 7.75551657e-03,\n",
            "       7.75551657e-03, 7.84784415e-03, 7.84784415e-03, 7.94017173e-03,\n",
            "       7.94017173e-03, 8.12482689e-03, 8.12482689e-03, 8.21715446e-03,\n",
            "       8.21715446e-03, 8.30948204e-03, 8.30948204e-03, 8.40180962e-03,\n",
            "       8.40180962e-03, 8.49413720e-03, 8.49413720e-03, 8.58646478e-03,\n",
            "       8.58646478e-03, 8.77111993e-03, 8.77111993e-03, 8.86344751e-03,\n",
            "       8.86344751e-03, 9.32508540e-03, 9.32508540e-03, 9.41741298e-03,\n",
            "       9.41741298e-03, 9.50974056e-03, 9.50974056e-03, 9.69439572e-03,\n",
            "       9.69439572e-03, 9.78672329e-03, 9.78672329e-03, 9.97137845e-03,\n",
            "       9.97137845e-03, 1.02483612e-02, 1.02483612e-02, 1.03406888e-02,\n",
            "       1.03406888e-02, 1.04330163e-02, 1.04330163e-02, 1.06176715e-02,\n",
            "       1.06176715e-02, 1.07099991e-02, 1.07099991e-02, 1.08023267e-02,\n",
            "       1.08023267e-02, 1.08946542e-02, 1.08946542e-02, 1.09869818e-02,\n",
            "       1.09869818e-02, 1.10793094e-02, 1.10793094e-02, 1.11716370e-02,\n",
            "       1.11716370e-02, 1.13562921e-02, 1.13562921e-02, 1.15409473e-02,\n",
            "       1.15409473e-02, 1.17256024e-02, 1.17256024e-02, 1.18179300e-02,\n",
            "       1.18179300e-02, 1.19102576e-02, 1.19102576e-02, 1.20025852e-02,\n",
            "       1.20025852e-02, 1.22795679e-02, 1.22795679e-02, 1.23718955e-02,\n",
            "       1.23718955e-02, 1.26488782e-02, 1.26488782e-02, 1.28335334e-02,\n",
            "       1.28335334e-02, 1.30181885e-02, 1.30181885e-02, 1.32951713e-02,\n",
            "       1.32951713e-02, 1.35721540e-02, 1.35721540e-02, 1.36644816e-02,\n",
            "       1.36644816e-02, 1.37568092e-02, 1.37568092e-02, 1.43107746e-02,\n",
            "       1.43107746e-02, 1.48647401e-02, 1.48647401e-02, 1.49570677e-02,\n",
            "       1.49570677e-02, 1.50493953e-02, 1.50493953e-02, 1.51417228e-02,\n",
            "       1.51417228e-02, 1.53263780e-02, 1.53263780e-02, 1.58803435e-02,\n",
            "       1.58803435e-02, 1.59726710e-02, 1.59726710e-02, 1.67112917e-02,\n",
            "       1.67112917e-02, 1.68959468e-02, 1.68959468e-02, 1.74499123e-02,\n",
            "       1.74499123e-02, 1.77268950e-02, 1.77268950e-02, 1.84655156e-02,\n",
            "       1.84655156e-02, 1.85578432e-02, 1.85578432e-02, 1.86501708e-02,\n",
            "       1.86501708e-02, 1.87424984e-02, 1.87424984e-02, 1.88348260e-02,\n",
            "       1.88348260e-02, 1.90194811e-02, 1.90194811e-02, 1.92041363e-02,\n",
            "       1.92041363e-02, 1.93887914e-02, 1.93887914e-02, 1.95734466e-02,\n",
            "       1.95734466e-02, 1.96657742e-02, 1.96657742e-02, 1.98504293e-02,\n",
            "       1.98504293e-02, 2.00350845e-02, 2.00350845e-02, 2.03120672e-02,\n",
            "       2.03120672e-02, 2.06813775e-02, 2.06813775e-02, 2.07737051e-02,\n",
            "       2.07737051e-02, 2.14199982e-02, 2.14199982e-02, 2.15123257e-02,\n",
            "       2.15123257e-02, 2.16969809e-02, 2.16969809e-02, 2.21586188e-02,\n",
            "       2.21586188e-02, 2.26202567e-02, 2.26202567e-02, 2.30818946e-02,\n",
            "       2.30818946e-02, 2.41898255e-02, 2.41898255e-02, 2.43744807e-02,\n",
            "       2.43744807e-02, 2.45591358e-02, 2.45591358e-02, 2.49284461e-02,\n",
            "       2.49284461e-02, 2.53900840e-02, 2.53900840e-02, 2.55747392e-02,\n",
            "       2.55747392e-02, 2.65903425e-02, 2.65903425e-02, 2.69596528e-02,\n",
            "       2.69596528e-02, 2.71443080e-02, 2.71443080e-02, 2.75136183e-02,\n",
            "       2.75136183e-02, 2.76982735e-02, 2.76982735e-02, 2.78829286e-02,\n",
            "       2.78829286e-02, 2.81599114e-02, 2.81599114e-02, 2.82522389e-02,\n",
            "       2.82522389e-02, 2.86215493e-02, 2.86215493e-02, 2.87138768e-02,\n",
            "       2.87138768e-02, 2.88985320e-02, 2.88985320e-02, 2.90831871e-02,\n",
            "       2.90831871e-02, 2.92678423e-02, 2.92678423e-02, 2.94524975e-02,\n",
            "       2.94524975e-02, 2.98218078e-02, 2.98218078e-02, 3.00064629e-02,\n",
            "       3.00064629e-02, 3.08374111e-02, 3.08374111e-02, 3.11143939e-02,\n",
            "       3.11143939e-02, 3.12067214e-02, 3.12067214e-02, 3.22223248e-02,\n",
            "       3.22223248e-02, 3.26839627e-02, 3.26839627e-02, 3.27762903e-02,\n",
            "       3.27762903e-02, 3.30532730e-02, 3.30532730e-02, 3.32379282e-02,\n",
            "       3.32379282e-02, 3.35149109e-02, 3.35149109e-02, 3.37918936e-02,\n",
            "       3.37918936e-02, 3.38842212e-02, 3.38842212e-02, 3.41612040e-02,\n",
            "       3.41612040e-02, 3.47151694e-02, 3.47151694e-02, 3.53614625e-02,\n",
            "       3.53614625e-02, 3.63770658e-02, 3.63770658e-02, 3.65617210e-02,\n",
            "       3.65617210e-02, 3.67463761e-02, 3.67463761e-02, 3.68387037e-02,\n",
            "       3.68387037e-02, 3.77619795e-02, 3.77619795e-02, 3.81312898e-02,\n",
            "       3.81312898e-02, 3.97931862e-02, 3.97931862e-02, 4.00701690e-02,\n",
            "       4.00701690e-02, 4.01624965e-02, 4.01624965e-02, 4.08087896e-02,\n",
            "       4.08087896e-02, 4.31169790e-02, 4.31169790e-02, 4.46865479e-02,\n",
            "       4.46865479e-02, 4.48712030e-02, 4.48712030e-02, 4.49635306e-02,\n",
            "       4.49635306e-02, 4.80103407e-02, 4.80103407e-02, 4.86566337e-02,\n",
            "       4.86566337e-02, 5.17957714e-02, 5.17957714e-02, 5.47502539e-02,\n",
            "       5.47502539e-02, 5.49349091e-02, 5.49349091e-02, 5.81663743e-02,\n",
            "       5.81663743e-02, 5.85356846e-02, 5.85356846e-02, 5.94589604e-02,\n",
            "       5.94589604e-02, 6.21364602e-02, 6.21364602e-02, 6.30597359e-02,\n",
            "       6.30597359e-02, 6.37983566e-02, 6.37983566e-02, 6.58295633e-02,\n",
            "       6.58295633e-02, 6.80454252e-02, 6.80454252e-02, 7.15538731e-02,\n",
            "       7.15538731e-02, 7.44160281e-02, 7.44160281e-02, 7.80168036e-02,\n",
            "       7.80168036e-02, 8.13405964e-02, 8.13405964e-02, 8.41104238e-02,\n",
            "       8.41104238e-02, 8.46643893e-02, 8.46643893e-02, 8.81728372e-02,\n",
            "       8.81728372e-02, 9.17736128e-02, 9.17736128e-02, 1.02021974e-01,\n",
            "       1.02021974e-01, 1.02391284e-01, 1.02391284e-01, 1.02668267e-01,\n",
            "       1.02668267e-01, 1.06269043e-01, 1.06269043e-01, 1.08115594e-01,\n",
            "       1.08115594e-01, 1.09777491e-01, 1.09777491e-01, 1.18363955e-01,\n",
            "       1.18363955e-01, 1.24826886e-01, 1.24826886e-01, 1.29904903e-01,\n",
            "       1.29904903e-01, 1.32490075e-01, 1.32490075e-01, 1.34705937e-01,\n",
            "       1.34705937e-01, 1.43200074e-01, 1.43200074e-01, 1.48739729e-01,\n",
            "       1.48739729e-01, 1.49755332e-01, 1.49755332e-01, 1.50678608e-01,\n",
            "       1.50678608e-01, 1.53263780e-01, 1.53263780e-01, 1.77361278e-01,\n",
            "       1.77361278e-01, 1.83916536e-01, 1.83916536e-01, 1.84839812e-01,\n",
            "       1.84839812e-01, 2.16692826e-01, 2.16692826e-01, 2.19554981e-01,\n",
            "       2.19554981e-01, 3.89991691e-01, 3.89991691e-01, 1.00000000e+00]),\n",
            "  7: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27557740e-05,\n",
            "       9.27557740e-05, 1.85511548e-04, 1.85511548e-04, 2.78267322e-04,\n",
            "       2.78267322e-04, 4.63778870e-04, 4.63778870e-04, 5.56534644e-04,\n",
            "       5.56534644e-04, 6.49290418e-04, 6.49290418e-04, 7.42046192e-04,\n",
            "       7.42046192e-04, 8.34801966e-04, 8.34801966e-04, 9.27557740e-04,\n",
            "       9.27557740e-04, 1.02031351e-03, 1.02031351e-03, 1.11306929e-03,\n",
            "       1.11306929e-03, 1.20582506e-03, 1.20582506e-03, 1.29858084e-03,\n",
            "       1.29858084e-03, 1.39133661e-03, 1.39133661e-03, 1.48409238e-03,\n",
            "       1.48409238e-03, 1.57684816e-03, 1.57684816e-03, 1.66960393e-03,\n",
            "       1.66960393e-03, 1.76235971e-03, 1.76235971e-03, 1.85511548e-03,\n",
            "       1.85511548e-03, 1.94787125e-03, 1.94787125e-03, 2.04062703e-03,\n",
            "       2.04062703e-03, 2.13338280e-03, 2.13338280e-03, 2.22613858e-03,\n",
            "       2.22613858e-03, 2.31889435e-03, 2.31889435e-03, 2.41165013e-03,\n",
            "       2.41165013e-03, 2.59716167e-03, 2.59716167e-03, 2.78267322e-03,\n",
            "       2.78267322e-03, 2.87542900e-03, 2.87542900e-03, 3.06094054e-03,\n",
            "       3.06094054e-03, 3.15369632e-03, 3.15369632e-03, 3.24645209e-03,\n",
            "       3.24645209e-03, 3.33920787e-03, 3.33920787e-03, 3.43196364e-03,\n",
            "       3.43196364e-03, 3.52471941e-03, 3.52471941e-03, 3.61747519e-03,\n",
            "       3.61747519e-03, 3.71023096e-03, 3.71023096e-03, 3.80298674e-03,\n",
            "       3.80298674e-03, 3.89574251e-03, 3.89574251e-03, 3.98849828e-03,\n",
            "       3.98849828e-03, 4.08125406e-03, 4.08125406e-03, 4.17400983e-03,\n",
            "       4.17400983e-03, 4.26676561e-03, 4.26676561e-03, 4.35952138e-03,\n",
            "       4.35952138e-03, 4.45227715e-03, 4.45227715e-03, 4.54503293e-03,\n",
            "       4.54503293e-03, 4.82330025e-03, 4.82330025e-03, 5.00881180e-03,\n",
            "       5.00881180e-03, 5.10156757e-03, 5.10156757e-03, 5.19432335e-03,\n",
            "       5.19432335e-03, 5.28707912e-03, 5.28707912e-03, 5.37983489e-03,\n",
            "       5.37983489e-03, 5.56534644e-03, 5.56534644e-03, 5.65810222e-03,\n",
            "       5.65810222e-03, 5.75085799e-03, 5.75085799e-03, 6.12188109e-03,\n",
            "       6.12188109e-03, 6.21463686e-03, 6.21463686e-03, 6.30739264e-03,\n",
            "       6.30739264e-03, 6.40014841e-03, 6.40014841e-03, 6.49290418e-03,\n",
            "       6.49290418e-03, 6.77117151e-03, 6.77117151e-03, 6.86392728e-03,\n",
            "       6.86392728e-03, 7.04943883e-03, 7.04943883e-03, 7.23495038e-03,\n",
            "       7.23495038e-03, 7.32770615e-03, 7.32770615e-03, 7.51321770e-03,\n",
            "       7.51321770e-03, 7.69872925e-03, 7.69872925e-03, 7.79148502e-03,\n",
            "       7.79148502e-03, 7.88424079e-03, 7.88424079e-03, 7.97699657e-03,\n",
            "       7.97699657e-03, 8.06975234e-03, 8.06975234e-03, 8.16250812e-03,\n",
            "       8.16250812e-03, 8.25526389e-03, 8.25526389e-03, 8.53353121e-03,\n",
            "       8.53353121e-03, 8.62628699e-03, 8.62628699e-03, 8.71904276e-03,\n",
            "       8.71904276e-03, 8.90455431e-03, 8.90455431e-03, 8.99731008e-03,\n",
            "       8.99731008e-03, 9.09006586e-03, 9.09006586e-03, 9.27557740e-03,\n",
            "       9.27557740e-03, 9.36833318e-03, 9.36833318e-03, 9.46108895e-03,\n",
            "       9.46108895e-03, 9.64660050e-03, 9.64660050e-03, 9.73935627e-03,\n",
            "       9.73935627e-03, 9.92486782e-03, 9.92486782e-03, 1.02958909e-02,\n",
            "       1.02958909e-02, 1.04814025e-02, 1.04814025e-02, 1.09451813e-02,\n",
            "       1.09451813e-02, 1.11306929e-02, 1.11306929e-02, 1.13162044e-02,\n",
            "       1.13162044e-02, 1.16872275e-02, 1.16872275e-02, 1.17799833e-02,\n",
            "       1.17799833e-02, 1.18727391e-02, 1.18727391e-02, 1.19654949e-02,\n",
            "       1.19654949e-02, 1.21510064e-02, 1.21510064e-02, 1.25220295e-02,\n",
            "       1.25220295e-02, 1.28002968e-02, 1.28002968e-02, 1.29858084e-02,\n",
            "       1.29858084e-02, 1.30785641e-02, 1.30785641e-02, 1.32640757e-02,\n",
            "       1.32640757e-02, 1.36350988e-02, 1.36350988e-02, 1.37278546e-02,\n",
            "       1.37278546e-02, 1.43771450e-02, 1.43771450e-02, 1.45626565e-02,\n",
            "       1.45626565e-02, 1.46554123e-02, 1.46554123e-02, 1.51191912e-02,\n",
            "       1.51191912e-02, 1.52119469e-02, 1.52119469e-02, 1.53047027e-02,\n",
            "       1.53047027e-02, 1.55829700e-02, 1.55829700e-02, 1.61395047e-02,\n",
            "       1.61395047e-02, 1.62322605e-02, 1.62322605e-02, 1.63250162e-02,\n",
            "       1.63250162e-02, 1.65105278e-02, 1.65105278e-02, 1.66032836e-02,\n",
            "       1.66032836e-02, 1.67887951e-02, 1.67887951e-02, 1.69743067e-02,\n",
            "       1.69743067e-02, 1.71598182e-02, 1.71598182e-02, 1.74380855e-02,\n",
            "       1.74380855e-02, 1.79946202e-02, 1.79946202e-02, 1.83656433e-02,\n",
            "       1.83656433e-02, 1.84583990e-02, 1.84583990e-02, 1.85511548e-02,\n",
            "       1.85511548e-02, 1.88294221e-02, 1.88294221e-02, 1.90149337e-02,\n",
            "       1.90149337e-02, 1.91076895e-02, 1.91076895e-02, 1.92932010e-02,\n",
            "       1.92932010e-02, 1.94787125e-02, 1.94787125e-02, 1.95714683e-02,\n",
            "       1.95714683e-02, 1.98497356e-02, 1.98497356e-02, 1.99424914e-02,\n",
            "       1.99424914e-02, 2.00352472e-02, 2.00352472e-02, 2.01280030e-02,\n",
            "       2.01280030e-02, 2.02207587e-02, 2.02207587e-02, 2.08700492e-02,\n",
            "       2.08700492e-02, 2.09628049e-02, 2.09628049e-02, 2.13338280e-02,\n",
            "       2.13338280e-02, 2.15193396e-02, 2.15193396e-02, 2.17976069e-02,\n",
            "       2.17976069e-02, 2.20758742e-02, 2.20758742e-02, 2.22613858e-02,\n",
            "       2.22613858e-02, 2.25396531e-02, 2.25396531e-02, 2.26324089e-02,\n",
            "       2.26324089e-02, 2.27251646e-02, 2.27251646e-02, 2.28179204e-02,\n",
            "       2.28179204e-02, 2.29106762e-02, 2.29106762e-02, 2.31889435e-02,\n",
            "       2.31889435e-02, 2.33744551e-02, 2.33744551e-02, 2.35599666e-02,\n",
            "       2.35599666e-02, 2.39309897e-02, 2.39309897e-02, 2.40237455e-02,\n",
            "       2.40237455e-02, 2.41165013e-02, 2.41165013e-02, 2.45802801e-02,\n",
            "       2.45802801e-02, 2.46730359e-02, 2.46730359e-02, 2.47657917e-02,\n",
            "       2.47657917e-02, 2.50440590e-02, 2.50440590e-02, 2.57861052e-02,\n",
            "       2.57861052e-02, 2.58788610e-02, 2.58788610e-02, 2.63426398e-02,\n",
            "       2.63426398e-02, 2.67136629e-02, 2.67136629e-02, 2.71774418e-02,\n",
            "       2.71774418e-02, 2.83832669e-02, 2.83832669e-02, 2.85687784e-02,\n",
            "       2.85687784e-02, 2.91253131e-02, 2.91253131e-02, 2.92180688e-02,\n",
            "       2.92180688e-02, 2.97746035e-02, 2.97746035e-02, 2.98673592e-02,\n",
            "       2.98673592e-02, 3.00528708e-02, 3.00528708e-02, 3.02383823e-02,\n",
            "       3.02383823e-02, 3.13514516e-02, 3.13514516e-02, 3.14442074e-02,\n",
            "       3.14442074e-02, 3.16297190e-02, 3.16297190e-02, 3.20934978e-02,\n",
            "       3.20934978e-02, 3.22790094e-02, 3.22790094e-02, 3.25572767e-02,\n",
            "       3.25572767e-02, 3.49689268e-02, 3.49689268e-02, 3.60819961e-02,\n",
            "       3.60819961e-02, 3.62675077e-02, 3.62675077e-02, 3.64530192e-02,\n",
            "       3.64530192e-02, 3.73805769e-02, 3.73805769e-02, 3.81226231e-02,\n",
            "       3.81226231e-02, 3.98849828e-02, 3.98849828e-02, 4.01632502e-02,\n",
            "       4.01632502e-02, 4.17400983e-02, 4.17400983e-02, 4.19256099e-02,\n",
            "       4.19256099e-02, 4.26676561e-02, 4.26676561e-02, 4.42445042e-02,\n",
            "       4.42445042e-02, 4.43372600e-02, 4.43372600e-02, 4.44300158e-02,\n",
            "       4.44300158e-02, 4.48010389e-02, 4.48010389e-02, 4.57285966e-02,\n",
            "       4.57285966e-02, 4.68416659e-02, 4.68416659e-02, 4.77692236e-02,\n",
            "       4.77692236e-02, 4.86967814e-02, 4.86967814e-02, 4.91605602e-02,\n",
            "       4.91605602e-02, 4.99026064e-02, 4.99026064e-02, 5.04591411e-02,\n",
            "       5.04591411e-02, 5.30563028e-02, 5.30563028e-02, 5.34273259e-02,\n",
            "       5.34273259e-02, 5.50969298e-02, 5.50969298e-02, 5.66737779e-02,\n",
            "       5.66737779e-02, 5.83433819e-02, 5.83433819e-02, 5.90854281e-02,\n",
            "       5.90854281e-02, 6.01984974e-02, 6.01984974e-02, 6.05695205e-02,\n",
            "       6.05695205e-02, 6.09405435e-02, 6.09405435e-02, 6.11260551e-02,\n",
            "       6.11260551e-02, 6.57638438e-02, 6.57638438e-02, 6.72479362e-02,\n",
            "       6.72479362e-02, 6.82682497e-02, 6.82682497e-02, 7.03088767e-02,\n",
            "       7.03088767e-02, 7.05871440e-02, 7.05871440e-02, 7.07726556e-02,\n",
            "       7.07726556e-02, 7.27205269e-02, 7.27205269e-02, 7.29987942e-02,\n",
            "       7.29987942e-02, 7.50394212e-02, 7.50394212e-02, 7.53176885e-02,\n",
            "       7.53176885e-02, 7.55959558e-02, 7.55959558e-02, 7.74510713e-02,\n",
            "       7.74510713e-02, 7.92134310e-02, 7.92134310e-02, 8.00482330e-02,\n",
            "       8.00482330e-02, 8.11613023e-02, 8.11613023e-02, 8.45932659e-02,\n",
            "       8.45932659e-02, 8.53353121e-02, 8.53353121e-02, 8.94165662e-02,\n",
            "       8.94165662e-02, 9.23847510e-02, 9.23847510e-02, 1.01382061e-01,\n",
            "       1.01382061e-01, 1.01753084e-01, 1.01753084e-01, 1.16686764e-01,\n",
            "       1.16686764e-01, 1.20768018e-01, 1.20768018e-01, 1.20860774e-01,\n",
            "       1.20860774e-01, 1.35052407e-01, 1.35052407e-01, 1.36258232e-01,\n",
            "       1.36258232e-01, 1.39504684e-01, 1.39504684e-01, 1.39968463e-01,\n",
            "       1.39968463e-01, 1.44142473e-01, 1.44142473e-01, 1.48130971e-01,\n",
            "       1.48130971e-01, 1.53232539e-01, 1.53232539e-01, 1.54438364e-01,\n",
            "       1.54438364e-01, 1.68722753e-01, 1.68722753e-01, 1.70114090e-01,\n",
            "       1.70114090e-01, 1.84027456e-01, 1.84027456e-01, 1.87366664e-01,\n",
            "       1.87366664e-01, 1.94787125e-01, 1.94787125e-01, 1.99146647e-01,\n",
            "       1.99146647e-01, 2.25396531e-01, 2.25396531e-01, 2.41443280e-01,\n",
            "       2.41443280e-01, 2.70846860e-01, 2.70846860e-01, 1.00000000e+00]),\n",
            "  8: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.24727205e-05,\n",
            "       9.24727205e-05, 1.84945441e-04, 1.84945441e-04, 2.77418162e-04,\n",
            "       2.77418162e-04, 3.69890882e-04, 3.69890882e-04, 4.62363603e-04,\n",
            "       4.62363603e-04, 5.54836323e-04, 5.54836323e-04, 6.47309044e-04,\n",
            "       6.47309044e-04, 7.39781764e-04, 7.39781764e-04, 8.32254485e-04,\n",
            "       8.32254485e-04, 9.24727205e-04, 9.24727205e-04, 1.01719993e-03,\n",
            "       1.01719993e-03, 1.10967265e-03, 1.10967265e-03, 1.20214537e-03,\n",
            "       1.20214537e-03, 1.29461809e-03, 1.29461809e-03, 1.38709081e-03,\n",
            "       1.38709081e-03, 1.47956353e-03, 1.47956353e-03, 1.57203625e-03,\n",
            "       1.57203625e-03, 1.66450897e-03, 1.66450897e-03, 1.75698169e-03,\n",
            "       1.75698169e-03, 1.84945441e-03, 1.84945441e-03, 1.94192713e-03,\n",
            "       1.94192713e-03, 2.03439985e-03, 2.03439985e-03, 2.12687257e-03,\n",
            "       2.12687257e-03, 2.31181801e-03, 2.31181801e-03, 2.40429073e-03,\n",
            "       2.40429073e-03, 2.49676345e-03, 2.49676345e-03, 2.58923618e-03,\n",
            "       2.58923618e-03, 2.68170890e-03, 2.68170890e-03, 2.77418162e-03,\n",
            "       2.77418162e-03, 2.86665434e-03, 2.86665434e-03, 3.05159978e-03,\n",
            "       3.05159978e-03, 3.14407250e-03, 3.14407250e-03, 3.23654522e-03,\n",
            "       3.23654522e-03, 3.42149066e-03, 3.42149066e-03, 3.51396338e-03,\n",
            "       3.51396338e-03, 3.60643610e-03, 3.60643610e-03, 3.69890882e-03,\n",
            "       3.69890882e-03, 3.88385426e-03, 3.88385426e-03, 4.06879970e-03,\n",
            "       4.06879970e-03, 4.25374515e-03, 4.25374515e-03, 4.34621787e-03,\n",
            "       4.34621787e-03, 4.43869059e-03, 4.43869059e-03, 4.53116331e-03,\n",
            "       4.53116331e-03, 4.99352691e-03, 4.99352691e-03, 5.17847235e-03,\n",
            "       5.17847235e-03, 5.27094507e-03, 5.27094507e-03, 5.45589051e-03,\n",
            "       5.45589051e-03, 5.54836323e-03, 5.54836323e-03, 5.64083595e-03,\n",
            "       5.64083595e-03, 6.01072684e-03, 6.01072684e-03, 6.28814500e-03,\n",
            "       6.28814500e-03, 6.38061772e-03, 6.38061772e-03, 6.47309044e-03,\n",
            "       6.47309044e-03, 6.56556316e-03, 6.56556316e-03, 6.65803588e-03,\n",
            "       6.65803588e-03, 6.93545404e-03, 6.93545404e-03, 7.12039948e-03,\n",
            "       7.12039948e-03, 7.21287220e-03, 7.21287220e-03, 7.30534492e-03,\n",
            "       7.30534492e-03, 7.39781764e-03, 7.39781764e-03, 7.58276308e-03,\n",
            "       7.58276308e-03, 7.76770853e-03, 7.76770853e-03, 7.86018125e-03,\n",
            "       7.86018125e-03, 8.13759941e-03, 8.13759941e-03, 8.50749029e-03,\n",
            "       8.50749029e-03, 8.59996301e-03, 8.59996301e-03, 8.69243573e-03,\n",
            "       8.69243573e-03, 8.78490845e-03, 8.78490845e-03, 8.96985389e-03,\n",
            "       8.96985389e-03, 9.24727205e-03, 9.24727205e-03, 9.33974478e-03,\n",
            "       9.33974478e-03, 9.70963566e-03, 9.70963566e-03, 1.00795265e-02,\n",
            "       1.00795265e-02, 1.02644720e-02, 1.02644720e-02, 1.07268356e-02,\n",
            "       1.07268356e-02, 1.09117810e-02, 1.09117810e-02, 1.11891992e-02,\n",
            "       1.11891992e-02, 1.13741446e-02, 1.13741446e-02, 1.15590901e-02,\n",
            "       1.15590901e-02, 1.17440355e-02, 1.17440355e-02, 1.22063991e-02,\n",
            "       1.22063991e-02, 1.35934899e-02, 1.35934899e-02, 1.37784354e-02,\n",
            "       1.37784354e-02, 1.41483262e-02, 1.41483262e-02, 1.50730534e-02,\n",
            "       1.50730534e-02, 1.56278898e-02, 1.56278898e-02, 1.58128352e-02,\n",
            "       1.58128352e-02, 1.65526170e-02, 1.65526170e-02, 1.84020714e-02,\n",
            "       1.84020714e-02, 1.88644350e-02, 1.88644350e-02, 1.89569077e-02,\n",
            "       1.89569077e-02, 1.90493804e-02, 1.90493804e-02, 1.96042168e-02,\n",
            "       1.96042168e-02, 1.98816349e-02, 1.98816349e-02, 2.00665804e-02,\n",
            "       2.00665804e-02, 2.03439985e-02, 2.03439985e-02, 2.09913076e-02,\n",
            "       2.09913076e-02, 2.26558165e-02, 2.26558165e-02, 2.47826891e-02,\n",
            "       2.47826891e-02, 2.57074163e-02, 2.57074163e-02, 2.69095617e-02,\n",
            "       2.69095617e-02, 2.80192343e-02, 2.80192343e-02, 2.82966525e-02,\n",
            "       2.82966525e-02, 2.94987979e-02, 2.94987979e-02, 3.19955613e-02,\n",
            "       3.19955613e-02, 3.42149066e-02, 3.42149066e-02, 3.54170520e-02,\n",
            "       3.54170520e-02, 3.67116701e-02, 3.67116701e-02, 3.72665064e-02,\n",
            "       3.72665064e-02, 3.80987609e-02, 3.80987609e-02, 3.96707971e-02,\n",
            "       3.96707971e-02, 4.08729425e-02, 4.08729425e-02, 4.15202515e-02,\n",
            "       4.15202515e-02, 4.17051970e-02, 4.17051970e-02, 4.27223969e-02,\n",
            "       4.27223969e-02, 4.29998151e-02, 4.29998151e-02, 4.53116331e-02,\n",
            "       4.53116331e-02, 4.72535602e-02, 4.72535602e-02, 4.82707601e-02,\n",
            "       4.82707601e-02, 4.87331237e-02, 4.87331237e-02, 5.63158868e-02,\n",
            "       5.63158868e-02, 6.60255225e-02, 6.60255225e-02, 6.64878861e-02,\n",
            "       6.64878861e-02, 6.81523950e-02, 6.81523950e-02, 7.86018125e-02,\n",
            "       7.86018125e-02, 8.72017755e-02, 8.72017755e-02, 8.86813390e-02,\n",
            "       8.86813390e-02, 9.60791566e-02, 9.60791566e-02, 1.21231737e-01,\n",
            "       1.21231737e-01, 1.23358609e-01, 1.23358609e-01, 1.23636027e-01,\n",
            "       1.23636027e-01, 1.30848900e-01, 1.30848900e-01, 1.32790827e-01,\n",
            "       1.32790827e-01, 1.33438136e-01, 1.33438136e-01, 1.49713335e-01,\n",
            "       1.49713335e-01, 1.80599223e-01, 1.80599223e-01, 2.14444239e-01,\n",
            "       2.14444239e-01, 3.08304050e-01, 3.08304050e-01, 3.37155539e-01,\n",
            "       3.37155539e-01, 3.40299612e-01, 3.40299612e-01, 4.55428149e-01,\n",
            "       4.55428149e-01, 1.00000000e+00]),\n",
            "  9: array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.27127758e-05,\n",
            "       9.27127758e-05, 1.85425552e-04, 1.85425552e-04, 2.78138327e-04,\n",
            "       2.78138327e-04, 3.70851103e-04, 3.70851103e-04, 4.63563879e-04,\n",
            "       4.63563879e-04, 5.56276655e-04, 5.56276655e-04, 6.48989431e-04,\n",
            "       6.48989431e-04, 7.41702207e-04, 7.41702207e-04, 8.34414982e-04,\n",
            "       8.34414982e-04, 9.27127758e-04, 9.27127758e-04, 1.11255331e-03,\n",
            "       1.11255331e-03, 1.20526609e-03, 1.20526609e-03, 1.29797886e-03,\n",
            "       1.29797886e-03, 1.39069164e-03, 1.39069164e-03, 1.48340441e-03,\n",
            "       1.48340441e-03, 1.57611719e-03, 1.57611719e-03, 1.76154274e-03,\n",
            "       1.76154274e-03, 1.85425552e-03, 1.85425552e-03, 1.94696829e-03,\n",
            "       1.94696829e-03, 2.03968107e-03, 2.03968107e-03, 2.13239384e-03,\n",
            "       2.13239384e-03, 2.22510662e-03, 2.22510662e-03, 2.31781940e-03,\n",
            "       2.31781940e-03, 2.50324495e-03, 2.50324495e-03, 2.59595772e-03,\n",
            "       2.59595772e-03, 2.78138327e-03, 2.78138327e-03, 2.87409605e-03,\n",
            "       2.87409605e-03, 2.96680883e-03, 2.96680883e-03, 3.05952160e-03,\n",
            "       3.05952160e-03, 3.15223438e-03, 3.15223438e-03, 3.24494715e-03,\n",
            "       3.24494715e-03, 3.33765993e-03, 3.33765993e-03, 3.52308548e-03,\n",
            "       3.52308548e-03, 3.70851103e-03, 3.70851103e-03, 3.98664936e-03,\n",
            "       3.98664936e-03, 4.45021324e-03, 4.45021324e-03, 4.54292602e-03,\n",
            "       4.54292602e-03, 4.63563879e-03, 4.63563879e-03, 4.72835157e-03,\n",
            "       4.72835157e-03, 5.00648989e-03, 5.00648989e-03, 5.09920267e-03,\n",
            "       5.09920267e-03, 5.28462822e-03, 5.28462822e-03, 5.37734100e-03,\n",
            "       5.37734100e-03, 5.47005377e-03, 5.47005377e-03, 5.56276655e-03,\n",
            "       5.56276655e-03, 5.65547933e-03, 5.65547933e-03, 5.74819210e-03,\n",
            "       5.74819210e-03, 5.84090488e-03, 5.84090488e-03, 5.93361765e-03,\n",
            "       5.93361765e-03, 6.11904320e-03, 6.11904320e-03, 6.21175598e-03,\n",
            "       6.21175598e-03, 6.58260708e-03, 6.58260708e-03, 6.76803263e-03,\n",
            "       6.76803263e-03, 6.86074541e-03, 6.86074541e-03, 7.04617096e-03,\n",
            "       7.04617096e-03, 7.32430929e-03, 7.32430929e-03, 7.69516039e-03,\n",
            "       7.69516039e-03, 7.78787317e-03, 7.78787317e-03, 8.15872427e-03,\n",
            "       8.15872427e-03, 8.34414982e-03, 8.34414982e-03, 8.43686260e-03,\n",
            "       8.43686260e-03, 8.52957538e-03, 8.52957538e-03, 8.71500093e-03,\n",
            "       8.71500093e-03, 9.08585203e-03, 9.08585203e-03, 9.17856481e-03,\n",
            "       9.17856481e-03, 9.36399036e-03, 9.36399036e-03, 9.54941591e-03,\n",
            "       9.54941591e-03, 9.73484146e-03, 9.73484146e-03, 9.82755424e-03,\n",
            "       9.82755424e-03, 1.00129798e-02, 1.00129798e-02, 1.01056926e-02,\n",
            "       1.01056926e-02, 1.02911181e-02, 1.02911181e-02, 1.07546820e-02,\n",
            "       1.07546820e-02, 1.08473948e-02, 1.08473948e-02, 1.10328203e-02,\n",
            "       1.10328203e-02, 1.11255331e-02, 1.11255331e-02, 1.12182459e-02,\n",
            "       1.12182459e-02, 1.13109587e-02, 1.13109587e-02, 1.19599481e-02,\n",
            "       1.19599481e-02, 1.29797886e-02, 1.29797886e-02, 1.30725014e-02,\n",
            "       1.30725014e-02, 1.32579269e-02, 1.32579269e-02, 1.40923419e-02,\n",
            "       1.40923419e-02, 1.48340441e-02, 1.48340441e-02, 1.51121825e-02,\n",
            "       1.51121825e-02, 1.55757463e-02, 1.55757463e-02, 1.56684591e-02,\n",
            "       1.56684591e-02, 1.57611719e-02, 1.57611719e-02, 1.65028741e-02,\n",
            "       1.65028741e-02, 1.66882996e-02, 1.66882996e-02, 1.84498424e-02,\n",
            "       1.84498424e-02, 2.10458001e-02, 2.10458001e-02, 2.11385129e-02,\n",
            "       2.11385129e-02, 2.13239384e-02, 2.13239384e-02, 2.14166512e-02,\n",
            "       2.14166512e-02, 2.17875023e-02, 2.17875023e-02, 2.19729279e-02,\n",
            "       2.19729279e-02, 2.26219173e-02, 2.26219173e-02, 2.35490451e-02,\n",
            "       2.35490451e-02, 2.39198962e-02, 2.39198962e-02, 2.46615984e-02,\n",
            "       2.46615984e-02, 2.65158539e-02, 2.65158539e-02, 2.68867050e-02,\n",
            "       2.68867050e-02, 2.69794178e-02, 2.69794178e-02, 2.80919711e-02,\n",
            "       2.80919711e-02, 2.83701094e-02, 2.83701094e-02, 2.90190988e-02,\n",
            "       2.90190988e-02, 3.20786204e-02, 3.20786204e-02, 3.26348971e-02,\n",
            "       3.26348971e-02, 3.30984610e-02, 3.30984610e-02, 3.33765993e-02,\n",
            "       3.33765993e-02, 3.60652698e-02, 3.60652698e-02, 3.64361209e-02,\n",
            "       3.64361209e-02, 3.73632487e-02, 3.73632487e-02, 3.79195253e-02,\n",
            "       3.79195253e-02, 4.10717597e-02, 4.10717597e-02, 4.17207491e-02,\n",
            "       4.17207491e-02, 4.21843130e-02, 4.21843130e-02, 4.45021324e-02,\n",
            "       4.45021324e-02, 4.58001113e-02, 4.58001113e-02, 4.77470795e-02,\n",
            "       4.77470795e-02, 4.81179307e-02, 4.81179307e-02, 4.96940478e-02,\n",
            "       4.96940478e-02, 4.99721862e-02, 4.99721862e-02, 5.28462822e-02,\n",
            "       5.28462822e-02, 5.57203783e-02, 5.57203783e-02, 5.94288893e-02,\n",
            "       5.94288893e-02, 6.09122937e-02, 6.09122937e-02, 6.10977193e-02,\n",
            "       6.10977193e-02, 6.26738365e-02, 6.26738365e-02, 6.67531986e-02,\n",
            "       6.67531986e-02, 6.73094752e-02, 6.73094752e-02, 6.74949008e-02,\n",
            "       6.74949008e-02, 6.77730391e-02, 6.77730391e-02, 6.87001669e-02,\n",
            "       6.87001669e-02, 7.30576673e-02, 7.30576673e-02, 7.34285184e-02,\n",
            "       7.34285184e-02, 7.36139440e-02, 7.36139440e-02, 7.68588912e-02,\n",
            "       7.68588912e-02, 8.15872427e-02, 8.15872427e-02, 8.17726683e-02,\n",
            "       8.17726683e-02, 8.26997960e-02, 8.26997960e-02, 8.27925088e-02,\n",
            "       8.27925088e-02, 9.03949564e-02, 9.03949564e-02, 9.78119785e-02,\n",
            "       9.78119785e-02, 9.90172446e-02, 9.90172446e-02, 1.01242351e-01,\n",
            "       1.01242351e-01, 1.05414426e-01, 1.05414426e-01, 1.10699054e-01,\n",
            "       1.10699054e-01, 1.23864268e-01, 1.23864268e-01, 1.25533098e-01,\n",
            "       1.25533098e-01, 1.27294641e-01, 1.27294641e-01, 1.35916929e-01,\n",
            "       1.35916929e-01, 1.36658632e-01, 1.36658632e-01, 1.37771185e-01,\n",
            "       1.37771185e-01, 1.37956610e-01, 1.37956610e-01, 1.47969590e-01,\n",
            "       1.47969590e-01, 1.48896718e-01, 1.48896718e-01, 1.71889486e-01,\n",
            "       1.71889486e-01, 1.77544966e-01, 1.77544966e-01, 1.80511775e-01,\n",
            "       1.80511775e-01, 1.87928797e-01, 1.87928797e-01, 1.95623957e-01,\n",
            "       1.95623957e-01, 2.04338958e-01, 2.04338958e-01, 2.24272205e-01,\n",
            "       2.24272205e-01, 2.38549972e-01, 2.38549972e-01, 2.42165770e-01,\n",
            "       2.42165770e-01, 2.44112739e-01, 2.44112739e-01, 2.51344335e-01,\n",
            "       2.51344335e-01, 2.53476729e-01, 2.53476729e-01, 2.61542741e-01,\n",
            "       2.61542741e-01, 2.75171519e-01, 2.75171519e-01, 2.85462637e-01,\n",
            "       2.85462637e-01, 3.04283330e-01, 3.04283330e-01, 3.09567958e-01,\n",
            "       3.09567958e-01, 3.19766364e-01, 3.19766364e-01, 3.25050992e-01,\n",
            "       3.25050992e-01, 3.29779344e-01, 3.29779344e-01, 3.47487484e-01,\n",
            "       3.47487484e-01, 5.26979418e-01, 5.26979418e-01, 1.00000000e+00])},\n",
            " {0: array([0.00000000e+00, 8.49617672e-04, 2.82922685e-01, 2.82922685e-01,\n",
            "       3.29651657e-01, 3.29651657e-01, 4.93627867e-01, 4.93627867e-01,\n",
            "       5.12319456e-01, 5.12319456e-01, 5.28462192e-01, 5.28462192e-01,\n",
            "       5.65845370e-01, 5.65845370e-01, 5.76040782e-01, 5.76040782e-01,\n",
            "       5.99830076e-01, 5.99830076e-01, 6.06627018e-01, 6.06627018e-01,\n",
            "       6.09175871e-01, 6.09175871e-01, 6.21070518e-01, 6.21070518e-01,\n",
            "       6.31265930e-01, 6.31265930e-01, 6.41461342e-01, 6.41461342e-01,\n",
            "       6.55055225e-01, 6.55055225e-01, 6.55904843e-01, 6.55904843e-01,\n",
            "       6.74596432e-01, 6.74596432e-01, 6.81393373e-01, 6.81393373e-01,\n",
            "       6.83942226e-01, 6.83942226e-01, 6.84791844e-01, 6.84791844e-01,\n",
            "       6.87340697e-01, 6.87340697e-01, 6.94987256e-01, 6.94987256e-01,\n",
            "       6.99235344e-01, 6.99235344e-01, 7.00084962e-01, 7.00084962e-01,\n",
            "       7.05182668e-01, 7.05182668e-01, 7.17926933e-01, 7.17926933e-01,\n",
            "       7.18776551e-01, 7.18776551e-01, 7.19626168e-01, 7.19626168e-01,\n",
            "       7.23024639e-01, 7.23024639e-01, 7.34069669e-01, 7.34069669e-01,\n",
            "       7.34919286e-01, 7.34919286e-01, 7.39167375e-01, 7.39167375e-01,\n",
            "       7.42565845e-01, 7.42565845e-01, 7.43415463e-01, 7.43415463e-01,\n",
            "       7.45114698e-01, 7.45114698e-01, 7.47663551e-01, 7.47663551e-01,\n",
            "       7.51062022e-01, 7.51062022e-01, 7.52761257e-01, 7.52761257e-01,\n",
            "       7.56159728e-01, 7.56159728e-01, 7.57009346e-01, 7.57009346e-01,\n",
            "       7.57858963e-01, 7.57858963e-01, 7.65505523e-01, 7.65505523e-01,\n",
            "       7.68054376e-01, 7.68054376e-01, 7.68903993e-01, 7.68903993e-01,\n",
            "       7.71452846e-01, 7.71452846e-01, 7.73152082e-01, 7.73152082e-01,\n",
            "       7.74001699e-01, 7.74001699e-01, 7.74851317e-01, 7.74851317e-01,\n",
            "       7.75700935e-01, 7.75700935e-01, 7.76550552e-01, 7.76550552e-01,\n",
            "       7.79949023e-01, 7.79949023e-01, 7.81648258e-01, 7.81648258e-01,\n",
            "       7.85896347e-01, 7.85896347e-01, 7.86745964e-01, 7.86745964e-01,\n",
            "       7.87595582e-01, 7.87595582e-01, 7.90994053e-01, 7.90994053e-01,\n",
            "       7.91843670e-01, 7.91843670e-01, 7.92693288e-01, 7.92693288e-01,\n",
            "       7.96091759e-01, 7.96091759e-01, 7.96941376e-01, 7.96941376e-01,\n",
            "       7.97790994e-01, 7.97790994e-01, 8.01189465e-01, 8.01189465e-01,\n",
            "       8.08836024e-01, 8.08836024e-01, 8.09685641e-01, 8.09685641e-01,\n",
            "       8.11384877e-01, 8.11384877e-01, 8.13084112e-01, 8.13084112e-01,\n",
            "       8.16482583e-01, 8.16482583e-01, 8.19881054e-01, 8.19881054e-01,\n",
            "       8.23279524e-01, 8.23279524e-01, 8.24978760e-01, 8.24978760e-01,\n",
            "       8.28377230e-01, 8.28377230e-01, 8.30076466e-01, 8.30076466e-01,\n",
            "       8.31775701e-01, 8.31775701e-01, 8.33474936e-01, 8.33474936e-01,\n",
            "       8.35174172e-01, 8.35174172e-01, 8.36023789e-01, 8.36023789e-01,\n",
            "       8.36873407e-01, 8.36873407e-01, 8.40271878e-01, 8.40271878e-01,\n",
            "       8.41121495e-01, 8.41121495e-01, 8.43670348e-01, 8.43670348e-01,\n",
            "       8.44519966e-01, 8.44519966e-01, 8.45369584e-01, 8.45369584e-01,\n",
            "       8.46219201e-01, 8.46219201e-01, 8.50467290e-01, 8.50467290e-01,\n",
            "       8.53016143e-01, 8.53016143e-01, 8.54715378e-01, 8.54715378e-01,\n",
            "       8.56414613e-01, 8.56414613e-01, 8.58113849e-01, 8.58113849e-01,\n",
            "       8.59813084e-01, 8.59813084e-01, 8.61512319e-01, 8.61512319e-01,\n",
            "       8.62361937e-01, 8.62361937e-01, 8.64061172e-01, 8.64061172e-01,\n",
            "       8.64910790e-01, 8.64910790e-01, 8.65760408e-01, 8.65760408e-01,\n",
            "       8.66610025e-01, 8.66610025e-01, 8.67459643e-01, 8.67459643e-01,\n",
            "       8.68309261e-01, 8.68309261e-01, 8.69158879e-01, 8.69158879e-01,\n",
            "       8.70008496e-01, 8.70008496e-01, 8.70858114e-01, 8.70858114e-01,\n",
            "       8.71707732e-01, 8.71707732e-01, 8.73406967e-01, 8.73406967e-01,\n",
            "       8.74256585e-01, 8.74256585e-01, 8.75955820e-01, 8.75955820e-01,\n",
            "       8.76805438e-01, 8.76805438e-01, 8.77655055e-01, 8.77655055e-01,\n",
            "       8.78504673e-01, 8.78504673e-01, 8.79354291e-01, 8.79354291e-01,\n",
            "       8.80203908e-01, 8.80203908e-01, 8.81053526e-01, 8.81053526e-01,\n",
            "       8.81903144e-01, 8.81903144e-01, 8.82752761e-01, 8.82752761e-01,\n",
            "       8.83602379e-01, 8.83602379e-01, 8.84451997e-01, 8.84451997e-01,\n",
            "       8.85301614e-01, 8.85301614e-01, 8.86151232e-01, 8.86151232e-01,\n",
            "       8.87000850e-01, 8.87000850e-01, 8.88700085e-01, 8.88700085e-01,\n",
            "       8.89549703e-01, 8.89549703e-01, 8.92098556e-01, 8.92098556e-01,\n",
            "       8.92948173e-01, 8.92948173e-01, 8.93797791e-01, 8.93797791e-01,\n",
            "       8.94647409e-01, 8.94647409e-01, 8.95497026e-01, 8.95497026e-01,\n",
            "       8.96346644e-01, 8.96346644e-01, 8.98045879e-01, 8.98045879e-01,\n",
            "       8.98895497e-01, 8.98895497e-01, 9.00594732e-01, 9.00594732e-01,\n",
            "       9.01444350e-01, 9.01444350e-01, 9.02293968e-01, 9.02293968e-01,\n",
            "       9.03143585e-01, 9.03143585e-01, 9.03993203e-01, 9.03993203e-01,\n",
            "       9.05692438e-01, 9.05692438e-01, 9.06542056e-01, 9.06542056e-01,\n",
            "       9.08241291e-01, 9.08241291e-01, 9.09940527e-01, 9.09940527e-01,\n",
            "       9.10790144e-01, 9.10790144e-01, 9.11639762e-01, 9.11639762e-01,\n",
            "       9.12489380e-01, 9.12489380e-01, 9.13338997e-01, 9.13338997e-01,\n",
            "       9.14188615e-01, 9.14188615e-01, 9.15038233e-01, 9.15038233e-01,\n",
            "       9.15887850e-01, 9.15887850e-01, 9.16737468e-01, 9.16737468e-01,\n",
            "       9.18436703e-01, 9.18436703e-01, 9.19286321e-01, 9.19286321e-01,\n",
            "       9.20135939e-01, 9.20135939e-01, 9.20985556e-01, 9.20985556e-01,\n",
            "       9.21835174e-01, 9.21835174e-01, 9.22684792e-01, 9.22684792e-01,\n",
            "       9.23534410e-01, 9.23534410e-01, 9.24384027e-01, 9.24384027e-01,\n",
            "       9.25233645e-01, 9.25233645e-01, 9.26083263e-01, 9.26083263e-01,\n",
            "       9.26932880e-01, 9.26932880e-01, 9.27782498e-01, 9.27782498e-01,\n",
            "       9.29481733e-01, 9.29481733e-01, 9.32030586e-01, 9.32030586e-01,\n",
            "       9.32880204e-01, 9.32880204e-01, 9.33729822e-01, 9.33729822e-01,\n",
            "       9.36278675e-01, 9.36278675e-01, 9.37128292e-01, 9.37128292e-01,\n",
            "       9.37977910e-01, 9.37977910e-01, 9.38827528e-01, 9.38827528e-01,\n",
            "       9.39677145e-01, 9.39677145e-01, 9.40526763e-01, 9.40526763e-01,\n",
            "       9.41376381e-01, 9.41376381e-01, 9.42225998e-01, 9.42225998e-01,\n",
            "       9.43075616e-01, 9.43075616e-01, 9.43925234e-01, 9.43925234e-01,\n",
            "       9.44774851e-01, 9.44774851e-01, 9.45624469e-01, 9.45624469e-01,\n",
            "       9.46474087e-01, 9.46474087e-01, 9.47323704e-01, 9.47323704e-01,\n",
            "       9.48173322e-01, 9.48173322e-01, 9.49022940e-01, 9.49022940e-01,\n",
            "       9.49872557e-01, 9.49872557e-01, 9.51571793e-01, 9.51571793e-01,\n",
            "       9.52421410e-01, 9.52421410e-01, 9.53271028e-01, 9.53271028e-01,\n",
            "       9.54120646e-01, 9.54120646e-01, 9.54970263e-01, 9.54970263e-01,\n",
            "       9.55819881e-01, 9.55819881e-01, 9.56669499e-01, 9.56669499e-01,\n",
            "       9.57519116e-01, 9.57519116e-01, 9.58368734e-01, 9.58368734e-01,\n",
            "       9.59218352e-01, 9.59218352e-01, 9.60067969e-01, 9.60067969e-01,\n",
            "       9.60917587e-01, 9.60917587e-01, 9.61767205e-01, 9.61767205e-01,\n",
            "       9.62616822e-01, 9.62616822e-01, 9.63466440e-01, 9.63466440e-01,\n",
            "       9.64316058e-01, 9.64316058e-01, 9.65165675e-01, 9.65165675e-01,\n",
            "       9.66015293e-01, 9.66015293e-01, 9.66864911e-01, 9.66864911e-01,\n",
            "       9.67714528e-01, 9.67714528e-01, 9.68564146e-01, 9.68564146e-01,\n",
            "       9.69413764e-01, 9.69413764e-01, 9.70263381e-01, 9.70263381e-01,\n",
            "       9.71112999e-01, 9.71112999e-01, 9.71962617e-01, 9.71962617e-01,\n",
            "       9.72812234e-01, 9.72812234e-01, 9.73661852e-01, 9.73661852e-01,\n",
            "       9.74511470e-01, 9.74511470e-01, 9.75361088e-01, 9.75361088e-01,\n",
            "       9.76210705e-01, 9.76210705e-01, 9.77060323e-01, 9.77060323e-01,\n",
            "       9.77909941e-01, 9.77909941e-01, 9.78759558e-01, 9.78759558e-01,\n",
            "       9.79609176e-01, 9.79609176e-01, 9.80458794e-01, 9.80458794e-01,\n",
            "       9.81308411e-01, 9.81308411e-01, 9.82158029e-01, 9.82158029e-01,\n",
            "       9.83007647e-01, 9.83007647e-01, 9.83857264e-01, 9.83857264e-01,\n",
            "       9.84706882e-01, 9.84706882e-01, 9.85556500e-01, 9.85556500e-01,\n",
            "       9.86406117e-01, 9.86406117e-01, 9.87255735e-01, 9.87255735e-01,\n",
            "       9.88105353e-01, 9.88105353e-01, 9.88954970e-01, 9.88954970e-01,\n",
            "       9.89804588e-01, 9.89804588e-01, 9.90654206e-01, 9.90654206e-01,\n",
            "       9.91503823e-01, 9.91503823e-01, 9.92353441e-01, 9.92353441e-01,\n",
            "       9.93203059e-01, 9.93203059e-01, 9.94052676e-01, 9.94052676e-01,\n",
            "       9.94902294e-01, 9.94902294e-01, 9.95751912e-01, 9.95751912e-01,\n",
            "       9.96601529e-01, 9.96601529e-01, 9.97451147e-01, 9.97451147e-01,\n",
            "       9.98300765e-01, 9.98300765e-01, 9.99150382e-01, 9.99150382e-01,\n",
            "       1.00000000e+00, 1.00000000e+00]),\n",
            "  1: array([0.00000000e+00, 8.21018062e-04, 2.22495895e-01, 2.22495895e-01,\n",
            "       2.54515599e-01, 2.54515599e-01, 4.06403941e-01, 4.06403941e-01,\n",
            "       4.54022989e-01, 4.54022989e-01, 5.84564860e-01, 5.84564860e-01,\n",
            "       5.92775041e-01, 5.92775041e-01, 6.18226601e-01, 6.18226601e-01,\n",
            "       7.22495895e-01, 7.22495895e-01, 7.29064039e-01, 7.29064039e-01,\n",
            "       7.33169130e-01, 7.33169130e-01, 7.39737274e-01, 7.39737274e-01,\n",
            "       7.59441708e-01, 7.59441708e-01, 7.65188834e-01, 7.65188834e-01,\n",
            "       7.78325123e-01, 7.78325123e-01, 7.79146141e-01, 7.79146141e-01,\n",
            "       7.82430213e-01, 7.82430213e-01, 7.93103448e-01, 7.93103448e-01,\n",
            "       7.95566502e-01, 7.95566502e-01, 7.99671593e-01, 7.99671593e-01,\n",
            "       8.04597701e-01, 8.04597701e-01, 8.25944171e-01, 8.25944171e-01,\n",
            "       8.33333333e-01, 8.33333333e-01, 8.40722496e-01, 8.40722496e-01,\n",
            "       8.48111658e-01, 8.48111658e-01, 8.50574713e-01, 8.50574713e-01,\n",
            "       8.66174056e-01, 8.66174056e-01, 8.74384236e-01, 8.74384236e-01,\n",
            "       8.76847291e-01, 8.76847291e-01, 8.80952381e-01, 8.80952381e-01,\n",
            "       8.90804598e-01, 8.90804598e-01, 8.98193760e-01, 8.98193760e-01,\n",
            "       9.00656814e-01, 9.00656814e-01, 9.04761905e-01, 9.04761905e-01,\n",
            "       9.05582923e-01, 9.05582923e-01, 9.07224959e-01, 9.07224959e-01,\n",
            "       9.08866995e-01, 9.08866995e-01, 9.12151067e-01, 9.12151067e-01,\n",
            "       9.12972085e-01, 9.12972085e-01, 9.17898194e-01, 9.17898194e-01,\n",
            "       9.18719212e-01, 9.18719212e-01, 9.19540230e-01, 9.19540230e-01,\n",
            "       9.28571429e-01, 9.28571429e-01, 9.35139573e-01, 9.35139573e-01,\n",
            "       9.36781609e-01, 9.36781609e-01, 9.40886700e-01, 9.40886700e-01,\n",
            "       9.43349754e-01, 9.43349754e-01, 9.44170772e-01, 9.44170772e-01,\n",
            "       9.44991790e-01, 9.44991790e-01, 9.45812808e-01, 9.45812808e-01,\n",
            "       9.49096880e-01, 9.49096880e-01, 9.49917898e-01, 9.49917898e-01,\n",
            "       9.50738916e-01, 9.50738916e-01, 9.51559934e-01, 9.51559934e-01,\n",
            "       9.53201970e-01, 9.53201970e-01, 9.54022989e-01, 9.54022989e-01,\n",
            "       9.54844007e-01, 9.54844007e-01, 9.55665025e-01, 9.55665025e-01,\n",
            "       9.57307061e-01, 9.57307061e-01, 9.58128079e-01, 9.58128079e-01,\n",
            "       9.58949097e-01, 9.58949097e-01, 9.61412151e-01, 9.61412151e-01,\n",
            "       9.62233169e-01, 9.62233169e-01, 9.63054187e-01, 9.63054187e-01,\n",
            "       9.63875205e-01, 9.63875205e-01, 9.64696223e-01, 9.64696223e-01,\n",
            "       9.65517241e-01, 9.65517241e-01, 9.67159278e-01, 9.67159278e-01,\n",
            "       9.67980296e-01, 9.67980296e-01, 9.69622332e-01, 9.69622332e-01,\n",
            "       9.70443350e-01, 9.70443350e-01, 9.71264368e-01, 9.71264368e-01,\n",
            "       9.72085386e-01, 9.72085386e-01, 9.72906404e-01, 9.72906404e-01,\n",
            "       9.77011494e-01, 9.77011494e-01, 9.77832512e-01, 9.77832512e-01,\n",
            "       9.78653530e-01, 9.78653530e-01, 9.79474548e-01, 9.79474548e-01,\n",
            "       9.81116585e-01, 9.81116585e-01, 9.81937603e-01, 9.81937603e-01,\n",
            "       9.82758621e-01, 9.82758621e-01, 9.83579639e-01, 9.83579639e-01,\n",
            "       9.84400657e-01, 9.84400657e-01, 9.85221675e-01, 9.85221675e-01,\n",
            "       9.86042693e-01, 9.86042693e-01, 9.86863711e-01, 9.86863711e-01,\n",
            "       9.87684729e-01, 9.87684729e-01, 9.88505747e-01, 9.88505747e-01,\n",
            "       9.89326765e-01, 9.89326765e-01, 9.90147783e-01, 9.90147783e-01,\n",
            "       9.90968801e-01, 9.90968801e-01, 9.91789819e-01, 9.91789819e-01,\n",
            "       9.92610837e-01, 9.92610837e-01, 9.93431856e-01, 9.93431856e-01,\n",
            "       9.94252874e-01, 9.94252874e-01, 9.95073892e-01, 9.95073892e-01,\n",
            "       9.95894910e-01, 9.95894910e-01, 9.96715928e-01, 9.96715928e-01,\n",
            "       9.97536946e-01, 9.97536946e-01, 9.98357964e-01, 9.98357964e-01,\n",
            "       9.99178982e-01, 9.99178982e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  2: array([0.00000000e+00, 8.16993464e-04, 5.71895425e-03, 5.71895425e-03,\n",
            "       5.28594771e-01, 5.28594771e-01, 5.74346405e-01, 5.74346405e-01,\n",
            "       5.78431373e-01, 5.78431373e-01, 5.93137255e-01, 5.93137255e-01,\n",
            "       5.95588235e-01, 5.95588235e-01, 6.33986928e-01, 6.33986928e-01,\n",
            "       6.39705882e-01, 6.39705882e-01, 6.46241830e-01, 6.46241830e-01,\n",
            "       6.48692810e-01, 6.48692810e-01, 6.54411765e-01, 6.54411765e-01,\n",
            "       6.56862745e-01, 6.56862745e-01, 6.79738562e-01, 6.79738562e-01,\n",
            "       7.00980392e-01, 7.00980392e-01, 7.02614379e-01, 7.02614379e-01,\n",
            "       7.03431373e-01, 7.03431373e-01, 7.05065359e-01, 7.05065359e-01,\n",
            "       7.22222222e-01, 7.22222222e-01, 7.23039216e-01, 7.23039216e-01,\n",
            "       7.29575163e-01, 7.29575163e-01, 7.33660131e-01, 7.33660131e-01,\n",
            "       7.36111111e-01, 7.36111111e-01, 7.36928105e-01, 7.36928105e-01,\n",
            "       7.38562092e-01, 7.38562092e-01, 7.42647059e-01, 7.42647059e-01,\n",
            "       7.46732026e-01, 7.46732026e-01, 7.48366013e-01, 7.48366013e-01,\n",
            "       7.52450980e-01, 7.52450980e-01, 7.55718954e-01, 7.55718954e-01,\n",
            "       7.56535948e-01, 7.56535948e-01, 7.57352941e-01, 7.57352941e-01,\n",
            "       7.59803922e-01, 7.59803922e-01, 7.63888889e-01, 7.63888889e-01,\n",
            "       7.65522876e-01, 7.65522876e-01, 7.73692810e-01, 7.73692810e-01,\n",
            "       7.75326797e-01, 7.75326797e-01, 7.77777778e-01, 7.77777778e-01,\n",
            "       7.78594771e-01, 7.78594771e-01, 7.79411765e-01, 7.79411765e-01,\n",
            "       7.80228758e-01, 7.80228758e-01, 7.81045752e-01, 7.81045752e-01,\n",
            "       7.86764706e-01, 7.86764706e-01, 7.90849673e-01, 7.90849673e-01,\n",
            "       7.92483660e-01, 7.92483660e-01, 7.93300654e-01, 7.93300654e-01,\n",
            "       7.94934641e-01, 7.94934641e-01, 7.97385621e-01, 7.97385621e-01,\n",
            "       7.99019608e-01, 7.99019608e-01, 7.99836601e-01, 7.99836601e-01,\n",
            "       8.01470588e-01, 8.01470588e-01, 8.03104575e-01, 8.03104575e-01,\n",
            "       8.03921569e-01, 8.03921569e-01, 8.05555556e-01, 8.05555556e-01,\n",
            "       8.07189542e-01, 8.07189542e-01, 8.08006536e-01, 8.08006536e-01,\n",
            "       8.11274510e-01, 8.11274510e-01, 8.12908497e-01, 8.12908497e-01,\n",
            "       8.16176471e-01, 8.16176471e-01, 8.17810458e-01, 8.17810458e-01,\n",
            "       8.19444444e-01, 8.19444444e-01, 8.21078431e-01, 8.21078431e-01,\n",
            "       8.21895425e-01, 8.21895425e-01, 8.22712418e-01, 8.22712418e-01,\n",
            "       8.24346405e-01, 8.24346405e-01, 8.25163399e-01, 8.25163399e-01,\n",
            "       8.27614379e-01, 8.27614379e-01, 8.28431373e-01, 8.28431373e-01,\n",
            "       8.29248366e-01, 8.29248366e-01, 8.30882353e-01, 8.30882353e-01,\n",
            "       8.31699346e-01, 8.31699346e-01, 8.32516340e-01, 8.32516340e-01,\n",
            "       8.33333333e-01, 8.33333333e-01, 8.34967320e-01, 8.34967320e-01,\n",
            "       8.35784314e-01, 8.35784314e-01, 8.36601307e-01, 8.36601307e-01,\n",
            "       8.37418301e-01, 8.37418301e-01, 8.39869281e-01, 8.39869281e-01,\n",
            "       8.40686275e-01, 8.40686275e-01, 8.42320261e-01, 8.42320261e-01,\n",
            "       8.44771242e-01, 8.44771242e-01, 8.45588235e-01, 8.45588235e-01,\n",
            "       8.46405229e-01, 8.46405229e-01, 8.47222222e-01, 8.47222222e-01,\n",
            "       8.48039216e-01, 8.48039216e-01, 8.49673203e-01, 8.49673203e-01,\n",
            "       8.50490196e-01, 8.50490196e-01, 8.51307190e-01, 8.51307190e-01,\n",
            "       8.52124183e-01, 8.52124183e-01, 8.52941176e-01, 8.52941176e-01,\n",
            "       8.53758170e-01, 8.53758170e-01, 8.54575163e-01, 8.54575163e-01,\n",
            "       8.55392157e-01, 8.55392157e-01, 8.56209150e-01, 8.56209150e-01,\n",
            "       8.57026144e-01, 8.57026144e-01, 8.59477124e-01, 8.59477124e-01,\n",
            "       8.60294118e-01, 8.60294118e-01, 8.61111111e-01, 8.61111111e-01,\n",
            "       8.61928105e-01, 8.61928105e-01, 8.62745098e-01, 8.62745098e-01,\n",
            "       8.63562092e-01, 8.63562092e-01, 8.66013072e-01, 8.66013072e-01,\n",
            "       8.67647059e-01, 8.67647059e-01, 8.68464052e-01, 8.68464052e-01,\n",
            "       8.69281046e-01, 8.69281046e-01, 8.70098039e-01, 8.70098039e-01,\n",
            "       8.70915033e-01, 8.70915033e-01, 8.71732026e-01, 8.71732026e-01,\n",
            "       8.72549020e-01, 8.72549020e-01, 8.74183007e-01, 8.74183007e-01,\n",
            "       8.75000000e-01, 8.75000000e-01, 8.76633987e-01, 8.76633987e-01,\n",
            "       8.78267974e-01, 8.78267974e-01, 8.79084967e-01, 8.79084967e-01,\n",
            "       8.80718954e-01, 8.80718954e-01, 8.81535948e-01, 8.81535948e-01,\n",
            "       8.82352941e-01, 8.82352941e-01, 8.83169935e-01, 8.83169935e-01,\n",
            "       8.83986928e-01, 8.83986928e-01, 8.84803922e-01, 8.84803922e-01,\n",
            "       8.85620915e-01, 8.85620915e-01, 8.86437908e-01, 8.86437908e-01,\n",
            "       8.87254902e-01, 8.87254902e-01, 8.88071895e-01, 8.88071895e-01,\n",
            "       8.88888889e-01, 8.88888889e-01, 8.89705882e-01, 8.89705882e-01,\n",
            "       8.91339869e-01, 8.91339869e-01, 8.92156863e-01, 8.92156863e-01,\n",
            "       8.92973856e-01, 8.92973856e-01, 8.93790850e-01, 8.93790850e-01,\n",
            "       8.94607843e-01, 8.94607843e-01, 8.95424837e-01, 8.95424837e-01,\n",
            "       8.96241830e-01, 8.96241830e-01, 8.97875817e-01, 8.97875817e-01,\n",
            "       8.98692810e-01, 8.98692810e-01, 8.99509804e-01, 8.99509804e-01,\n",
            "       9.01143791e-01, 9.01143791e-01, 9.01960784e-01, 9.01960784e-01,\n",
            "       9.03594771e-01, 9.03594771e-01, 9.04411765e-01, 9.04411765e-01,\n",
            "       9.05228758e-01, 9.05228758e-01, 9.06862745e-01, 9.06862745e-01,\n",
            "       9.07679739e-01, 9.07679739e-01, 9.08496732e-01, 9.08496732e-01,\n",
            "       9.09313725e-01, 9.09313725e-01, 9.10130719e-01, 9.10130719e-01,\n",
            "       9.10947712e-01, 9.10947712e-01, 9.11764706e-01, 9.11764706e-01,\n",
            "       9.12581699e-01, 9.12581699e-01, 9.13398693e-01, 9.13398693e-01,\n",
            "       9.14215686e-01, 9.14215686e-01, 9.15032680e-01, 9.15032680e-01,\n",
            "       9.15849673e-01, 9.15849673e-01, 9.16666667e-01, 9.16666667e-01,\n",
            "       9.17483660e-01, 9.17483660e-01, 9.18300654e-01, 9.18300654e-01,\n",
            "       9.19117647e-01, 9.19117647e-01, 9.19934641e-01, 9.19934641e-01,\n",
            "       9.21568627e-01, 9.21568627e-01, 9.22385621e-01, 9.22385621e-01,\n",
            "       9.23202614e-01, 9.23202614e-01, 9.24019608e-01, 9.24019608e-01,\n",
            "       9.24836601e-01, 9.24836601e-01, 9.25653595e-01, 9.25653595e-01,\n",
            "       9.26470588e-01, 9.26470588e-01, 9.27287582e-01, 9.27287582e-01,\n",
            "       9.28104575e-01, 9.28104575e-01, 9.28921569e-01, 9.28921569e-01,\n",
            "       9.29738562e-01, 9.29738562e-01, 9.30555556e-01, 9.30555556e-01,\n",
            "       9.31372549e-01, 9.31372549e-01, 9.32189542e-01, 9.32189542e-01,\n",
            "       9.33006536e-01, 9.33006536e-01, 9.33823529e-01, 9.33823529e-01,\n",
            "       9.34640523e-01, 9.34640523e-01, 9.35457516e-01, 9.35457516e-01,\n",
            "       9.36274510e-01, 9.36274510e-01, 9.37091503e-01, 9.37091503e-01,\n",
            "       9.37908497e-01, 9.37908497e-01, 9.38725490e-01, 9.38725490e-01,\n",
            "       9.39542484e-01, 9.39542484e-01, 9.40359477e-01, 9.40359477e-01,\n",
            "       9.41176471e-01, 9.41176471e-01, 9.41993464e-01, 9.41993464e-01,\n",
            "       9.42810458e-01, 9.42810458e-01, 9.43627451e-01, 9.43627451e-01,\n",
            "       9.44444444e-01, 9.44444444e-01, 9.46078431e-01, 9.46078431e-01,\n",
            "       9.46895425e-01, 9.46895425e-01, 9.47712418e-01, 9.47712418e-01,\n",
            "       9.48529412e-01, 9.48529412e-01, 9.49346405e-01, 9.49346405e-01,\n",
            "       9.50163399e-01, 9.50163399e-01, 9.50980392e-01, 9.50980392e-01,\n",
            "       9.51797386e-01, 9.51797386e-01, 9.52614379e-01, 9.52614379e-01,\n",
            "       9.54248366e-01, 9.54248366e-01, 9.55065359e-01, 9.55065359e-01,\n",
            "       9.55882353e-01, 9.55882353e-01, 9.56699346e-01, 9.56699346e-01,\n",
            "       9.57516340e-01, 9.57516340e-01, 9.58333333e-01, 9.58333333e-01,\n",
            "       9.59150327e-01, 9.59150327e-01, 9.59967320e-01, 9.59967320e-01,\n",
            "       9.60784314e-01, 9.60784314e-01, 9.61601307e-01, 9.61601307e-01,\n",
            "       9.62418301e-01, 9.62418301e-01, 9.64052288e-01, 9.64052288e-01,\n",
            "       9.65686275e-01, 9.65686275e-01, 9.67320261e-01, 9.67320261e-01,\n",
            "       9.68137255e-01, 9.68137255e-01, 9.68954248e-01, 9.68954248e-01,\n",
            "       9.69771242e-01, 9.69771242e-01, 9.70588235e-01, 9.70588235e-01,\n",
            "       9.71405229e-01, 9.71405229e-01, 9.72222222e-01, 9.72222222e-01,\n",
            "       9.73039216e-01, 9.73039216e-01, 9.73856209e-01, 9.73856209e-01,\n",
            "       9.74673203e-01, 9.74673203e-01, 9.75490196e-01, 9.75490196e-01,\n",
            "       9.76307190e-01, 9.76307190e-01, 9.77124183e-01, 9.77124183e-01,\n",
            "       9.77941176e-01, 9.77941176e-01, 9.78758170e-01, 9.78758170e-01,\n",
            "       9.79575163e-01, 9.79575163e-01, 9.80392157e-01, 9.80392157e-01,\n",
            "       9.81209150e-01, 9.81209150e-01, 9.82026144e-01, 9.82026144e-01,\n",
            "       9.82843137e-01, 9.82843137e-01, 9.83660131e-01, 9.83660131e-01,\n",
            "       9.84477124e-01, 9.84477124e-01, 9.85294118e-01, 9.85294118e-01,\n",
            "       9.86111111e-01, 9.86111111e-01, 9.86928105e-01, 9.86928105e-01,\n",
            "       9.87745098e-01, 9.87745098e-01, 9.88562092e-01, 9.88562092e-01,\n",
            "       9.89379085e-01, 9.89379085e-01, 9.90196078e-01, 9.90196078e-01,\n",
            "       9.91013072e-01, 9.91013072e-01, 9.91830065e-01, 9.91830065e-01,\n",
            "       9.92647059e-01, 9.92647059e-01, 9.93464052e-01, 9.93464052e-01,\n",
            "       9.94281046e-01, 9.94281046e-01, 9.95098039e-01, 9.95098039e-01,\n",
            "       9.95915033e-01, 9.95915033e-01, 9.96732026e-01, 9.96732026e-01,\n",
            "       9.97549020e-01, 9.97549020e-01, 9.98366013e-01, 9.98366013e-01,\n",
            "       9.99183007e-01, 9.99183007e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  3: array([0.00000000e+00, 8.44594595e-04, 8.61486486e-02, 8.61486486e-02,\n",
            "       1.38513514e-01, 1.38513514e-01, 1.40202703e-01, 1.40202703e-01,\n",
            "       1.71452703e-01, 1.71452703e-01, 1.98479730e-01, 1.98479730e-01,\n",
            "       2.26351351e-01, 2.26351351e-01, 2.30574324e-01, 2.30574324e-01,\n",
            "       2.66047297e-01, 2.66047297e-01, 2.67736486e-01, 2.67736486e-01,\n",
            "       2.80405405e-01, 2.80405405e-01, 3.00675676e-01, 3.00675676e-01,\n",
            "       3.02364865e-01, 3.02364865e-01, 3.15033784e-01, 3.15033784e-01,\n",
            "       3.29391892e-01, 3.29391892e-01, 3.38682432e-01, 3.38682432e-01,\n",
            "       3.45439189e-01, 3.45439189e-01, 3.47128378e-01, 3.47128378e-01,\n",
            "       3.49662162e-01, 3.49662162e-01, 3.56418919e-01, 3.56418919e-01,\n",
            "       3.58108108e-01, 3.58108108e-01, 3.60641892e-01, 3.60641892e-01,\n",
            "       3.63175676e-01, 3.63175676e-01, 3.69932432e-01, 3.69932432e-01,\n",
            "       3.72466216e-01, 3.72466216e-01, 3.75844595e-01, 3.75844595e-01,\n",
            "       3.76689189e-01, 3.76689189e-01, 3.79222973e-01, 3.79222973e-01,\n",
            "       3.80912162e-01, 3.80912162e-01, 3.91891892e-01, 3.91891892e-01,\n",
            "       3.93581081e-01, 3.93581081e-01, 4.09628378e-01, 4.09628378e-01,\n",
            "       4.12162162e-01, 4.12162162e-01, 4.27364865e-01, 4.27364865e-01,\n",
            "       4.29054054e-01, 4.29054054e-01, 4.29898649e-01, 4.29898649e-01,\n",
            "       4.30743243e-01, 4.30743243e-01, 4.35810811e-01, 4.35810811e-01,\n",
            "       4.45945946e-01, 4.45945946e-01, 4.58614865e-01, 4.58614865e-01,\n",
            "       4.61148649e-01, 4.61148649e-01, 4.62837838e-01, 4.62837838e-01,\n",
            "       4.64527027e-01, 4.64527027e-01, 4.65371622e-01, 4.65371622e-01,\n",
            "       4.78040541e-01, 4.78040541e-01, 4.87331081e-01, 4.87331081e-01,\n",
            "       4.94087838e-01, 4.94087838e-01, 5.01689189e-01, 5.01689189e-01,\n",
            "       5.02533784e-01, 5.02533784e-01, 5.06756757e-01, 5.06756757e-01,\n",
            "       5.10135135e-01, 5.10135135e-01, 5.18581081e-01, 5.18581081e-01,\n",
            "       5.20270270e-01, 5.20270270e-01, 5.21959459e-01, 5.21959459e-01,\n",
            "       5.22804054e-01, 5.22804054e-01, 5.24493243e-01, 5.24493243e-01,\n",
            "       5.30405405e-01, 5.30405405e-01, 5.32094595e-01, 5.32094595e-01,\n",
            "       5.32939189e-01, 5.32939189e-01, 5.34628378e-01, 5.34628378e-01,\n",
            "       5.38006757e-01, 5.38006757e-01, 5.39695946e-01, 5.39695946e-01,\n",
            "       5.40540541e-01, 5.40540541e-01, 5.43074324e-01, 5.43074324e-01,\n",
            "       5.45608108e-01, 5.45608108e-01, 5.46452703e-01, 5.46452703e-01,\n",
            "       5.47297297e-01, 5.47297297e-01, 5.49831081e-01, 5.49831081e-01,\n",
            "       5.54054054e-01, 5.54054054e-01, 5.59121622e-01, 5.59121622e-01,\n",
            "       5.59966216e-01, 5.59966216e-01, 5.60810811e-01, 5.60810811e-01,\n",
            "       5.65033784e-01, 5.65033784e-01, 5.68412162e-01, 5.68412162e-01,\n",
            "       5.72635135e-01, 5.72635135e-01, 5.73479730e-01, 5.73479730e-01,\n",
            "       5.76013514e-01, 5.76013514e-01, 5.76858108e-01, 5.76858108e-01,\n",
            "       5.77702703e-01, 5.77702703e-01, 5.78547297e-01, 5.78547297e-01,\n",
            "       5.82770270e-01, 5.82770270e-01, 5.84459459e-01, 5.84459459e-01,\n",
            "       5.85304054e-01, 5.85304054e-01, 5.87837838e-01, 5.87837838e-01,\n",
            "       5.91216216e-01, 5.91216216e-01, 5.92905405e-01, 5.92905405e-01,\n",
            "       5.93750000e-01, 5.93750000e-01, 5.97972973e-01, 5.97972973e-01,\n",
            "       6.01351351e-01, 6.01351351e-01, 6.02195946e-01, 6.02195946e-01,\n",
            "       6.03040541e-01, 6.03040541e-01, 6.03885135e-01, 6.03885135e-01,\n",
            "       6.07263514e-01, 6.07263514e-01, 6.08108108e-01, 6.08108108e-01,\n",
            "       6.08952703e-01, 6.08952703e-01, 6.10641892e-01, 6.10641892e-01,\n",
            "       6.11486486e-01, 6.11486486e-01, 6.12331081e-01, 6.12331081e-01,\n",
            "       6.13175676e-01, 6.13175676e-01, 6.15709459e-01, 6.15709459e-01,\n",
            "       6.16554054e-01, 6.16554054e-01, 6.17398649e-01, 6.17398649e-01,\n",
            "       6.20777027e-01, 6.20777027e-01, 6.21621622e-01, 6.21621622e-01,\n",
            "       6.23310811e-01, 6.23310811e-01, 6.25844595e-01, 6.25844595e-01,\n",
            "       6.26689189e-01, 6.26689189e-01, 6.27533784e-01, 6.27533784e-01,\n",
            "       6.28378378e-01, 6.28378378e-01, 6.30067568e-01, 6.30067568e-01,\n",
            "       6.32601351e-01, 6.32601351e-01, 6.39358108e-01, 6.39358108e-01,\n",
            "       6.49493243e-01, 6.49493243e-01, 6.51182432e-01, 6.51182432e-01,\n",
            "       6.53716216e-01, 6.53716216e-01, 6.54560811e-01, 6.54560811e-01,\n",
            "       6.65540541e-01, 6.65540541e-01, 6.67229730e-01, 6.67229730e-01,\n",
            "       6.68074324e-01, 6.68074324e-01, 6.68918919e-01, 6.68918919e-01,\n",
            "       6.71452703e-01, 6.71452703e-01, 6.72297297e-01, 6.72297297e-01,\n",
            "       6.73141892e-01, 6.73141892e-01, 6.74831081e-01, 6.74831081e-01,\n",
            "       6.75675676e-01, 6.75675676e-01, 6.78209459e-01, 6.78209459e-01,\n",
            "       6.79898649e-01, 6.79898649e-01, 6.81587838e-01, 6.81587838e-01,\n",
            "       6.83277027e-01, 6.83277027e-01, 6.84121622e-01, 6.84121622e-01,\n",
            "       6.84966216e-01, 6.84966216e-01, 6.85810811e-01, 6.85810811e-01,\n",
            "       6.90878378e-01, 6.90878378e-01, 6.91722973e-01, 6.91722973e-01,\n",
            "       6.99324324e-01, 6.99324324e-01, 7.00168919e-01, 7.00168919e-01,\n",
            "       7.01858108e-01, 7.01858108e-01, 7.02702703e-01, 7.02702703e-01,\n",
            "       7.04391892e-01, 7.04391892e-01, 7.05236486e-01, 7.05236486e-01,\n",
            "       7.06925676e-01, 7.06925676e-01, 7.07770270e-01, 7.07770270e-01,\n",
            "       7.09459459e-01, 7.09459459e-01, 7.10304054e-01, 7.10304054e-01,\n",
            "       7.14527027e-01, 7.14527027e-01, 7.17060811e-01, 7.17060811e-01,\n",
            "       7.21283784e-01, 7.21283784e-01, 7.22128378e-01, 7.22128378e-01,\n",
            "       7.26351351e-01, 7.26351351e-01, 7.28040541e-01, 7.28040541e-01,\n",
            "       7.28885135e-01, 7.28885135e-01, 7.33952703e-01, 7.33952703e-01,\n",
            "       7.34797297e-01, 7.34797297e-01, 7.36486486e-01, 7.36486486e-01,\n",
            "       7.37331081e-01, 7.37331081e-01, 7.38175676e-01, 7.38175676e-01,\n",
            "       7.39864865e-01, 7.39864865e-01, 7.40709459e-01, 7.40709459e-01,\n",
            "       7.42398649e-01, 7.42398649e-01, 7.43243243e-01, 7.43243243e-01,\n",
            "       7.48310811e-01, 7.48310811e-01, 7.50000000e-01, 7.50000000e-01,\n",
            "       7.51689189e-01, 7.51689189e-01, 7.52533784e-01, 7.52533784e-01,\n",
            "       7.53378378e-01, 7.53378378e-01, 7.54222973e-01, 7.54222973e-01,\n",
            "       7.55067568e-01, 7.55067568e-01, 7.58445946e-01, 7.58445946e-01,\n",
            "       7.60979730e-01, 7.60979730e-01, 7.63513514e-01, 7.63513514e-01,\n",
            "       7.64358108e-01, 7.64358108e-01, 7.65202703e-01, 7.65202703e-01,\n",
            "       7.66047297e-01, 7.66047297e-01, 7.66891892e-01, 7.66891892e-01,\n",
            "       7.67736486e-01, 7.67736486e-01, 7.69425676e-01, 7.69425676e-01,\n",
            "       7.70270270e-01, 7.70270270e-01, 7.72804054e-01, 7.72804054e-01,\n",
            "       7.74493243e-01, 7.74493243e-01, 7.75337838e-01, 7.75337838e-01,\n",
            "       7.76182432e-01, 7.76182432e-01, 7.77871622e-01, 7.77871622e-01,\n",
            "       7.81250000e-01, 7.81250000e-01, 7.82094595e-01, 7.82094595e-01,\n",
            "       7.83783784e-01, 7.83783784e-01, 7.84628378e-01, 7.84628378e-01,\n",
            "       7.85472973e-01, 7.85472973e-01, 7.86317568e-01, 7.86317568e-01,\n",
            "       7.87162162e-01, 7.87162162e-01, 7.88006757e-01, 7.88006757e-01,\n",
            "       7.89695946e-01, 7.89695946e-01, 7.93918919e-01, 7.93918919e-01,\n",
            "       7.94763514e-01, 7.94763514e-01, 7.96452703e-01, 7.96452703e-01,\n",
            "       7.97297297e-01, 7.97297297e-01, 7.98986486e-01, 7.98986486e-01,\n",
            "       7.99831081e-01, 7.99831081e-01, 8.01520270e-01, 8.01520270e-01,\n",
            "       8.03209459e-01, 8.03209459e-01, 8.06587838e-01, 8.06587838e-01,\n",
            "       8.07432432e-01, 8.07432432e-01, 8.09121622e-01, 8.09121622e-01,\n",
            "       8.11655405e-01, 8.11655405e-01, 8.12500000e-01, 8.12500000e-01,\n",
            "       8.14189189e-01, 8.14189189e-01, 8.15033784e-01, 8.15033784e-01,\n",
            "       8.18412162e-01, 8.18412162e-01, 8.19256757e-01, 8.19256757e-01,\n",
            "       8.21790541e-01, 8.21790541e-01, 8.23479730e-01, 8.23479730e-01,\n",
            "       8.24324324e-01, 8.24324324e-01, 8.26858108e-01, 8.26858108e-01,\n",
            "       8.28547297e-01, 8.28547297e-01, 8.29391892e-01, 8.29391892e-01,\n",
            "       8.31081081e-01, 8.31081081e-01, 8.31925676e-01, 8.31925676e-01,\n",
            "       8.32770270e-01, 8.32770270e-01, 8.36148649e-01, 8.36148649e-01,\n",
            "       8.37837838e-01, 8.37837838e-01, 8.38682432e-01, 8.38682432e-01,\n",
            "       8.42060811e-01, 8.42060811e-01, 8.42905405e-01, 8.42905405e-01,\n",
            "       8.43750000e-01, 8.43750000e-01, 8.44594595e-01, 8.44594595e-01,\n",
            "       8.45439189e-01, 8.45439189e-01, 8.46283784e-01, 8.46283784e-01,\n",
            "       8.47128378e-01, 8.47128378e-01, 8.47972973e-01, 8.47972973e-01,\n",
            "       8.51351351e-01, 8.51351351e-01, 8.52195946e-01, 8.52195946e-01,\n",
            "       8.53040541e-01, 8.53040541e-01, 8.53885135e-01, 8.53885135e-01,\n",
            "       8.54729730e-01, 8.54729730e-01, 8.57263514e-01, 8.57263514e-01,\n",
            "       8.58108108e-01, 8.58108108e-01, 8.58952703e-01, 8.58952703e-01,\n",
            "       8.59797297e-01, 8.59797297e-01, 8.62331081e-01, 8.62331081e-01,\n",
            "       8.63175676e-01, 8.63175676e-01, 8.64020270e-01, 8.64020270e-01,\n",
            "       8.64864865e-01, 8.64864865e-01, 8.65709459e-01, 8.65709459e-01,\n",
            "       8.66554054e-01, 8.66554054e-01, 8.67398649e-01, 8.67398649e-01,\n",
            "       8.69087838e-01, 8.69087838e-01, 8.69932432e-01, 8.69932432e-01,\n",
            "       8.72466216e-01, 8.72466216e-01, 8.74155405e-01, 8.74155405e-01,\n",
            "       8.75000000e-01, 8.75000000e-01, 8.75844595e-01, 8.75844595e-01,\n",
            "       8.76689189e-01, 8.76689189e-01, 8.77533784e-01, 8.77533784e-01,\n",
            "       8.79222973e-01, 8.79222973e-01, 8.80067568e-01, 8.80067568e-01,\n",
            "       8.80912162e-01, 8.80912162e-01, 8.81756757e-01, 8.81756757e-01,\n",
            "       8.83445946e-01, 8.83445946e-01, 8.84290541e-01, 8.84290541e-01,\n",
            "       8.85135135e-01, 8.85135135e-01, 8.85979730e-01, 8.85979730e-01,\n",
            "       8.86824324e-01, 8.86824324e-01, 8.87668919e-01, 8.87668919e-01,\n",
            "       8.88513514e-01, 8.88513514e-01, 8.89358108e-01, 8.89358108e-01,\n",
            "       8.90202703e-01, 8.90202703e-01, 8.91891892e-01, 8.91891892e-01,\n",
            "       8.92736486e-01, 8.92736486e-01, 8.93581081e-01, 8.93581081e-01,\n",
            "       8.94425676e-01, 8.94425676e-01, 8.95270270e-01, 8.95270270e-01,\n",
            "       8.96114865e-01, 8.96114865e-01, 8.96959459e-01, 8.96959459e-01,\n",
            "       8.97804054e-01, 8.97804054e-01, 8.98648649e-01, 8.98648649e-01,\n",
            "       8.99493243e-01, 8.99493243e-01, 9.00337838e-01, 9.00337838e-01,\n",
            "       9.01182432e-01, 9.01182432e-01, 9.02027027e-01, 9.02027027e-01,\n",
            "       9.02871622e-01, 9.02871622e-01, 9.03716216e-01, 9.03716216e-01,\n",
            "       9.04560811e-01, 9.04560811e-01, 9.05405405e-01, 9.05405405e-01,\n",
            "       9.06250000e-01, 9.06250000e-01, 9.07939189e-01, 9.07939189e-01,\n",
            "       9.08783784e-01, 9.08783784e-01, 9.10472973e-01, 9.10472973e-01,\n",
            "       9.11317568e-01, 9.11317568e-01, 9.12162162e-01, 9.12162162e-01,\n",
            "       9.13006757e-01, 9.13006757e-01, 9.14695946e-01, 9.14695946e-01,\n",
            "       9.15540541e-01, 9.15540541e-01, 9.16385135e-01, 9.16385135e-01,\n",
            "       9.18074324e-01, 9.18074324e-01, 9.18918919e-01, 9.18918919e-01,\n",
            "       9.19763514e-01, 9.19763514e-01, 9.20608108e-01, 9.20608108e-01,\n",
            "       9.21452703e-01, 9.21452703e-01, 9.23141892e-01, 9.23141892e-01,\n",
            "       9.23986486e-01, 9.23986486e-01, 9.24831081e-01, 9.24831081e-01,\n",
            "       9.25675676e-01, 9.25675676e-01, 9.26520270e-01, 9.26520270e-01,\n",
            "       9.27364865e-01, 9.27364865e-01, 9.29054054e-01, 9.29054054e-01,\n",
            "       9.29898649e-01, 9.29898649e-01, 9.30743243e-01, 9.30743243e-01,\n",
            "       9.31587838e-01, 9.31587838e-01, 9.32432432e-01, 9.32432432e-01,\n",
            "       9.33277027e-01, 9.33277027e-01, 9.34121622e-01, 9.34121622e-01,\n",
            "       9.35810811e-01, 9.35810811e-01, 9.37500000e-01, 9.37500000e-01,\n",
            "       9.38344595e-01, 9.38344595e-01, 9.39189189e-01, 9.39189189e-01,\n",
            "       9.40033784e-01, 9.40033784e-01, 9.40878378e-01, 9.40878378e-01,\n",
            "       9.41722973e-01, 9.41722973e-01, 9.42567568e-01, 9.42567568e-01,\n",
            "       9.43412162e-01, 9.43412162e-01, 9.44256757e-01, 9.44256757e-01,\n",
            "       9.45101351e-01, 9.45101351e-01, 9.45945946e-01, 9.45945946e-01,\n",
            "       9.46790541e-01, 9.46790541e-01, 9.47635135e-01, 9.47635135e-01,\n",
            "       9.48479730e-01, 9.48479730e-01, 9.49324324e-01, 9.49324324e-01,\n",
            "       9.50168919e-01, 9.50168919e-01, 9.51013514e-01, 9.51013514e-01,\n",
            "       9.51858108e-01, 9.51858108e-01, 9.52702703e-01, 9.52702703e-01,\n",
            "       9.53547297e-01, 9.53547297e-01, 9.54391892e-01, 9.54391892e-01,\n",
            "       9.55236486e-01, 9.55236486e-01, 9.56081081e-01, 9.56081081e-01,\n",
            "       9.57770270e-01, 9.57770270e-01, 9.58614865e-01, 9.58614865e-01,\n",
            "       9.59459459e-01, 9.59459459e-01, 9.60304054e-01, 9.60304054e-01,\n",
            "       9.61148649e-01, 9.61148649e-01, 9.61993243e-01, 9.61993243e-01,\n",
            "       9.62837838e-01, 9.62837838e-01, 9.63682432e-01, 9.63682432e-01,\n",
            "       9.64527027e-01, 9.64527027e-01, 9.65371622e-01, 9.65371622e-01,\n",
            "       9.66216216e-01, 9.66216216e-01, 9.67060811e-01, 9.67060811e-01,\n",
            "       9.67905405e-01, 9.67905405e-01, 9.68750000e-01, 9.68750000e-01,\n",
            "       9.69594595e-01, 9.69594595e-01, 9.70439189e-01, 9.70439189e-01,\n",
            "       9.71283784e-01, 9.71283784e-01, 9.72128378e-01, 9.72128378e-01,\n",
            "       9.72972973e-01, 9.72972973e-01, 9.73817568e-01, 9.73817568e-01,\n",
            "       9.74662162e-01, 9.74662162e-01, 9.75506757e-01, 9.75506757e-01,\n",
            "       9.76351351e-01, 9.76351351e-01, 9.77195946e-01, 9.77195946e-01,\n",
            "       9.78040541e-01, 9.78040541e-01, 9.78885135e-01, 9.78885135e-01,\n",
            "       9.79729730e-01, 9.79729730e-01, 9.80574324e-01, 9.80574324e-01,\n",
            "       9.82263514e-01, 9.82263514e-01, 9.83108108e-01, 9.83108108e-01,\n",
            "       9.83952703e-01, 9.83952703e-01, 9.84797297e-01, 9.84797297e-01,\n",
            "       9.85641892e-01, 9.85641892e-01, 9.86486486e-01, 9.86486486e-01,\n",
            "       9.87331081e-01, 9.87331081e-01, 9.88175676e-01, 9.88175676e-01,\n",
            "       9.89020270e-01, 9.89020270e-01, 9.89864865e-01, 9.89864865e-01,\n",
            "       9.90709459e-01, 9.90709459e-01, 9.91554054e-01, 9.91554054e-01,\n",
            "       9.92398649e-01, 9.92398649e-01, 9.93243243e-01, 9.93243243e-01,\n",
            "       9.94087838e-01, 9.94087838e-01, 9.94932432e-01, 9.94932432e-01,\n",
            "       9.95777027e-01, 9.95777027e-01, 9.96621622e-01, 9.96621622e-01,\n",
            "       9.97466216e-01, 9.97466216e-01, 9.98310811e-01, 9.98310811e-01,\n",
            "       9.99155405e-01, 9.99155405e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  4: array([0.00000000e+00, 8.19000819e-04, 5.43816544e-01, 5.43816544e-01,\n",
            "       6.43734644e-01, 6.43734644e-01, 7.19082719e-01, 7.19082719e-01,\n",
            "       7.24815725e-01, 7.24815725e-01, 7.31367731e-01, 7.31367731e-01,\n",
            "       7.46928747e-01, 7.46928747e-01, 7.51023751e-01, 7.51023751e-01,\n",
            "       7.54299754e-01, 7.54299754e-01, 7.62489762e-01, 7.62489762e-01,\n",
            "       7.69860770e-01, 7.69860770e-01, 7.72317772e-01, 7.72317772e-01,\n",
            "       7.83783784e-01, 7.83783784e-01, 7.84602785e-01, 7.84602785e-01,\n",
            "       7.90335790e-01, 7.90335790e-01, 8.01801802e-01, 8.01801802e-01,\n",
            "       8.08353808e-01, 8.08353808e-01, 8.10810811e-01, 8.10810811e-01,\n",
            "       8.14905815e-01, 8.14905815e-01, 8.22276822e-01, 8.22276822e-01,\n",
            "       8.26371826e-01, 8.26371826e-01, 8.27190827e-01, 8.27190827e-01,\n",
            "       8.28828829e-01, 8.28828829e-01, 8.34561835e-01, 8.34561835e-01,\n",
            "       8.35380835e-01, 8.35380835e-01, 8.36199836e-01, 8.36199836e-01,\n",
            "       8.40294840e-01, 8.40294840e-01, 8.43570844e-01, 8.43570844e-01,\n",
            "       8.47665848e-01, 8.47665848e-01, 8.48484848e-01, 8.48484848e-01,\n",
            "       8.51760852e-01, 8.51760852e-01, 8.54217854e-01, 8.54217854e-01,\n",
            "       8.55036855e-01, 8.55036855e-01, 8.55855856e-01, 8.55855856e-01,\n",
            "       8.61588862e-01, 8.61588862e-01, 8.62407862e-01, 8.62407862e-01,\n",
            "       8.64864865e-01, 8.64864865e-01, 8.68140868e-01, 8.68140868e-01,\n",
            "       8.70597871e-01, 8.70597871e-01, 8.74692875e-01, 8.74692875e-01,\n",
            "       8.75511876e-01, 8.75511876e-01, 8.76330876e-01, 8.76330876e-01,\n",
            "       8.78787879e-01, 8.78787879e-01, 8.80425880e-01, 8.80425880e-01,\n",
            "       8.81244881e-01, 8.81244881e-01, 8.82063882e-01, 8.82063882e-01,\n",
            "       8.83701884e-01, 8.83701884e-01, 8.85339885e-01, 8.85339885e-01,\n",
            "       8.86977887e-01, 8.86977887e-01, 8.87796888e-01, 8.87796888e-01,\n",
            "       8.88615889e-01, 8.88615889e-01, 8.90253890e-01, 8.90253890e-01,\n",
            "       8.91891892e-01, 8.91891892e-01, 8.92710893e-01, 8.92710893e-01,\n",
            "       8.93529894e-01, 8.93529894e-01, 8.94348894e-01, 8.94348894e-01,\n",
            "       8.96805897e-01, 8.96805897e-01, 8.97624898e-01, 8.97624898e-01,\n",
            "       8.98443898e-01, 8.98443898e-01, 9.00081900e-01, 9.00081900e-01,\n",
            "       9.00900901e-01, 9.00900901e-01, 9.01719902e-01, 9.01719902e-01,\n",
            "       9.07452907e-01, 9.07452907e-01, 9.09090909e-01, 9.09090909e-01,\n",
            "       9.11547912e-01, 9.11547912e-01, 9.13185913e-01, 9.13185913e-01,\n",
            "       9.14004914e-01, 9.14004914e-01, 9.16461916e-01, 9.16461916e-01,\n",
            "       9.17280917e-01, 9.17280917e-01, 9.18918919e-01, 9.18918919e-01,\n",
            "       9.19737920e-01, 9.19737920e-01, 9.21375921e-01, 9.21375921e-01,\n",
            "       9.24651925e-01, 9.24651925e-01, 9.26289926e-01, 9.26289926e-01,\n",
            "       9.27108927e-01, 9.27108927e-01, 9.27927928e-01, 9.27927928e-01,\n",
            "       9.30384930e-01, 9.30384930e-01, 9.32022932e-01, 9.32022932e-01,\n",
            "       9.32841933e-01, 9.32841933e-01, 9.33660934e-01, 9.33660934e-01,\n",
            "       9.36936937e-01, 9.36936937e-01, 9.38574939e-01, 9.38574939e-01,\n",
            "       9.40212940e-01, 9.40212940e-01, 9.41850942e-01, 9.41850942e-01,\n",
            "       9.43488943e-01, 9.43488943e-01, 9.44307944e-01, 9.44307944e-01,\n",
            "       9.45945946e-01, 9.45945946e-01, 9.46764947e-01, 9.46764947e-01,\n",
            "       9.47583948e-01, 9.47583948e-01, 9.48402948e-01, 9.48402948e-01,\n",
            "       9.50040950e-01, 9.50040950e-01, 9.50859951e-01, 9.50859951e-01,\n",
            "       9.52497952e-01, 9.52497952e-01, 9.55773956e-01, 9.55773956e-01,\n",
            "       9.56592957e-01, 9.56592957e-01, 9.57411957e-01, 9.57411957e-01,\n",
            "       9.58230958e-01, 9.58230958e-01, 9.59049959e-01, 9.59049959e-01,\n",
            "       9.59868960e-01, 9.59868960e-01, 9.60687961e-01, 9.60687961e-01,\n",
            "       9.61506962e-01, 9.61506962e-01, 9.63144963e-01, 9.63144963e-01,\n",
            "       9.63963964e-01, 9.63963964e-01, 9.64782965e-01, 9.64782965e-01,\n",
            "       9.65601966e-01, 9.65601966e-01, 9.66420966e-01, 9.66420966e-01,\n",
            "       9.67239967e-01, 9.67239967e-01, 9.68877969e-01, 9.68877969e-01,\n",
            "       9.69696970e-01, 9.69696970e-01, 9.70515971e-01, 9.70515971e-01,\n",
            "       9.71334971e-01, 9.71334971e-01, 9.72153972e-01, 9.72153972e-01,\n",
            "       9.72972973e-01, 9.72972973e-01, 9.74610975e-01, 9.74610975e-01,\n",
            "       9.75429975e-01, 9.75429975e-01, 9.76248976e-01, 9.76248976e-01,\n",
            "       9.77067977e-01, 9.77067977e-01, 9.77886978e-01, 9.77886978e-01,\n",
            "       9.78705979e-01, 9.78705979e-01, 9.79524980e-01, 9.79524980e-01,\n",
            "       9.81162981e-01, 9.81162981e-01, 9.81981982e-01, 9.81981982e-01,\n",
            "       9.82800983e-01, 9.82800983e-01, 9.83619984e-01, 9.83619984e-01,\n",
            "       9.84438984e-01, 9.84438984e-01, 9.85257985e-01, 9.85257985e-01,\n",
            "       9.86076986e-01, 9.86076986e-01, 9.86895987e-01, 9.86895987e-01,\n",
            "       9.87714988e-01, 9.87714988e-01, 9.88533989e-01, 9.88533989e-01,\n",
            "       9.89352989e-01, 9.89352989e-01, 9.90171990e-01, 9.90171990e-01,\n",
            "       9.90990991e-01, 9.90990991e-01, 9.91809992e-01, 9.91809992e-01,\n",
            "       9.92628993e-01, 9.92628993e-01, 9.93447993e-01, 9.93447993e-01,\n",
            "       9.94266994e-01, 9.94266994e-01, 9.95085995e-01, 9.95085995e-01,\n",
            "       9.95904996e-01, 9.95904996e-01, 9.96723997e-01, 9.96723997e-01,\n",
            "       9.97542998e-01, 9.97542998e-01, 9.98361998e-01, 9.98361998e-01,\n",
            "       9.99180999e-01, 9.99180999e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  5: array([0.00000000e+00, 8.41750842e-04, 4.80639731e-01, 4.80639731e-01,\n",
            "       6.06902357e-01, 6.06902357e-01, 7.06228956e-01, 7.06228956e-01,\n",
            "       7.12962963e-01, 7.12962963e-01, 7.44107744e-01, 7.44107744e-01,\n",
            "       7.92087542e-01, 7.92087542e-01, 8.06397306e-01, 8.06397306e-01,\n",
            "       8.29124579e-01, 8.29124579e-01, 8.33333333e-01, 8.33333333e-01,\n",
            "       8.56902357e-01, 8.56902357e-01, 8.67003367e-01, 8.67003367e-01,\n",
            "       8.72053872e-01, 8.72053872e-01, 8.74579125e-01, 8.74579125e-01,\n",
            "       8.75420875e-01, 8.75420875e-01, 8.80471380e-01, 8.80471380e-01,\n",
            "       8.83838384e-01, 8.83838384e-01, 8.90572391e-01, 8.90572391e-01,\n",
            "       8.96464646e-01, 8.96464646e-01, 8.99831650e-01, 8.99831650e-01,\n",
            "       9.02356902e-01, 9.02356902e-01, 9.03198653e-01, 9.03198653e-01,\n",
            "       9.09090909e-01, 9.09090909e-01, 9.10774411e-01, 9.10774411e-01,\n",
            "       9.12457912e-01, 9.12457912e-01, 9.15824916e-01, 9.15824916e-01,\n",
            "       9.16666667e-01, 9.16666667e-01, 9.17508418e-01, 9.17508418e-01,\n",
            "       9.18350168e-01, 9.18350168e-01, 9.19191919e-01, 9.19191919e-01,\n",
            "       9.20033670e-01, 9.20033670e-01, 9.23400673e-01, 9.23400673e-01,\n",
            "       9.24242424e-01, 9.24242424e-01, 9.25084175e-01, 9.25084175e-01,\n",
            "       9.25925926e-01, 9.25925926e-01, 9.26767677e-01, 9.26767677e-01,\n",
            "       9.27609428e-01, 9.27609428e-01, 9.29292929e-01, 9.29292929e-01,\n",
            "       9.30976431e-01, 9.30976431e-01, 9.32659933e-01, 9.32659933e-01,\n",
            "       9.35185185e-01, 9.35185185e-01, 9.37710438e-01, 9.37710438e-01,\n",
            "       9.38552189e-01, 9.38552189e-01, 9.41919192e-01, 9.41919192e-01,\n",
            "       9.42760943e-01, 9.42760943e-01, 9.44444444e-01, 9.44444444e-01,\n",
            "       9.46127946e-01, 9.46127946e-01, 9.46969697e-01, 9.46969697e-01,\n",
            "       9.47811448e-01, 9.47811448e-01, 9.50336700e-01, 9.50336700e-01,\n",
            "       9.52861953e-01, 9.52861953e-01, 9.54545455e-01, 9.54545455e-01,\n",
            "       9.57070707e-01, 9.57070707e-01, 9.57912458e-01, 9.57912458e-01,\n",
            "       9.60437710e-01, 9.60437710e-01, 9.62962963e-01, 9.62962963e-01,\n",
            "       9.64646465e-01, 9.64646465e-01, 9.68013468e-01, 9.68013468e-01,\n",
            "       9.68855219e-01, 9.68855219e-01, 9.69696970e-01, 9.69696970e-01,\n",
            "       9.70538721e-01, 9.70538721e-01, 9.72222222e-01, 9.72222222e-01,\n",
            "       9.73063973e-01, 9.73063973e-01, 9.73905724e-01, 9.73905724e-01,\n",
            "       9.74747475e-01, 9.74747475e-01, 9.75589226e-01, 9.75589226e-01,\n",
            "       9.76430976e-01, 9.76430976e-01, 9.77272727e-01, 9.77272727e-01,\n",
            "       9.78114478e-01, 9.78114478e-01, 9.78956229e-01, 9.78956229e-01,\n",
            "       9.79797980e-01, 9.79797980e-01, 9.80639731e-01, 9.80639731e-01,\n",
            "       9.81481481e-01, 9.81481481e-01, 9.82323232e-01, 9.82323232e-01,\n",
            "       9.83164983e-01, 9.83164983e-01, 9.84848485e-01, 9.84848485e-01,\n",
            "       9.85690236e-01, 9.85690236e-01, 9.86531987e-01, 9.86531987e-01,\n",
            "       9.87373737e-01, 9.87373737e-01, 9.88215488e-01, 9.88215488e-01,\n",
            "       9.89057239e-01, 9.89057239e-01, 9.89898990e-01, 9.89898990e-01,\n",
            "       9.90740741e-01, 9.90740741e-01, 9.91582492e-01, 9.91582492e-01,\n",
            "       9.92424242e-01, 9.92424242e-01, 9.93265993e-01, 9.93265993e-01,\n",
            "       9.94107744e-01, 9.94107744e-01, 9.94949495e-01, 9.94949495e-01,\n",
            "       9.95791246e-01, 9.95791246e-01, 9.96632997e-01, 9.96632997e-01,\n",
            "       9.97474747e-01, 9.97474747e-01, 9.98316498e-01, 9.98316498e-01,\n",
            "       9.99158249e-01, 9.99158249e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  6: array([0.00000000e+00, 8.55431993e-04, 1.83917879e-01, 1.83917879e-01,\n",
            "       2.10436270e-01, 2.10436270e-01, 2.37810094e-01, 2.37810094e-01,\n",
            "       2.90846878e-01, 2.90846878e-01, 3.31907613e-01, 3.31907613e-01,\n",
            "       3.70402053e-01, 3.70402053e-01, 3.87510693e-01, 3.87510693e-01,\n",
            "       3.92643285e-01, 3.92643285e-01, 4.13173653e-01, 4.13173653e-01,\n",
            "       4.24294269e-01, 4.24294269e-01, 4.31137725e-01, 4.31137725e-01,\n",
            "       4.47390932e-01, 4.47390932e-01, 4.56800684e-01, 4.56800684e-01,\n",
            "       4.80752780e-01, 4.80752780e-01, 4.90162532e-01, 4.90162532e-01,\n",
            "       5.10692900e-01, 5.10692900e-01, 5.20958084e-01, 5.20958084e-01,\n",
            "       5.26946108e-01, 5.26946108e-01, 5.40633020e-01, 5.40633020e-01,\n",
            "       5.54319932e-01, 5.54319932e-01, 5.55175364e-01, 5.55175364e-01,\n",
            "       5.64585115e-01, 5.64585115e-01, 5.68006843e-01, 5.68006843e-01,\n",
            "       5.73139435e-01, 5.73139435e-01, 5.86826347e-01, 5.86826347e-01,\n",
            "       5.91958939e-01, 5.91958939e-01, 5.94525235e-01, 5.94525235e-01,\n",
            "       6.03079555e-01, 6.03079555e-01, 6.12489307e-01, 6.12489307e-01,\n",
            "       6.26176219e-01, 6.26176219e-01, 6.30453379e-01, 6.30453379e-01,\n",
            "       6.37296835e-01, 6.37296835e-01, 6.43284859e-01, 6.43284859e-01,\n",
            "       6.44995723e-01, 6.44995723e-01, 6.57827203e-01, 6.57827203e-01,\n",
            "       6.67236955e-01, 6.67236955e-01, 6.73224979e-01, 6.73224979e-01,\n",
            "       6.77502139e-01, 6.77502139e-01, 6.80923867e-01, 6.80923867e-01,\n",
            "       6.85201027e-01, 6.85201027e-01, 6.86911891e-01, 6.86911891e-01,\n",
            "       6.87767322e-01, 6.87767322e-01, 6.95466210e-01, 6.95466210e-01,\n",
            "       6.97177074e-01, 6.97177074e-01, 6.98032506e-01, 6.98032506e-01,\n",
            "       7.07442258e-01, 7.07442258e-01, 7.09153122e-01, 7.09153122e-01,\n",
            "       7.10863986e-01, 7.10863986e-01, 7.19418306e-01, 7.19418306e-01,\n",
            "       7.21129170e-01, 7.21129170e-01, 7.23695466e-01, 7.23695466e-01,\n",
            "       7.26261762e-01, 7.26261762e-01, 7.30538922e-01, 7.30538922e-01,\n",
            "       7.37382378e-01, 7.37382378e-01, 7.41659538e-01, 7.41659538e-01,\n",
            "       7.45081266e-01, 7.45081266e-01, 7.49358426e-01, 7.49358426e-01,\n",
            "       7.51069290e-01, 7.51069290e-01, 7.51924722e-01, 7.51924722e-01,\n",
            "       7.55346450e-01, 7.55346450e-01, 7.56201882e-01, 7.56201882e-01,\n",
            "       7.61334474e-01, 7.61334474e-01, 7.66467066e-01, 7.66467066e-01,\n",
            "       7.70744226e-01, 7.70744226e-01, 7.71599658e-01, 7.71599658e-01,\n",
            "       7.76732250e-01, 7.76732250e-01, 7.79298546e-01, 7.79298546e-01,\n",
            "       7.80153978e-01, 7.80153978e-01, 7.81864842e-01, 7.81864842e-01,\n",
            "       7.85286570e-01, 7.85286570e-01, 7.86142002e-01, 7.86142002e-01,\n",
            "       7.88708298e-01, 7.88708298e-01, 7.90419162e-01, 7.90419162e-01,\n",
            "       7.91274594e-01, 7.91274594e-01, 7.92985458e-01, 7.92985458e-01,\n",
            "       7.93840890e-01, 7.93840890e-01, 7.94696322e-01, 7.94696322e-01,\n",
            "       7.95551754e-01, 7.95551754e-01, 7.98973482e-01, 7.98973482e-01,\n",
            "       8.02395210e-01, 8.02395210e-01, 8.03250642e-01, 8.03250642e-01,\n",
            "       8.04106074e-01, 8.04106074e-01, 8.05816938e-01, 8.05816938e-01,\n",
            "       8.07527802e-01, 8.07527802e-01, 8.08383234e-01, 8.08383234e-01,\n",
            "       8.10094098e-01, 8.10094098e-01, 8.10949530e-01, 8.10949530e-01,\n",
            "       8.14371257e-01, 8.14371257e-01, 8.16082121e-01, 8.16082121e-01,\n",
            "       8.16937553e-01, 8.16937553e-01, 8.17792985e-01, 8.17792985e-01,\n",
            "       8.18648417e-01, 8.18648417e-01, 8.22070145e-01, 8.22070145e-01,\n",
            "       8.22925577e-01, 8.22925577e-01, 8.23781009e-01, 8.23781009e-01,\n",
            "       8.28058169e-01, 8.28058169e-01, 8.28913601e-01, 8.28913601e-01,\n",
            "       8.29769033e-01, 8.29769033e-01, 8.37467921e-01, 8.37467921e-01,\n",
            "       8.39178785e-01, 8.39178785e-01, 8.40034217e-01, 8.40034217e-01,\n",
            "       8.40889649e-01, 8.40889649e-01, 8.42600513e-01, 8.42600513e-01,\n",
            "       8.44311377e-01, 8.44311377e-01, 8.45166809e-01, 8.45166809e-01,\n",
            "       8.50299401e-01, 8.50299401e-01, 8.51154833e-01, 8.51154833e-01,\n",
            "       8.52010265e-01, 8.52010265e-01, 8.53721129e-01, 8.53721129e-01,\n",
            "       8.54576561e-01, 8.54576561e-01, 8.57142857e-01, 8.57142857e-01,\n",
            "       8.59709153e-01, 8.59709153e-01, 8.60564585e-01, 8.60564585e-01,\n",
            "       8.62275449e-01, 8.62275449e-01, 8.63986313e-01, 8.63986313e-01,\n",
            "       8.65697177e-01, 8.65697177e-01, 8.67408041e-01, 8.67408041e-01,\n",
            "       8.68263473e-01, 8.68263473e-01, 8.70829769e-01, 8.70829769e-01,\n",
            "       8.73396065e-01, 8.73396065e-01, 8.75106929e-01, 8.75106929e-01,\n",
            "       8.76817793e-01, 8.76817793e-01, 8.78528657e-01, 8.78528657e-01,\n",
            "       8.79384089e-01, 8.79384089e-01, 8.80239521e-01, 8.80239521e-01,\n",
            "       8.81950385e-01, 8.81950385e-01, 8.82805817e-01, 8.82805817e-01,\n",
            "       8.83661249e-01, 8.83661249e-01, 8.85372113e-01, 8.85372113e-01,\n",
            "       8.86227545e-01, 8.86227545e-01, 8.87082977e-01, 8.87082977e-01,\n",
            "       8.87938409e-01, 8.87938409e-01, 8.89649273e-01, 8.89649273e-01,\n",
            "       8.91360137e-01, 8.91360137e-01, 8.93071001e-01, 8.93071001e-01,\n",
            "       8.93926433e-01, 8.93926433e-01, 8.94781865e-01, 8.94781865e-01,\n",
            "       8.95637297e-01, 8.95637297e-01, 8.96492729e-01, 8.96492729e-01,\n",
            "       8.97348161e-01, 8.97348161e-01, 9.00769889e-01, 9.00769889e-01,\n",
            "       9.01625321e-01, 9.01625321e-01, 9.02480753e-01, 9.02480753e-01,\n",
            "       9.03336185e-01, 9.03336185e-01, 9.05047049e-01, 9.05047049e-01,\n",
            "       9.05902481e-01, 9.05902481e-01, 9.07613345e-01, 9.07613345e-01,\n",
            "       9.08468777e-01, 9.08468777e-01, 9.09324209e-01, 9.09324209e-01,\n",
            "       9.10179641e-01, 9.10179641e-01, 9.11035073e-01, 9.11035073e-01,\n",
            "       9.13601369e-01, 9.13601369e-01, 9.16167665e-01, 9.16167665e-01,\n",
            "       9.17023097e-01, 9.17023097e-01, 9.17878529e-01, 9.17878529e-01,\n",
            "       9.18733961e-01, 9.18733961e-01, 9.19589393e-01, 9.19589393e-01,\n",
            "       9.20444825e-01, 9.20444825e-01, 9.22155689e-01, 9.22155689e-01,\n",
            "       9.23011121e-01, 9.23011121e-01, 9.23866553e-01, 9.23866553e-01,\n",
            "       9.24721985e-01, 9.24721985e-01, 9.25577417e-01, 9.25577417e-01,\n",
            "       9.26432849e-01, 9.26432849e-01, 9.27288281e-01, 9.27288281e-01,\n",
            "       9.28143713e-01, 9.28143713e-01, 9.28999145e-01, 9.28999145e-01,\n",
            "       9.29854577e-01, 9.29854577e-01, 9.31565441e-01, 9.31565441e-01,\n",
            "       9.32420873e-01, 9.32420873e-01, 9.33276305e-01, 9.33276305e-01,\n",
            "       9.34131737e-01, 9.34131737e-01, 9.34987169e-01, 9.34987169e-01,\n",
            "       9.35842601e-01, 9.35842601e-01, 9.36698033e-01, 9.36698033e-01,\n",
            "       9.37553464e-01, 9.37553464e-01, 9.38408896e-01, 9.38408896e-01,\n",
            "       9.40119760e-01, 9.40119760e-01, 9.40975192e-01, 9.40975192e-01,\n",
            "       9.41830624e-01, 9.41830624e-01, 9.42686056e-01, 9.42686056e-01,\n",
            "       9.44396920e-01, 9.44396920e-01, 9.45252352e-01, 9.45252352e-01,\n",
            "       9.46107784e-01, 9.46107784e-01, 9.46963216e-01, 9.46963216e-01,\n",
            "       9.47818648e-01, 9.47818648e-01, 9.48674080e-01, 9.48674080e-01,\n",
            "       9.49529512e-01, 9.49529512e-01, 9.50384944e-01, 9.50384944e-01,\n",
            "       9.51240376e-01, 9.51240376e-01, 9.52951240e-01, 9.52951240e-01,\n",
            "       9.54662104e-01, 9.54662104e-01, 9.55517536e-01, 9.55517536e-01,\n",
            "       9.56372968e-01, 9.56372968e-01, 9.57228400e-01, 9.57228400e-01,\n",
            "       9.58083832e-01, 9.58083832e-01, 9.58939264e-01, 9.58939264e-01,\n",
            "       9.60650128e-01, 9.60650128e-01, 9.62360992e-01, 9.62360992e-01,\n",
            "       9.63216424e-01, 9.63216424e-01, 9.65782720e-01, 9.65782720e-01,\n",
            "       9.66638152e-01, 9.66638152e-01, 9.67493584e-01, 9.67493584e-01,\n",
            "       9.68349016e-01, 9.68349016e-01, 9.69204448e-01, 9.69204448e-01,\n",
            "       9.70059880e-01, 9.70059880e-01, 9.70915312e-01, 9.70915312e-01,\n",
            "       9.71770744e-01, 9.71770744e-01, 9.72626176e-01, 9.72626176e-01,\n",
            "       9.73481608e-01, 9.73481608e-01, 9.74337040e-01, 9.74337040e-01,\n",
            "       9.75192472e-01, 9.75192472e-01, 9.76047904e-01, 9.76047904e-01,\n",
            "       9.76903336e-01, 9.76903336e-01, 9.77758768e-01, 9.77758768e-01,\n",
            "       9.78614200e-01, 9.78614200e-01, 9.79469632e-01, 9.79469632e-01,\n",
            "       9.80325064e-01, 9.80325064e-01, 9.81180496e-01, 9.81180496e-01,\n",
            "       9.82035928e-01, 9.82035928e-01, 9.82891360e-01, 9.82891360e-01,\n",
            "       9.83746792e-01, 9.83746792e-01, 9.84602224e-01, 9.84602224e-01,\n",
            "       9.85457656e-01, 9.85457656e-01, 9.86313088e-01, 9.86313088e-01,\n",
            "       9.87168520e-01, 9.87168520e-01, 9.88023952e-01, 9.88023952e-01,\n",
            "       9.88879384e-01, 9.88879384e-01, 9.89734816e-01, 9.89734816e-01,\n",
            "       9.90590248e-01, 9.90590248e-01, 9.91445680e-01, 9.91445680e-01,\n",
            "       9.92301112e-01, 9.92301112e-01, 9.93156544e-01, 9.93156544e-01,\n",
            "       9.94011976e-01, 9.94011976e-01, 9.94867408e-01, 9.94867408e-01,\n",
            "       9.95722840e-01, 9.95722840e-01, 9.96578272e-01, 9.96578272e-01,\n",
            "       9.97433704e-01, 9.97433704e-01, 9.98289136e-01, 9.98289136e-01,\n",
            "       9.99144568e-01, 9.99144568e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  7: array([0.00000000e+00, 8.20344545e-04, 2.83839212e-01, 2.83839212e-01,\n",
            "       3.62592289e-01, 3.62592289e-01, 4.33962264e-01, 4.33962264e-01,\n",
            "       4.70057424e-01, 4.70057424e-01, 4.75799836e-01, 4.75799836e-01,\n",
            "       4.85643970e-01, 4.85643970e-01, 5.06152584e-01, 5.06152584e-01,\n",
            "       5.72600492e-01, 5.72600492e-01, 5.73420837e-01, 5.73420837e-01,\n",
            "       5.74241181e-01, 5.74241181e-01, 5.92288761e-01, 5.92288761e-01,\n",
            "       5.99671862e-01, 5.99671862e-01, 6.02132896e-01, 6.02132896e-01,\n",
            "       6.07054963e-01, 6.07054963e-01, 6.08695652e-01, 6.08695652e-01,\n",
            "       6.18539787e-01, 6.18539787e-01, 6.20180476e-01, 6.20180476e-01,\n",
            "       6.24282199e-01, 6.24282199e-01, 6.26743232e-01, 6.26743232e-01,\n",
            "       6.28383921e-01, 6.28383921e-01, 6.34126333e-01, 6.34126333e-01,\n",
            "       6.39048400e-01, 6.39048400e-01, 6.42329779e-01, 6.42329779e-01,\n",
            "       6.48892535e-01, 6.48892535e-01, 6.54634947e-01, 6.54634947e-01,\n",
            "       6.66119770e-01, 6.66119770e-01, 6.67760459e-01, 6.67760459e-01,\n",
            "       6.71041838e-01, 6.71041838e-01, 6.75143560e-01, 6.75143560e-01,\n",
            "       6.77604594e-01, 6.77604594e-01, 6.82526661e-01, 6.82526661e-01,\n",
            "       6.85808039e-01, 6.85808039e-01, 6.91550451e-01, 6.91550451e-01,\n",
            "       6.97292863e-01, 6.97292863e-01, 6.98113208e-01, 6.98113208e-01,\n",
            "       6.98933552e-01, 6.98933552e-01, 7.01394586e-01, 7.01394586e-01,\n",
            "       7.03855619e-01, 7.03855619e-01, 7.04675964e-01, 7.04675964e-01,\n",
            "       7.05496308e-01, 7.05496308e-01, 7.07136998e-01, 7.07136998e-01,\n",
            "       7.07957342e-01, 7.07957342e-01, 7.11238720e-01, 7.11238720e-01,\n",
            "       7.13699754e-01, 7.13699754e-01, 7.16981132e-01, 7.16981132e-01,\n",
            "       7.17801477e-01, 7.17801477e-01, 7.20262510e-01, 7.20262510e-01,\n",
            "       7.21082855e-01, 7.21082855e-01, 7.21903199e-01, 7.21903199e-01,\n",
            "       7.24364233e-01, 7.24364233e-01, 7.26004922e-01, 7.26004922e-01,\n",
            "       7.26825267e-01, 7.26825267e-01, 7.30926989e-01, 7.30926989e-01,\n",
            "       7.31747334e-01, 7.31747334e-01, 7.34208368e-01, 7.34208368e-01,\n",
            "       7.35849057e-01, 7.35849057e-01, 7.37489746e-01, 7.37489746e-01,\n",
            "       7.39130435e-01, 7.39130435e-01, 7.39950779e-01, 7.39950779e-01,\n",
            "       7.48974569e-01, 7.48974569e-01, 7.50615258e-01, 7.50615258e-01,\n",
            "       7.52255947e-01, 7.52255947e-01, 7.53896637e-01, 7.53896637e-01,\n",
            "       7.55537326e-01, 7.55537326e-01, 7.61279737e-01, 7.61279737e-01,\n",
            "       7.69483183e-01, 7.69483183e-01, 7.71944217e-01, 7.71944217e-01,\n",
            "       7.73584906e-01, 7.73584906e-01, 7.76045939e-01, 7.76045939e-01,\n",
            "       7.77686628e-01, 7.77686628e-01, 7.79327317e-01, 7.79327317e-01,\n",
            "       7.80968007e-01, 7.80968007e-01, 7.82608696e-01, 7.82608696e-01,\n",
            "       7.84249385e-01, 7.84249385e-01, 7.88351107e-01, 7.88351107e-01,\n",
            "       7.89991797e-01, 7.89991797e-01, 7.90812141e-01, 7.90812141e-01,\n",
            "       7.91632486e-01, 7.91632486e-01, 7.92452830e-01, 7.92452830e-01,\n",
            "       8.00656276e-01, 8.00656276e-01, 8.01476620e-01, 8.01476620e-01,\n",
            "       8.02296965e-01, 8.02296965e-01, 8.03937654e-01, 8.03937654e-01,\n",
            "       8.07219032e-01, 8.07219032e-01, 8.08039377e-01, 8.08039377e-01,\n",
            "       8.13781788e-01, 8.13781788e-01, 8.17063167e-01, 8.17063167e-01,\n",
            "       8.18703856e-01, 8.18703856e-01, 8.21985234e-01, 8.21985234e-01,\n",
            "       8.23625923e-01, 8.23625923e-01, 8.26086957e-01, 8.26086957e-01,\n",
            "       8.26907301e-01, 8.26907301e-01, 8.27727646e-01, 8.27727646e-01,\n",
            "       8.29368335e-01, 8.29368335e-01, 8.31829368e-01, 8.31829368e-01,\n",
            "       8.32649713e-01, 8.32649713e-01, 8.33470057e-01, 8.33470057e-01,\n",
            "       8.34290402e-01, 8.34290402e-01, 8.35110747e-01, 8.35110747e-01,\n",
            "       8.35931091e-01, 8.35931091e-01, 8.37571780e-01, 8.37571780e-01,\n",
            "       8.39212469e-01, 8.39212469e-01, 8.41673503e-01, 8.41673503e-01,\n",
            "       8.43314192e-01, 8.43314192e-01, 8.44134537e-01, 8.44134537e-01,\n",
            "       8.45775226e-01, 8.45775226e-01, 8.47415915e-01, 8.47415915e-01,\n",
            "       8.48236259e-01, 8.48236259e-01, 8.49056604e-01, 8.49056604e-01,\n",
            "       8.49876948e-01, 8.49876948e-01, 8.53978671e-01, 8.53978671e-01,\n",
            "       8.54799016e-01, 8.54799016e-01, 8.56439705e-01, 8.56439705e-01,\n",
            "       8.57260049e-01, 8.57260049e-01, 8.58080394e-01, 8.58080394e-01,\n",
            "       8.58900738e-01, 8.58900738e-01, 8.59721083e-01, 8.59721083e-01,\n",
            "       8.63002461e-01, 8.63002461e-01, 8.63822806e-01, 8.63822806e-01,\n",
            "       8.65463495e-01, 8.65463495e-01, 8.66283839e-01, 8.66283839e-01,\n",
            "       8.67104184e-01, 8.67104184e-01, 8.67924528e-01, 8.67924528e-01,\n",
            "       8.68744873e-01, 8.68744873e-01, 8.71205906e-01, 8.71205906e-01,\n",
            "       8.72026251e-01, 8.72026251e-01, 8.72846596e-01, 8.72846596e-01,\n",
            "       8.76948318e-01, 8.76948318e-01, 8.77768663e-01, 8.77768663e-01,\n",
            "       8.78589007e-01, 8.78589007e-01, 8.79409352e-01, 8.79409352e-01,\n",
            "       8.80229696e-01, 8.80229696e-01, 8.81050041e-01, 8.81050041e-01,\n",
            "       8.82690730e-01, 8.82690730e-01, 8.84331419e-01, 8.84331419e-01,\n",
            "       8.85151764e-01, 8.85151764e-01, 8.85972108e-01, 8.85972108e-01,\n",
            "       8.86792453e-01, 8.86792453e-01, 8.88433142e-01, 8.88433142e-01,\n",
            "       8.89253486e-01, 8.89253486e-01, 8.90073831e-01, 8.90073831e-01,\n",
            "       8.91714520e-01, 8.91714520e-01, 8.92534865e-01, 8.92534865e-01,\n",
            "       8.93355209e-01, 8.93355209e-01, 8.94175554e-01, 8.94175554e-01,\n",
            "       8.94995898e-01, 8.94995898e-01, 8.96636587e-01, 8.96636587e-01,\n",
            "       8.97456932e-01, 8.97456932e-01, 8.98277276e-01, 8.98277276e-01,\n",
            "       8.99097621e-01, 8.99097621e-01, 8.99917966e-01, 8.99917966e-01,\n",
            "       9.00738310e-01, 9.00738310e-01, 9.01558655e-01, 9.01558655e-01,\n",
            "       9.02378999e-01, 9.02378999e-01, 9.05660377e-01, 9.05660377e-01,\n",
            "       9.07301066e-01, 9.07301066e-01, 9.10582445e-01, 9.10582445e-01,\n",
            "       9.12223134e-01, 9.12223134e-01, 9.13863823e-01, 9.13863823e-01,\n",
            "       9.14684167e-01, 9.14684167e-01, 9.17145201e-01, 9.17145201e-01,\n",
            "       9.17965546e-01, 9.17965546e-01, 9.18785890e-01, 9.18785890e-01,\n",
            "       9.20426579e-01, 9.20426579e-01, 9.21246924e-01, 9.21246924e-01,\n",
            "       9.22067268e-01, 9.22067268e-01, 9.23707957e-01, 9.23707957e-01,\n",
            "       9.26989336e-01, 9.26989336e-01, 9.28630025e-01, 9.28630025e-01,\n",
            "       9.29450369e-01, 9.29450369e-01, 9.30270714e-01, 9.30270714e-01,\n",
            "       9.32731747e-01, 9.32731747e-01, 9.33552092e-01, 9.33552092e-01,\n",
            "       9.34372436e-01, 9.34372436e-01, 9.36013126e-01, 9.36013126e-01,\n",
            "       9.36833470e-01, 9.36833470e-01, 9.38474159e-01, 9.38474159e-01,\n",
            "       9.39294504e-01, 9.39294504e-01, 9.40114848e-01, 9.40114848e-01,\n",
            "       9.40935193e-01, 9.40935193e-01, 9.41755537e-01, 9.41755537e-01,\n",
            "       9.42575882e-01, 9.42575882e-01, 9.43396226e-01, 9.43396226e-01,\n",
            "       9.45036916e-01, 9.45036916e-01, 9.45857260e-01, 9.45857260e-01,\n",
            "       9.46677605e-01, 9.46677605e-01, 9.47497949e-01, 9.47497949e-01,\n",
            "       9.48318294e-01, 9.48318294e-01, 9.49138638e-01, 9.49138638e-01,\n",
            "       9.49958983e-01, 9.49958983e-01, 9.51599672e-01, 9.51599672e-01,\n",
            "       9.53240361e-01, 9.53240361e-01, 9.54060705e-01, 9.54060705e-01,\n",
            "       9.54881050e-01, 9.54881050e-01, 9.55701395e-01, 9.55701395e-01,\n",
            "       9.56521739e-01, 9.56521739e-01, 9.57342084e-01, 9.57342084e-01,\n",
            "       9.58162428e-01, 9.58162428e-01, 9.58982773e-01, 9.58982773e-01,\n",
            "       9.59803117e-01, 9.59803117e-01, 9.60623462e-01, 9.60623462e-01,\n",
            "       9.61443806e-01, 9.61443806e-01, 9.62264151e-01, 9.62264151e-01,\n",
            "       9.63084495e-01, 9.63084495e-01, 9.63904840e-01, 9.63904840e-01,\n",
            "       9.64725185e-01, 9.64725185e-01, 9.65545529e-01, 9.65545529e-01,\n",
            "       9.66365874e-01, 9.66365874e-01, 9.67186218e-01, 9.67186218e-01,\n",
            "       9.68006563e-01, 9.68006563e-01, 9.68826907e-01, 9.68826907e-01,\n",
            "       9.69647252e-01, 9.69647252e-01, 9.70467596e-01, 9.70467596e-01,\n",
            "       9.71287941e-01, 9.71287941e-01, 9.72108285e-01, 9.72108285e-01,\n",
            "       9.72928630e-01, 9.72928630e-01, 9.73748975e-01, 9.73748975e-01,\n",
            "       9.74569319e-01, 9.74569319e-01, 9.75389664e-01, 9.75389664e-01,\n",
            "       9.76210008e-01, 9.76210008e-01, 9.77030353e-01, 9.77030353e-01,\n",
            "       9.77850697e-01, 9.77850697e-01, 9.78671042e-01, 9.78671042e-01,\n",
            "       9.79491386e-01, 9.79491386e-01, 9.80311731e-01, 9.80311731e-01,\n",
            "       9.81132075e-01, 9.81132075e-01, 9.81952420e-01, 9.81952420e-01,\n",
            "       9.82772765e-01, 9.82772765e-01, 9.83593109e-01, 9.83593109e-01,\n",
            "       9.84413454e-01, 9.84413454e-01, 9.86054143e-01, 9.86054143e-01,\n",
            "       9.86874487e-01, 9.86874487e-01, 9.87694832e-01, 9.87694832e-01,\n",
            "       9.88515176e-01, 9.88515176e-01, 9.90155865e-01, 9.90155865e-01,\n",
            "       9.90976210e-01, 9.90976210e-01, 9.91796555e-01, 9.91796555e-01,\n",
            "       9.92616899e-01, 9.92616899e-01, 9.93437244e-01, 9.93437244e-01,\n",
            "       9.94257588e-01, 9.94257588e-01, 9.95077933e-01, 9.95077933e-01,\n",
            "       9.95898277e-01, 9.95898277e-01, 9.96718622e-01, 9.96718622e-01,\n",
            "       9.97538966e-01, 9.97538966e-01, 9.98359311e-01, 9.98359311e-01,\n",
            "       9.99179655e-01, 9.99179655e-01, 1.00000000e+00, 1.00000000e+00]),\n",
            "  8: array([0.00000000e+00, 8.43170320e-04, 2.07419899e-01, 2.07419899e-01,\n",
            "       2.90050590e-01, 2.90050590e-01, 4.92411467e-01, 4.92411467e-01,\n",
            "       5.47217538e-01, 5.47217538e-01, 5.79258010e-01, 5.79258010e-01,\n",
            "       6.17200675e-01, 6.17200675e-01, 6.33220911e-01, 6.33220911e-01,\n",
            "       6.34907251e-01, 6.34907251e-01, 6.51770658e-01, 6.51770658e-01,\n",
            "       6.75379427e-01, 6.75379427e-01, 6.81281619e-01, 6.81281619e-01,\n",
            "       6.93929174e-01, 6.93929174e-01, 7.09106239e-01, 7.09106239e-01,\n",
            "       7.09949410e-01, 7.09949410e-01, 7.47892074e-01, 7.47892074e-01,\n",
            "       7.55480607e-01, 7.55480607e-01, 7.56323777e-01, 7.56323777e-01,\n",
            "       7.57166948e-01, 7.57166948e-01, 7.67284992e-01, 7.67284992e-01,\n",
            "       7.71500843e-01, 7.71500843e-01, 7.93423272e-01, 7.93423272e-01,\n",
            "       8.08600337e-01, 8.08600337e-01, 8.10286678e-01, 8.10286678e-01,\n",
            "       8.12816189e-01, 8.12816189e-01, 8.15345700e-01, 8.15345700e-01,\n",
            "       8.16188870e-01, 8.16188870e-01, 8.17875211e-01, 8.17875211e-01,\n",
            "       8.22934233e-01, 8.22934233e-01, 8.27993255e-01, 8.27993255e-01,\n",
            "       8.28836425e-01, 8.28836425e-01, 8.31365936e-01, 8.31365936e-01,\n",
            "       8.39797639e-01, 8.39797639e-01, 8.40640809e-01, 8.40640809e-01,\n",
            "       8.49072513e-01, 8.49072513e-01, 8.49915683e-01, 8.49915683e-01,\n",
            "       8.50758853e-01, 8.50758853e-01, 8.53288364e-01, 8.53288364e-01,\n",
            "       8.61720067e-01, 8.61720067e-01, 8.65092749e-01, 8.65092749e-01,\n",
            "       8.66779089e-01, 8.66779089e-01, 8.70151771e-01, 8.70151771e-01,\n",
            "       8.70994941e-01, 8.70994941e-01, 8.72681282e-01, 8.72681282e-01,\n",
            "       8.74367622e-01, 8.74367622e-01, 8.76053963e-01, 8.76053963e-01,\n",
            "       8.76897133e-01, 8.76897133e-01, 8.77740304e-01, 8.77740304e-01,\n",
            "       8.80269815e-01, 8.80269815e-01, 8.81112985e-01, 8.81112985e-01,\n",
            "       8.83642496e-01, 8.83642496e-01, 8.85328836e-01, 8.85328836e-01,\n",
            "       8.89544688e-01, 8.89544688e-01, 8.90387858e-01, 8.90387858e-01,\n",
            "       8.91231029e-01, 8.91231029e-01, 8.92917369e-01, 8.92917369e-01,\n",
            "       9.00505902e-01, 9.00505902e-01, 9.01349073e-01, 9.01349073e-01,\n",
            "       9.03878583e-01, 9.03878583e-01, 9.05564924e-01, 9.05564924e-01,\n",
            "       9.06408094e-01, 9.06408094e-01, 9.09780776e-01, 9.09780776e-01,\n",
            "       9.14839798e-01, 9.14839798e-01, 9.19055649e-01, 9.19055649e-01,\n",
            "       9.19898820e-01, 9.19898820e-01, 9.20741990e-01, 9.20741990e-01,\n",
            "       9.22428331e-01, 9.22428331e-01, 9.23271501e-01, 9.23271501e-01,\n",
            "       9.24957841e-01, 9.24957841e-01, 9.26644182e-01, 9.26644182e-01,\n",
            "       9.27487352e-01, 9.27487352e-01, 9.28330523e-01, 9.28330523e-01,\n",
            "       9.29173693e-01, 9.29173693e-01, 9.30016863e-01, 9.30016863e-01,\n",
            "       9.30860034e-01, 9.30860034e-01, 9.31703204e-01, 9.31703204e-01,\n",
            "       9.32546374e-01, 9.32546374e-01, 9.33389545e-01, 9.33389545e-01,\n",
            "       9.34232715e-01, 9.34232715e-01, 9.35919056e-01, 9.35919056e-01,\n",
            "       9.37605396e-01, 9.37605396e-01, 9.38448567e-01, 9.38448567e-01,\n",
            "       9.39291737e-01, 9.39291737e-01, 9.41821248e-01, 9.41821248e-01,\n",
            "       9.42664418e-01, 9.42664418e-01, 9.43507589e-01, 9.43507589e-01,\n",
            "       9.45193929e-01, 9.45193929e-01, 9.46880270e-01, 9.46880270e-01,\n",
            "       9.48566610e-01, 9.48566610e-01, 9.50252951e-01, 9.50252951e-01,\n",
            "       9.51096121e-01, 9.51096121e-01, 9.51939292e-01, 9.51939292e-01,\n",
            "       9.52782462e-01, 9.52782462e-01, 9.54468803e-01, 9.54468803e-01,\n",
            "       9.55311973e-01, 9.55311973e-01, 9.56155143e-01, 9.56155143e-01,\n",
            "       9.56998314e-01, 9.56998314e-01, 9.57841484e-01, 9.57841484e-01,\n",
            "       9.58684654e-01, 9.58684654e-01, 9.61214165e-01, 9.61214165e-01,\n",
            "       9.62900506e-01, 9.62900506e-01, 9.63743676e-01, 9.63743676e-01,\n",
            "       9.64586847e-01, 9.64586847e-01, 9.66273187e-01, 9.66273187e-01,\n",
            "       9.67116358e-01, 9.67116358e-01, 9.68802698e-01, 9.68802698e-01,\n",
            "       9.69645868e-01, 9.69645868e-01, 9.70489039e-01, 9.70489039e-01,\n",
            "       9.71332209e-01, 9.71332209e-01, 9.72175379e-01, 9.72175379e-01,\n",
            "       9.73018550e-01, 9.73018550e-01, 9.73861720e-01, 9.73861720e-01,\n",
            "       9.74704890e-01, 9.74704890e-01, 9.75548061e-01, 9.75548061e-01,\n",
            "       9.76391231e-01, 9.76391231e-01, 9.77234401e-01, 9.77234401e-01,\n",
            "       9.78077572e-01, 9.78077572e-01, 9.78920742e-01, 9.78920742e-01,\n",
            "       9.79763912e-01, 9.79763912e-01, 9.80607083e-01, 9.80607083e-01,\n",
            "       9.81450253e-01, 9.81450253e-01, 9.82293423e-01, 9.82293423e-01,\n",
            "       9.83136594e-01, 9.83136594e-01, 9.83979764e-01, 9.83979764e-01,\n",
            "       9.84822934e-01, 9.84822934e-01, 9.85666105e-01, 9.85666105e-01,\n",
            "       9.86509275e-01, 9.86509275e-01, 9.87352445e-01, 9.87352445e-01,\n",
            "       9.88195616e-01, 9.88195616e-01, 9.89038786e-01, 9.89038786e-01,\n",
            "       9.89881956e-01, 9.89881956e-01, 9.90725126e-01, 9.90725126e-01,\n",
            "       9.91568297e-01, 9.91568297e-01, 9.92411467e-01, 9.92411467e-01,\n",
            "       9.93254637e-01, 9.93254637e-01, 9.94097808e-01, 9.94097808e-01,\n",
            "       9.94940978e-01, 9.94940978e-01, 9.95784148e-01, 9.95784148e-01,\n",
            "       9.96627319e-01, 9.96627319e-01, 9.97470489e-01, 9.97470489e-01,\n",
            "       9.98313659e-01, 9.98313659e-01, 9.99156830e-01, 9.99156830e-01,\n",
            "       1.00000000e+00, 1.00000000e+00]),\n",
            "  9: array([0.00000000e+00, 8.23723229e-04, 4.39868204e-01, 4.39868204e-01,\n",
            "       4.76112026e-01, 4.76112026e-01, 5.05766063e-01, 5.05766063e-01,\n",
            "       5.22240527e-01, 5.22240527e-01, 5.65074135e-01, 5.65074135e-01,\n",
            "       5.74135091e-01, 5.74135091e-01, 6.30971993e-01, 6.30971993e-01,\n",
            "       6.40032949e-01, 6.40032949e-01, 6.49093904e-01, 6.49093904e-01,\n",
            "       6.59802306e-01, 6.59802306e-01, 6.77924217e-01, 6.77924217e-01,\n",
            "       6.79571664e-01, 6.79571664e-01, 6.88632619e-01, 6.88632619e-01,\n",
            "       7.40527183e-01, 7.40527183e-01, 7.61120264e-01, 7.61120264e-01,\n",
            "       7.63591433e-01, 7.63591433e-01, 7.71004942e-01, 7.71004942e-01,\n",
            "       7.87479407e-01, 7.87479407e-01, 7.90774300e-01, 7.90774300e-01,\n",
            "       7.91598023e-01, 7.91598023e-01, 7.94892916e-01, 7.94892916e-01,\n",
            "       7.95716639e-01, 7.95716639e-01, 7.96540362e-01, 7.96540362e-01,\n",
            "       8.04777595e-01, 8.04777595e-01, 8.05601318e-01, 8.05601318e-01,\n",
            "       8.08072488e-01, 8.08072488e-01, 8.12191104e-01, 8.12191104e-01,\n",
            "       8.18780890e-01, 8.18780890e-01, 8.24546952e-01, 8.24546952e-01,\n",
            "       8.26194399e-01, 8.26194399e-01, 8.27841845e-01, 8.27841845e-01,\n",
            "       8.31960461e-01, 8.31960461e-01, 8.35255354e-01, 8.35255354e-01,\n",
            "       8.36902801e-01, 8.36902801e-01, 8.37726524e-01, 8.37726524e-01,\n",
            "       8.38550247e-01, 8.38550247e-01, 8.42668863e-01, 8.42668863e-01,\n",
            "       8.43492586e-01, 8.43492586e-01, 8.49258649e-01, 8.49258649e-01,\n",
            "       8.51729819e-01, 8.51729819e-01, 8.54200988e-01, 8.54200988e-01,\n",
            "       8.58319605e-01, 8.58319605e-01, 8.59967051e-01, 8.59967051e-01,\n",
            "       8.62438221e-01, 8.62438221e-01, 8.64909390e-01, 8.64909390e-01,\n",
            "       8.65733114e-01, 8.65733114e-01, 8.66556837e-01, 8.66556837e-01,\n",
            "       8.71499176e-01, 8.71499176e-01, 8.72322900e-01, 8.72322900e-01,\n",
            "       8.73146623e-01, 8.73146623e-01, 8.73970346e-01, 8.73970346e-01,\n",
            "       8.75617792e-01, 8.75617792e-01, 8.76441516e-01, 8.76441516e-01,\n",
            "       8.78088962e-01, 8.78088962e-01, 8.80560132e-01, 8.80560132e-01,\n",
            "       8.81383855e-01, 8.81383855e-01, 8.82207578e-01, 8.82207578e-01,\n",
            "       8.83855025e-01, 8.83855025e-01, 8.84678748e-01, 8.84678748e-01,\n",
            "       8.86326194e-01, 8.86326194e-01, 8.87149918e-01, 8.87149918e-01,\n",
            "       8.87973641e-01, 8.87973641e-01, 8.89621087e-01, 8.89621087e-01,\n",
            "       8.90444811e-01, 8.90444811e-01, 8.91268534e-01, 8.91268534e-01,\n",
            "       8.92092257e-01, 8.92092257e-01, 8.92915980e-01, 8.92915980e-01,\n",
            "       8.93739703e-01, 8.93739703e-01, 8.94563427e-01, 8.94563427e-01,\n",
            "       8.95387150e-01, 8.95387150e-01, 8.96210873e-01, 8.96210873e-01,\n",
            "       8.97858320e-01, 8.97858320e-01, 8.98682043e-01, 8.98682043e-01,\n",
            "       9.00329489e-01, 9.00329489e-01, 9.01153213e-01, 9.01153213e-01,\n",
            "       9.02800659e-01, 9.02800659e-01, 9.03624382e-01, 9.03624382e-01,\n",
            "       9.04448105e-01, 9.04448105e-01, 9.05271829e-01, 9.05271829e-01,\n",
            "       9.06095552e-01, 9.06095552e-01, 9.06919275e-01, 9.06919275e-01,\n",
            "       9.08566722e-01, 9.08566722e-01, 9.09390445e-01, 9.09390445e-01,\n",
            "       9.11037891e-01, 9.11037891e-01, 9.11861614e-01, 9.11861614e-01,\n",
            "       9.12685338e-01, 9.12685338e-01, 9.14332784e-01, 9.14332784e-01,\n",
            "       9.15156507e-01, 9.15156507e-01, 9.15980231e-01, 9.15980231e-01,\n",
            "       9.16803954e-01, 9.16803954e-01, 9.17627677e-01, 9.17627677e-01,\n",
            "       9.18451400e-01, 9.18451400e-01, 9.19275124e-01, 9.19275124e-01,\n",
            "       9.21746293e-01, 9.21746293e-01, 9.23393740e-01, 9.23393740e-01,\n",
            "       9.24217463e-01, 9.24217463e-01, 9.26688633e-01, 9.26688633e-01,\n",
            "       9.27512356e-01, 9.27512356e-01, 9.28336079e-01, 9.28336079e-01,\n",
            "       9.29159802e-01, 9.29159802e-01, 9.29983526e-01, 9.29983526e-01,\n",
            "       9.30807249e-01, 9.30807249e-01, 9.31630972e-01, 9.31630972e-01,\n",
            "       9.32454695e-01, 9.32454695e-01, 9.33278418e-01, 9.33278418e-01,\n",
            "       9.34102142e-01, 9.34102142e-01, 9.34925865e-01, 9.34925865e-01,\n",
            "       9.37397035e-01, 9.37397035e-01, 9.38220758e-01, 9.38220758e-01,\n",
            "       9.39044481e-01, 9.39044481e-01, 9.39868204e-01, 9.39868204e-01,\n",
            "       9.40691928e-01, 9.40691928e-01, 9.41515651e-01, 9.41515651e-01,\n",
            "       9.42339374e-01, 9.42339374e-01, 9.43163097e-01, 9.43163097e-01,\n",
            "       9.43986820e-01, 9.43986820e-01, 9.44810544e-01, 9.44810544e-01,\n",
            "       9.45634267e-01, 9.45634267e-01, 9.46457990e-01, 9.46457990e-01,\n",
            "       9.47281713e-01, 9.47281713e-01, 9.48929160e-01, 9.48929160e-01,\n",
            "       9.49752883e-01, 9.49752883e-01, 9.50576606e-01, 9.50576606e-01,\n",
            "       9.51400329e-01, 9.51400329e-01, 9.52224053e-01, 9.52224053e-01,\n",
            "       9.53047776e-01, 9.53047776e-01, 9.53871499e-01, 9.53871499e-01,\n",
            "       9.54695222e-01, 9.54695222e-01, 9.55518946e-01, 9.55518946e-01,\n",
            "       9.56342669e-01, 9.56342669e-01, 9.57166392e-01, 9.57166392e-01,\n",
            "       9.57990115e-01, 9.57990115e-01, 9.58813839e-01, 9.58813839e-01,\n",
            "       9.59637562e-01, 9.59637562e-01, 9.60461285e-01, 9.60461285e-01,\n",
            "       9.61285008e-01, 9.61285008e-01, 9.62108731e-01, 9.62108731e-01,\n",
            "       9.62932455e-01, 9.62932455e-01, 9.63756178e-01, 9.63756178e-01,\n",
            "       9.64579901e-01, 9.64579901e-01, 9.65403624e-01, 9.65403624e-01,\n",
            "       9.66227348e-01, 9.66227348e-01, 9.67874794e-01, 9.67874794e-01,\n",
            "       9.68698517e-01, 9.68698517e-01, 9.69522241e-01, 9.69522241e-01,\n",
            "       9.70345964e-01, 9.70345964e-01, 9.71169687e-01, 9.71169687e-01,\n",
            "       9.71993410e-01, 9.71993410e-01, 9.72817133e-01, 9.72817133e-01,\n",
            "       9.73640857e-01, 9.73640857e-01, 9.74464580e-01, 9.74464580e-01,\n",
            "       9.75288303e-01, 9.75288303e-01, 9.76112026e-01, 9.76112026e-01,\n",
            "       9.76935750e-01, 9.76935750e-01, 9.77759473e-01, 9.77759473e-01,\n",
            "       9.78583196e-01, 9.78583196e-01, 9.80230643e-01, 9.80230643e-01,\n",
            "       9.81054366e-01, 9.81054366e-01, 9.81878089e-01, 9.81878089e-01,\n",
            "       9.82701812e-01, 9.82701812e-01, 9.83525535e-01, 9.83525535e-01,\n",
            "       9.84349259e-01, 9.84349259e-01, 9.85172982e-01, 9.85172982e-01,\n",
            "       9.85996705e-01, 9.85996705e-01, 9.86820428e-01, 9.86820428e-01,\n",
            "       9.87644152e-01, 9.87644152e-01, 9.88467875e-01, 9.88467875e-01,\n",
            "       9.89291598e-01, 9.89291598e-01, 9.90115321e-01, 9.90115321e-01,\n",
            "       9.90939044e-01, 9.90939044e-01, 9.91762768e-01, 9.91762768e-01,\n",
            "       9.92586491e-01, 9.92586491e-01, 9.93410214e-01, 9.93410214e-01,\n",
            "       9.94233937e-01, 9.94233937e-01, 9.95057661e-01, 9.95057661e-01,\n",
            "       9.95881384e-01, 9.95881384e-01, 9.96705107e-01, 9.96705107e-01,\n",
            "       9.97528830e-01, 9.97528830e-01, 9.98352554e-01, 9.98352554e-01,\n",
            "       9.99176277e-01, 9.99176277e-01, 1.00000000e+00, 1.00000000e+00])},\n",
            " {0: 0.9876475340323964,\n",
            "  1: 0.9981742970632499,\n",
            "  2: 0.9888839305209834,\n",
            "  3: 0.9784760346283782,\n",
            "  4: 0.9965958925046039,\n",
            "  5: 0.9986608438559974,\n",
            "  6: 0.9912395423616542,\n",
            "  7: 0.9906469612515989,\n",
            "  8: 0.9949908790397558,\n",
            "  9: 0.9902931862066605},\n",
            " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            " 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 10\n",
        "for data in results_dict['PCA-10']['roc_auc_data']:\n",
        "  fpr, tpr, roc_auc, class_names, n_classes = data\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown']\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# conf_matrix = results_dict['PCA-10']['Confusion Matrix']\n",
        "\n",
        "# # Plot confusion matrix\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# classes = np.unique(y)\n",
        "# tick_marks = np.arange(len(classes))\n",
        "# plt.xticks(tick_marks, classes)\n",
        "# plt.yticks(tick_marks, classes)\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('True')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "s8IL5iFEkkIl",
        "outputId": "cf707dcd-42b9-4fb5-fe4f-4799696e91ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-8c804ba0c904>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mplot_roc_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-8c804ba0c904>\u001b[0m in \u001b[0;36mplot_roc_curves\u001b[0;34m(fpr, tpr, roc_auc, class_names, n_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'darkorange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'purple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'brown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Class {i} (AUC = {roc_auc[i]:.2f})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9UAAAH5CAYAAACPux17AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0yklEQVR4nO3df3CdZZ03/k/SNglIUmC7TUuIW8GtBcGyFukWZJzuRDrKU5f5frt00Cl9WNBViwN0XKUgiRqlrAMsO9tqHxEW95lB6mHU8ZFOu1jp+GXpPowt7CJSGEQsBpLSRZpQStIm9/ePNidJk7Q5d8+vJK/XzJk55z73fc4n9Lb2neu6PldFkiRJAAAAADmrLHUBAAAAMF4J1QAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAAClNLXUBY9HX1xevvvpq1NbWRkVFRanLAQAAYIJLkiS6urrijDPOiMrK0cejx0WofvXVV6OxsbHUZQAAADDJvPLKK3HmmWeO+v64CNW1tbURcfiHqaurK3E1AAAATHSdnZ3R2NiYzaOjGRehun/Kd11dnVANAABA0RxvCbJGZQAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAAp5Ryqf/nLX8bSpUvjjDPOiIqKivjJT35y3Gu2bdsWH/zgB6O6ujre+973xgMPPJCiVAAAACgvOYfq/fv3x/z582P9+vVjOv93v/tdXH755bF48eJ4+umn48Ybb4zrrrsutmzZknOxAAAAUE6m5nrBxz72sfjYxz425vM3bNgQ73nPe+Kuu+6KiIhzzjknHn/88fjHf/zHWLJkSa5fDwAAAGUj51Cdq+3bt0dTU9OQY0uWLIkbb7xx1Gu6u7uju7s7+7qzs7NQ5UHOdm/ZEv+1bl0c3L8/b5954O2Izs6IviRvH8kJmpocjKq+7oiYgH8oFUmUw89VEREVSRIVpS4EACi6vt5psfK3/7fUZeRFwUN1e3t71NfXDzlWX18fnZ2dceDAgTjppJOGXbN27dr42te+VujSGEU+Q+NEDIunVnYU5HPrKiKkizIzpdQFAABQ7goeqtNYs2ZNrF69Ovu6s7MzGhsbS1jR+DFSIM412OY7NE7ksHjw4PBfCjHxJBV9efmcwyOzE/Z/DgAAY9bXO63UJeRNwUP1rFmzoqNjaEjr6OiIurq6EUepIyKqq6ujurq60KWVtbGMFo8UlkcLxGmD7RsH649/0nFMjYNRHd1RUeDppoX+/MGSvqnx33vOi7e6Bn7Z81Zl7Ql9ZmVlRF1dxCj/s8irA4cORGd3Z/Qlw8PiSQcjTnmnLyqP+s9ZyskGpQqh0yq648Lqx+Ksab/Jy+fNnigrWU7N426MNZURS+siFvgFFcCkV1UbcUlrxNxlpa4EclLwUL1o0aLYtGnTkGOPPvpoLFq0qNBfPS71h+nOl14a0/nHCssjBeLKMU5n7U7eFf/2zvXxzKHDzeTec+DZWNC5Lab1dR/nyuFO6evK+ZoTVdtwYgF3LCrqImrrIqprq2Nx6+I4d9m5Bf/OITKZiObmePuPe6KzuzOSEQLyaHr7Rj/3zLfzUdwEkUTEgSOPfMtnMM1VRWVEVV3E1ByDbG1tRGtrxDL/2AEA6JdzqH7rrbfixRdfzL7+3e9+F08//XScfvrp8e53vzvWrFkTbW1t8a//+q8REfHZz3421q1bF1/60pfib//2b+MXv/hF/PCHP4xHHnkkfz/FBLF7y5Z4fNC0935v9tVHX++xrx0clo8OxBHp/i18WebZ2Na8Prq7uqPrjfwE40KH3ZIF3BOQeTYTzduao6t7+H/jy//zQHxxc2ec0j08BM/ed/jYyUcehfBa3dDXFRFRV1ERJ1eMcew4h6A/JhXjMIgeTTAFAJhQcg7Vv/rVr2Lx4sXZ1/1rn1euXBkPPPBAvPbaa7F79+7s++95z3vikUceiZtuuin+6Z/+Kc4888z43ve+ZzutI3Zv2RKP374uOl/fH3UVQ6dut3WfFQ/vuT6e7Br636qhYeD5aP8+v+k43/ts5tnY1rwturtGH3nuahs5SKcJxuMx7ObLaKG5PzAvOnAoHh3l2jPH+LuMPxz5I5mSwzzpioioi4iTR7qmOiKWRMyeP9KVKTtHn9Jw/HNGYzoYAABlqiJJkrLvy9zZ2RnTp0+Pffv2RV1d3fEvGEce/MjSiL3Dp3r/0yt3x5NdS8YUoAcbS1iOGD0wj6a2oXZSBONjjRqncfl/HogbN70RtSP8cYw1MPc7etQ4IuKtqog7/yril++PaK2OWDbar8lOJNCeKIEYAIBxaKw5tCy7f090R5bCxpwDW2LFuw4H6r6kMt489KdxsPLw1O3OhiWRyWGGaH+Y3rtrb871HGvkeaIG6dHCc1tXW+rPXPZsxNcfiyEBeqzBub1u0LTqo6dM948aXzJyMP5fx/pggRYAAApKqC6B5uaIurYtsaJxYP30az1z4j13/J9Ytuz4U7cHO1aYPt407YkamEczOEiPJTw31I5tdLd/Gvef7zl0zPPerhthqvWRwDxrfsSI06pPaRCMAQCgjAnVRZbJHA7UNzQObUj2Zyuuz6lv0bHC9Ix5MyZVWB7JSCPRowXpo8NzbXVttC5ujWXnDvoD6Z9e8Mc9ET2dQ0eT3xyhGdf0Qc+PBOeTB69PPt50bEEaAADGBWuqi+z/OWdLLKscGqg/fPfd8e7jNG47eq30SGuiJ0OYHuua5+ONRDfUNgwPz89nIp5ojugZ9Nk7DkT8n86I9mOPQmfNjIglETHKVG1hGQAAxgdrqstQJhOx6OC6wyOXRxwrUA8O0sdqLDaRw/TRITrNmueGk07Pji7XVlRGa21dLKuJiOiK+P9uPPyIiHirLeI/I2JLRPSvi943wgf2j0IP3t6ppjJiaV3EoplCMwAATCJCdZFkMhF3Xrslbmgc6PR9vED98JUPj/he/1rpibgmOpcQ3VB57D2LswH60BsR2a2F+yIOvRHxVgwP0BEjh+h+s6YKzgAAwBBCdZH8oPmoddQzzjrmlO9tzduGvJ7oW1plHl0dzU+uj12HekY9p+FIk6/a6N8+aoS1zEOCcl9EvDH0/cGjyyOthR7yhUemcI9lLzMAAGBSEqqL5NJk3ZDXH77l+hHP65/y/d8v/Hf22N9k/mbiBOkR1i1n3jkQV775xrBTh4XoU0dZp9y/7vmdvuMH5Rjl/Vw3BAcAAAihuigymYhpffsjphx+faxp30d39J4xb8b4DdQjNf56a2A6d+ZQRHN3xK6jWuXNmzL1yLrnI3O2+5t7/WdyuAN311Hry9uGB/KIGBqURyNAAwAAJ0CoLoLm5ohVR553JvUjBuqjR6grKiviT+b+SSxuXVzESnMwUmA+2lvD10P3B+muiGgboe985pLVsazprkEHjmxl1XVjRNsYmpQ1NAjKAABA0QjVBda/L/XpjR0REVE3feTzjh6h/pO5fxKrnls18snFdpwR58EGh+Yhjqxlbusbefr1vBnzhm5v1R+md+0auaajR6EFaQAAoASE6gJrbo7425kD66nrZrxr2DnPZp7NBuqyGqHuD9NvjBJs40iIPjg1upLDYXm00BzJ8OP9e0Xf3/PxWLRuU8TaGyPixsNvjjQqbRQaAAAoM0J1gc05sCUa3jWwjdYHrh/eoGxwp++yGKE+Vpg+ZWCEOHMoiSv3vhoRh0b8mIbakdc011bXDoxKZzIRV1557HrmzROkAQCAsiRUF9hlNYNGqc8avo3W4FHqiCjtCPWxwvTp87J7M/fvJb1r79Dz+kP0kNB8LCMFal24AQCAcUSoLrDqiv3Z58cbpS5pp+/nMxE/G2HEeFCYjojIPJuJKx8efl7mbzLHD9HZk0dZL53JCNAAAMC4IlQXUCYT0dcbEZURb/aN3PW7u6s7+7wko9SjjU4fFaYjRg7UwxqMjSbbxbtr5PXSAjUAADAOCdUF9IPmLbFs2uGu35UVQ9/r30LrrdfeioiI2oba4oxSH93Je6Qu3kszQ8J0xMiBesyj08daN229NAAAMI4J1QV0aTJoPfWfDnT9fjbzbDx85cNDzq2urS58QaNN8e43wrrpru7D4buta2j4HlOgHm2aty7eAADABCFUF9Dg9dQfvmVgPfXgddQRh9dSF2Xq9xPNQ1/3d/Kuqh0aptefM6wJ2WBjHqG2bhoAAJjghOoiGLye+uhu33+T+ZviTfsevG560BTvzLOZaH70tuj62Y3DRqQjcuzqPXjt9GuvHT5WWRkxd66RaQAAYMIRqousJN2+j572ffq8yBxMonn9OdHV3TVikI7IoQlZv9HWTs+dG/HccykKBwAAKG9CdZGVpNv3UdO+M40fH3FbrIjDo9Jj3md6yIeOsud0/9ppAACACUioLpGidvseNO07M391XPnvdw85JXWQzn7oCIHa2mkAAGASEKoLZPeWLXFqZceQY89mno2utq7iFTFo2nfmUETzoarYdVSgHnPTsZGM1t1boAYAACYJobpA/mvdwHZa3cnh7bQGr6cu2BZag/ehPrIHdeZQxJXvRET0DDk1VaAe3IisbYS12AI1AAAwiVSWuoCJ6uD+ge20/u2dw9tpFXQ99fOZiH855/DI9Bu7soE6IqK5e+ip82bMSz9C3T8yfXSgnjdPoAYAACYdI9UF9sbB+njm0JIhx/K+nvro7t79TmmIzKEkdr31avbQCU/37p/qXVkZMXv2QCMyYRoAAJiEhOoC2L1lSxzo6Dj+ifkwUqA+fV7EJa2ROZgM6fI9b8a8EwvUg5uR2SYLAABAqC6EweupD/S9K2prC9CkrH/t9BtHNQlbmomYezg4N68/Z8hbrYtPYGur5qHbctkmCwAAQKguiMHrqR/ec3203h+x7bZt2WMn1KRstDAdEbE0E5mDSTSvPye6urvitbdey76Vt2nf/a9N9wYAANCorJDeOFgfbXVLYtmyPDUp65/qfXSgPn1edoS6eVtz7Nq7K9q62qIv6YuIPE/7njdPoAYAADjCSHWRpW5Sdoy10/3TvTPPZmLX3sOBu7KiMmafMjtqq2tN+wYAACgQobrcjWHtdMThQD24KdncP5kbz606wUZipn0DAAAck1Bdro6zdvpYgTriBJuSRZj2DQAAMAbWVJerkQL1oLXT/UYK1CfclOycc4YG6gjTvgEAAEZgpLoADrw99HVO22n1j1D/8YXDrysqI06bO2TtdL+CBOqjw3T/caPUAAAAwwjVebZ7y5aIro7s69raiG3N27Kvj7ud1tEj1KfNjbhmYG105tlMNG9rjq7urmjrahtyad4D9bx5h0eoBWoAAIARCdV59l/r1mWfH+h7V3xx6bPxh7v3Zo8ddzutniMj2oNHqI8YaWQ6+96JBOqI4V2+jU4DAAAcl1CdZwf3788+/8Wh6+N/bNqWfT1j3oxjb6f1fCbirSOjz++aPWyE+uhA3VDbkN0y64QCtS7fAAAAqQjVBfLGwfp45tCS+GjXs9ljxx2lfmLQaHFVbfZp3tdOD/kgXb4BAADS0v27gN5zYKBBWW1D7fFHqQevpT4y7btggVqXbwAAgBNmpLqAFnRuyz4fU4OyfqfPi8zBJJrXnxO79g7dVitvI9TNzUOnfEeY9g0AAJAjobqApvV1Z58fc+r3UaPUmcaPj9iQLK9TvvsDdWVlxNy5unwDAACkIFQXwXGnfg8apc7UnBFX/vvdQ96eN2PeiTcjy37BUWuo586NeO650c8HAABgVEJ1qR01St3cUzHk7byNTme/4Kits6yhBgAASE2jsgKZGgfjlL6u45941Cj1rs62gdf5DtS2zgIAAMgrobpAqmNgPfUxm5T1HA7emUMRV+59NXt43ox5+Q3UEUNHqW2dBQAAcMKE6gKpiCT7fNQmZc9nIt46PDLdfHDoTPzWxXmeln30KLVp3wAAACdMqC6wYzYpOzL1O3MoYlfvoezhvE/7jjBKDQAAUABCdakMalDWPDBTvDDTvo1SAwAAFIRQXQrPZyJ+dnhbq8yhiF0DM8ULM+178BZaRqkBAADyRqguhUEdvws+Sm0LLQAAgIIRqkthUMfvgo9S20ILAACgYITqYjvS8TtzKOLKdwYO532U2rRvAACAghOqi+3I1O/B074j8jxKfXSgjjDtGwAAoACE6mLr6Ro27TvvW2gdvY7atG8AAICCEKoLpCKSUd8raHMy66gBAACKRqgusOra6iGvM+8cKFxzMuuoAQAAikqoLrDFrYuHvG7u6sw+z/sote2zAAAAikqoLqC3Kmvj3GXnDhx4PhNdfYeyL/M+Sm3aNwAAQFEJ1cX0xMBIcsOUqYUbpTbtGwAAoCiE6iLKdO6Jtv711FV1efzgo0apTfsGAAAoCqG6iAavp65918w8frBRagAAgFIQqouoK+nLPs/reuquroHnRqkBAACKRqguksyjq6Ot73CobqiszO966n4NDUapAQAAikioLpLmJ9dnn9dWTs3fB2cyEW1t+fs8AAAAxkyoLoLMs5nYdagn+7p14fX5+/DB66lra/P3uQAAAByXUJ1nh94+OOxY87aB4DtvytRY1nRX/r7QemoAAICSEarzrLuzO/v8YGV1RER0dQ8E39baPG6lNZj11AAAAEUnVOdZkiTZ5zvqFkfm2Uy0dR1e89xQEbGs5qT8fZn11AAAACWVx45ZDJZERfzupHOjedv/mz2W9xXP1lMDAACUlJHqAhsy9bs6jx+cyUTs2jXw2npqAACAohOqi6ShImLZ1IioytOI8uBR6nnzrKcGAAAogVShev369TFnzpyoqamJhQsXxpNPPnnM8++555543/veFyeddFI0NjbGTTfdFO+8806qgse9S/I0oqzrNwAAQMnlHKo3btwYq1evjpaWlti5c2fMnz8/lixZEnv27Bnx/AcffDBuvvnmaGlpieeeey7uu+++2LhxY9xyyy0nXHy52b1lS0ypfHv0E05piJibhxHlwQ3KdP0GAAAomZxD9d133x2f/vSn45prrolzzz03NmzYECeffHLcf//9I57/xBNPxCWXXBKf/OQnY86cOXHZZZfFVVddddzR7fHov9atyz7v7ZtWuN5hGpQBAACUhZxCdU9PT+zYsSOampoGPqCyMpqammL79u0jXnPxxRfHjh07siH6pZdeik2bNsXHP/7xUb+nu7s7Ojs7hzzGg4P792efv7pnQeFmZZv6DQAAUBZy2lJr79690dvbG/X19UOO19fXx67BnagH+eQnPxl79+6ND3/4w5EkSRw6dCg++9nPHnP699q1a+NrX/taLqWVlYMHT4rO/e+J5JxMtD1bwH2kTf0GAAAoqYJ3/962bVvcfvvt8e1vfzt27twZP/rRj+KRRx6J1mOMsK5Zsyb27duXfbzyyiuFLrMgmrcNTNM2SRsAAGDiyWmkesaMGTFlypTo6OgYcryjoyNmzZo14jW33XZbrFixIq677rqIiDj//PNj//798ZnPfCZuvfXWqKwcnuurq6ujujqfmzqXxrA9qvOxndbgJmUAAACUVE4j1VVVVbFgwYLYunVr9lhfX19s3bo1Fi1aNOI1b7/99rDgPGXKlIiISJIk13rHpewe1fnYTkuTMgAAgLKR00h1RMTq1atj5cqVceGFF8ZFF10U99xzT+zfvz+uueaaiIi4+uqro6GhIdauXRsREUuXLo277747/uIv/iIWLlwYL774Ytx2222xdOnSbLieFPK1nZYmZQAAAGUj51C9fPnyeP3116O5uTna29vjggsuiM2bN2ebl+3evXvIyPRXvvKVqKioiK985SvR1tYWf/qnfxpLly6Nb37zm/n7KSYjTcoAAABKLudQHRFx/fXXx/XXXz/ie9u2bRv6BVOnRktLS7S0tKT5KgaznhoAAKCsFLz7N3mSyURceeXAa+upAQAASk6oLpSpB6KtK4+jyoMblEVYTw0AAFAGhOoC6avqzD7Py5jy4AZlmYz11AAAAGVAqC6YvuyzE96jevBaag3KAAAAyoZQXWB52aPa3tQAAABlSaguhhPdo9re1AAAAGVJqB5PTP0GAAAoK0I1AAAApCRUl7vBTcoAAAAoK0J1udOkDAAAoGwJ1YVS0Xf8c8ZCkzIAAICyJVQXWG3Eie1R3U+TMgAAgLIjVBdYa3Wc2B7VAAAAlC2hOo8OvX1wyOuGiohlp57AHtWalAEAAJQ1oTqPuju7B55Xdx/jzDHIZCKuvHLgtSZlAAAAZUeozqMkSbLPH1v82Il92OCu3xGalAEAAJQhoboAkookfvP+35zYhwzu+p3JaFIGAABQhoTqcqfrNwAAQNkSqgEAACAloboc6foNAAAwLgjV5WhwkzJdvwEAAMqWUF1oVSlC8eAmZbp+AwAAlC2huiAGttaKS04gFGtSBgAAUNaE6gKqrZwaMVcoBgAAmKiE6gJqra0rdQkAAAAUkFBdIJVds2JZzUm5X6jzNwAAwLghVJcbnb8BAADGDaG63Oj8DQAAMG4I1eVK528AAICyJ1QDAABASkI1AAAApCRUAwAAQEpCdTmxnRYAAMC4IlSXE9tpAQAAjCtCdTmxnRYAAMC4IlSXi8FTv22nBQAAMC4I1eXC1G8AAIBxR6guF6Z+AwAAjDtCdbkx9RsAAGDcEKoBAAAgJaEaAAAAUhKqy8Hgzt8AAACMG0J1IVWNsYu3zt8AAADjklBdSJeMsYu3zt8AAADjklBdMBURc3Ps4q3zNwAAwLgiVJea9dQAAADjllBdatZTAwAAjFtCdalZTw0AADBuCdXlwnpqAACAcUeoBgAAgJSEagAAAEhJqAYAAICUhGoAAABISaguJXtUAwAAjGtCdSnZoxoAAGBcE6pLyR7VAAAA45pQXQ7sUQ0AADAuCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUJ1HSZKUugQAAACKSKjOo74YCNWVB99VwkoAAAAoBqG6QOqe+FKpSwAAAKDAhOqCqIiTXvwfxz4lk4loaytOOQAAABSEUF0qzc0Dz2trS1cHAAAAqQnVpdLVNfC8tbV0dQAAAJCaUF1qDQ0Ry5aVugoAAABSEKrzyY5aAAAAk4pQXSC1NW+VugQAAAAKTKgukNald47+ps7fAAAAE4JQXSDLFjwy+ps6fwMAAEwIqUL1+vXrY86cOVFTUxMLFy6MJ5988pjnv/nmm7Fq1aqYPXt2VFdXx9y5c2PTpk2pCp4QdP4GAACYEKbmesHGjRtj9erVsWHDhli4cGHcc889sWTJknj++edj5syZw87v6emJj370ozFz5sx4+OGHo6GhIX7/+9/Hqaeemo/6xzedvwEAAMa1nEP13XffHZ/+9KfjmmuuiYiIDRs2xCOPPBL3339/3HzzzcPOv//+++ONN96IJ554IqZNmxYREXPmzDmxqgEAAKAM5DT9u6enJ3bs2BFNTU0DH1BZGU1NTbF9+/YRr/npT38aixYtilWrVkV9fX2cd955cfvtt0dvb++o39Pd3R2dnZ1DHhOGJmUAAAATRk6heu/evdHb2xv19fVDjtfX10d7e/uI17z00kvx8MMPR29vb2zatCluu+22uOuuu+Ib3/jGqN+zdu3amD59evbR2NiYS5nlTZMyAACACaPg3b/7+vpi5syZ8d3vfjcWLFgQy5cvj1tvvTU2bNgw6jVr1qyJffv2ZR+vvPJKocssHk3KAAAAJoyc1lTPmDEjpkyZEh0dHUOOd3R0xKxZs0a8Zvbs2TFt2rSYMmVK9tg555wT7e3t0dPTE1VVVcOuqa6ujurq6lxKG380KQMAABj3chqprqqqigULFsTWrVuzx/r6+mLr1q2xaNGiEa+55JJL4sUXX4y+vr7ssRdeeCFmz549YqAGAACA8SLn6d+rV6+Oe++9N77//e/Hc889F5/73Odi//792W7gV199daxZsyZ7/uc+97l444034oYbbogXXnghHnnkkbj99ttj1apV+fspAAAAoARy3lJr+fLl8frrr0dzc3O0t7fHBRdcEJs3b842L9u9e3dUVg5k9cbGxtiyZUvcdNNN8YEPfCAaGhrihhtuiC9/+cv5+ykAAACgBCqSJElKXcTxdHZ2xvTp02Pfvn1RV1dX6nJG9cD7FkTV1Hei51BN/M/VHRF/94fhJ5155uEttRoaIv4wwvsAAACU3FhzaMG7fwMAAMBEJVQDAABASkJ1MWUyh6d+AwAAMCEI1YVSVTv8WHPzwPPaEd4HAABgXBGqC+WS1uHHuroGnreO8D4AAADjilBdKHOXjf5eQ0PEsmO8DwAAwLggVAMAAEBKQjUAAACkJFQDAABASkJ1sdhOCwAAYMIRqovFdloAAAATjlBdLLbTAgAAmHCE6mKznRYAAMCEIVQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQnUxZDIRbW2lrgIAAIA8E6qLobl54HltbenqAAAAIK+E6mLo6hp43tpaujoAAADIK6G6mBoaIpYtK3UVAAAA5IlQDQAAACkJ1QAAAJCSUA0AAAApCdWFZjstAACACUuoLjTbaQEAAExYQnWh2U4LAABgwhKqi8V2WgAAABOOUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVhZTJRLS1lboKAAAACkSoLqTm5oHntbWlqwMAAICCEKoLqatr4Hlra+nqAAAAoCCE6mJoaIhYtqzUVQAAAJBnQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVBdKJhPR1lbqKgAAACggobpQmpsHntfWlq4OAAAACiZVqF6/fn3MmTMnampqYuHChfHkk0+O6bqHHnooKioq4oorrkjzteNLV9fA89bW0tUBAABAweQcqjdu3BirV6+OlpaW2LlzZ8yfPz+WLFkSe/bsOeZ1L7/8cnzxi1+MSy+9NHWx41JDQ8SyZaWuAgAAgALIOVTffffd8elPfzquueaaOPfcc2PDhg1x8sknx/333z/qNb29vfGpT30qvva1r8VZZ511QgUDAABAucgpVPf09MSOHTuiqalp4AMqK6OpqSm2b98+6nVf//rXY+bMmXHttdeO6Xu6u7ujs7NzyAMAAADKTU6heu/evdHb2xv19fVDjtfX10d7e/uI1zz++ONx3333xb333jvm71m7dm1Mnz49+2hsbMylTAAAACiKgnb/7urqihUrVsS9994bM2bMGPN1a9asiX379mUfr7zySgGrBAAAgHSm5nLyjBkzYsqUKdHR0THkeEdHR8yaNWvY+b/97W/j5ZdfjqVLl2aP9fX1Hf7iqVPj+eefj7PPPnvYddXV1VFdXZ1LaQAAAFB0OY1UV1VVxYIFC2Lr1q3ZY319fbF169ZYtGjRsPPnzZsXzzzzTDz99NPZxyc+8YlYvHhxPP3006Z1AwAAMK7lNFIdEbF69epYuXJlXHjhhXHRRRfFPffcE/v3749rrrkmIiKuvvrqaGhoiLVr10ZNTU2cd955Q64/9dRTIyKGHQcAAIDxJudQvXz58nj99dejubk52tvb44ILLojNmzdnm5ft3r07KisLulQbAAAAykJFkiRJqYs4ns7Ozpg+fXrs27cv6urqSl3OqB5434KomvpO9Byqif+5vyOirS2ioSHiD38odWkAAADkYKw51JAyAAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQnUBVERyuEkZAAAAE5pQXQAVg/up19aWrA4AAAAKS6gugIrBL1pbS1UGAAAABSZUF1JDQ8SyZaWuAgAAgAIRqgEAACAloRoAAABSEqoBAAAgJaEaAAAAUhKqAQAAICWhGgAAAFISqgEAACAlobqQamtLXQEAAAAFJFQXUmtrqSsAAACggITqQmloiFi2rNRVAAAAUEBCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFTnUUUkpS4BAACAIhKq86hicKaurS1ZHQAAABSHUJ1HFYNftLaWqgwAAACKRKgulGXLSl0BAAAABSZUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApJQqVK9fvz7mzJkTNTU1sXDhwnjyySdHPffee++NSy+9NE477bQ47bTToqmp6ZjnAwAAwHiRc6jeuHFjrF69OlpaWmLnzp0xf/78WLJkSezZs2fE87dt2xZXXXVVPPbYY7F9+/ZobGyMyy67LNra2k64eAAAACiliiRJklwuWLhwYXzoQx+KdevWRUREX19fNDY2xhe+8IW4+eabj3t9b29vnHbaabFu3bq4+uqrx/SdnZ2dMX369Ni3b1/U1dXlUm5R/e+5H4wp07qj92B1rHhhZ6nLAQAAIKWx5tCcRqp7enpix44d0dTUNPABlZXR1NQU27dvH9NnvP3223Hw4ME4/fTTRz2nu7s7Ojs7hzwAAACg3OQUqvfu3Ru9vb1RX18/5Hh9fX20t7eP6TO+/OUvxxlnnDEkmB9t7dq1MX369OyjsbExlzIBAACgKIra/fuOO+6Ihx56KH784x9HTU3NqOetWbMm9u3bl3288sorRawSAAAAxmZqLifPmDEjpkyZEh0dHUOOd3R0xKxZs4557Z133hl33HFH/PznP48PfOADxzy3uro6qqurcykNAAAAii6nkeqqqqpYsGBBbN26NXusr68vtm7dGosWLRr1um9961vR2toamzdvjgsvvDB9tQAAAFBGchqpjohYvXp1rFy5Mi688MK46KKL4p577on9+/fHNddcExERV199dTQ0NMTatWsjIuIf/uEform5OR588MGYM2dOdu31KaecEqecckoefxQAAAAorpxD9fLly+P111+P5ubmaG9vjwsuuCA2b96cbV62e/fuqKwcGAD/zne+Ez09PbFs2bIhn9PS0hJf/epXT6x6AAAAKKGc96kuBftUAwAAUEwF2acaAAAAGCBUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApJQqVK9fvz7mzJkTNTU1sXDhwnjyySePeX4mk4l58+ZFTU1NnH/++bFp06ZUxQIAAEA5yTlUb9y4MVavXh0tLS2xc+fOmD9/fixZsiT27Nkz4vlPPPFEXHXVVXHttdfGU089FVdccUVcccUV8etf//qEiwcAAIBSqkiSJMnlgoULF8aHPvShWLduXURE9PX1RWNjY3zhC1+Im2++edj5y5cvj/3798fPfvaz7LG//Mu/jAsuuCA2bNgwpu/s7OyM6dOnx759+6Kuri6Xcovqf8/9YEyZ1h29B6tjxQs7S10OAAAAKY01h+Y0Ut3T0xM7duyIpqamgQ+orIympqbYvn37iNds3759yPkREUuWLBn1/IiI7u7u6OzsHPIAAACAcpNTqN67d2/09vZGfX39kOP19fXR3t4+4jXt7e05nR8RsXbt2pg+fXr20djYmEuZAAAAUBRl2f17zZo1sW/fvuzjlVdeKXVJY9LXOy16D1ZHX++0UpcCAABAEUzN5eQZM2bElClToqOjY8jxjo6OmDVr1ojXzJo1K6fzIyKqq6ujuro6l9LKwsrf/t9SlwAAAEAR5TRSXVVVFQsWLIitW7dmj/X19cXWrVtj0aJFI16zaNGiIedHRDz66KOjng8AAADjRU4j1RERq1evjpUrV8aFF14YF110Udxzzz2xf//+uOaaayIi4uqrr46GhoZYu3ZtRETccMMN8ZGPfCTuuuuuuPzyy+Ohhx6KX/3qV/Hd7343vz8JAAAAFFnOoXr58uXx+uuvR3Nzc7S3t8cFF1wQmzdvzjYj2717d1RWDgyAX3zxxfHggw/GV77ylbjlllviz//8z+MnP/lJnHfeefn7KQAAAKAEct6nuhTGyz7VAAAATAwF2acaAAAAGCBUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVAMAAEBKQjUAAACkJFQDAABASkI1AAAApDS11AWMRZIkERHR2dlZ4koAAACYDPrzZ38eHc24CNVdXV0REdHY2FjiSgAAAJhMurq6Yvr06aO+X5EcL3aXgb6+vnj11VejtrY2KioqSl3OqDo7O6OxsTFeeeWVqKurK3U5MIx7lHLnHqXcuUcpd+5Ryt14ukeTJImurq4444wzorJy9JXT42KkurKyMs4888xSlzFmdXV1ZX+DMLm5Ryl37lHKnXuUcucepdyNl3v0WCPU/TQqAwAAgJSEagAAAEhJqM6j6urqaGlpierq6lKXAiNyj1Lu3KOUO/co5c49SrmbiPfouGhUBgAAAOXISDUAAACkJFQDAABASkI1AAAApCRUAwAAQEpCNQAAAKQkVOdo/fr1MWfOnKipqYmFCxfGk08+eczzM5lMzJs3L2pqauL888+PTZs2FalSJqtc7tF77703Lr300jjttNPitNNOi6ampuPe03Cicv17tN9DDz0UFRUVccUVVxS2QCa9XO/RN998M1atWhWzZ8+O6urqmDt3rv+/p6ByvUfvueeeeN/73hcnnXRSNDY2xk033RTvvPNOkaplsvnlL38ZS5cujTPOOCMqKiriJz/5yXGv2bZtW3zwgx+M6urqeO973xsPPPBAwevMJ6E6Bxs3bozVq1dHS0tL7Ny5M+bPnx9LliyJPXv2jHj+E088EVdddVVce+218dRTT8UVV1wRV1xxRfz6178ucuVMFrneo9u2bYurrroqHnvssdi+fXs0NjbGZZddFm1tbUWunMki13u038svvxxf/OIX49JLLy1SpUxWud6jPT098dGPfjRefvnlePjhh+P555+Pe++9NxoaGopcOZNFrvfogw8+GDfffHO0tLTEc889F/fdd19s3LgxbrnlliJXzmSxf//+mD9/fqxfv35M5//ud7+Lyy+/PBYvXhxPP/103HjjjXHdddfFli1bClxpHiWM2UUXXZSsWrUq+7q3tzc544wzkrVr1454/pVXXplcfvnlQ44tXLgw+bu/+7uC1snkles9erRDhw4ltbW1yfe///1Clcgkl+YePXToUHLxxRcn3/ve95KVK1cmf/3Xf12ESpmscr1Hv/Od7yRnnXVW0tPTU6wSmeRyvUdXrVqV/NVf/dWQY6tXr04uueSSgtYJSZIkEZH8+Mc/PuY5X/rSl5L3v//9Q44tX748WbJkSQEryy8j1WPU09MTO3bsiKampuyxysrKaGpqiu3bt494zfbt24ecHxGxZMmSUc+HE5HmHj3a22+/HQcPHozTTz+9UGUyiaW9R7/+9a/HzJkz49prry1GmUxiae7Rn/70p7Fo0aJYtWpV1NfXx3nnnRe333579Pb2FqtsJpE09+jFF18cO3bsyE4Rf+mll2LTpk3x8Y9/vCg1w/FMhMw0tdQFjBd79+6N3t7eqK+vH3K8vr4+du3aNeI17e3tI57f3t5esDqZvNLco0f78pe/HGecccawv9ggH9Lco48//njcd9998fTTTxehQia7NPfoSy+9FL/4xS/iU5/6VGzatClefPHF+PznPx8HDx6MlpaWYpTNJJLmHv3kJz8Ze/fujQ9/+MORJEkcOnQoPvvZz5r+TdkYLTN1dnbGgQMH4qSTTipRZWNnpBqIiIg77rgjHnroofjxj38cNTU1pS4HoqurK1asWBH33ntvzJgxo9TlwIj6+vpi5syZ8d3vfjcWLFgQy5cvj1tvvTU2bNhQ6tIgIg73T7n99tvj29/+duzcuTN+9KMfxSOPPBKtra2lLg0mDCPVYzRjxoyYMmVKdHR0DDne0dERs2bNGvGaWbNm5XQ+nIg092i/O++8M+644474+c9/Hh/4wAcKWSaTWK736G9/+9t4+eWXY+nSpdljfX19ERExderUeP755+Pss88ubNFMKmn+Hp09e3ZMmzYtpkyZkj12zjnnRHt7e/T09ERVVVVBa2ZySXOP3nbbbbFixYq47rrrIiLi/PPPj/3798dnPvOZuPXWW6Oy0hgbpTVaZqqrqxsXo9QRRqrHrKqqKhYsWBBbt27NHuvr64utW7fGokWLRrxm0aJFQ86PiHj00UdHPR9ORJp7NCLiW9/6VrS2tsbmzZvjwgsvLEapTFK53qPz5s2LZ555Jp5++uns4xOf+ES2O2hjY2Mxy2cSSPP36CWXXBIvvvhi9hc+EREvvPBCzJ49W6Am79Lco2+//faw4Nz/S6AkSQpXLIzRhMhMpe6UNp489NBDSXV1dfLAAw8kv/nNb5LPfOYzyamnnpq0t7cnSZIkK1asSG6++ebs+f/+7/+eTJ06NbnzzjuT5557LmlpaUmmTZuWPPPMM6X6EZjgcr1H77jjjqSqqip5+OGHk9deey376OrqKtWPwASX6z16NN2/KbRc79Hdu3cntbW1yfXXX588//zzyc9+9rNk5syZyTe+8Y1S/QhMcLneoy0tLUltbW3ygx/8IHnppZeSf/u3f0vOPvvs5MorryzVj8AE19XVlTz11FPJU089lUREcvfddydPPfVU8vvf/z5JkiS5+eabkxUrVmTPf+mll5KTTz45+fu///vkueeeS9avX59MmTIl2bx5c6l+hJwJ1Tn653/+5+Td7353UlVVlVx00UXJf/zHf2Tf+8hHPpKsXLlyyPk//OEPk7lz5yZVVVXJ+9///uSRRx4pcsVMNrnco3/2Z3+WRMSwR0tLS/ELZ9LI9e/RwYRqiiHXe/SJJ55IFi5cmFRXVydnnXVW8s1vfjM5dOhQkatmMsnlHj148GDy1a9+NTn77LOTmpqapLGxMfn85z+f/PGPfyx+4UwKjz322Ij/vuy/L1euXJl85CMfGXbNBRdckFRVVSVnnXVW8i//8i9Fr/tEVCSJeR8AAACQhjXVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAApCdUAAACQklANAAAAKQnVAAAAkJJQDQAAACkJ1QAAAJCSUA0AAAApCdUAAACQ0v8PswGoJ8cwnkAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze and visualize results\n",
        "def analyze_and_visualize_results(results_dict):\n",
        "    for component_size, result_df in results_dict.items():\n",
        "        print(f\"Results for PCA-{component_size}:\")\n",
        "        print(result_df)\n",
        "\n",
        "        # Extract ROC data for visualization\n",
        "        n_classes = len(result_df)\n",
        "        fpr = {}\n",
        "        tpr = {}\n",
        "        roc_auc = {}\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_test, result_df['roc_auc'][i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Plot ROC curves\n",
        "        plot_roc_curves(fpr, tpr, roc_auc, class_names=[f'Class {i}' for i in range(n_classes)], n_classes=n_classes)\n",
        "\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown']\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FysYbo31OHZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyb-pPBZOouh",
        "outputId": "45008081-a785-40b3-a23b-a4fe6e94fef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_and_visualize_results(results_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Tbs_mun6OHIX",
        "outputId": "25124e60-0ba1-4acf-fd62-a722305d15af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for PCA-PCA-10:\n",
            "                    Model  Precision    Recall  F1-Score   roc_auc  \\\n",
            "0  DecisionTreeClassifier   0.807924  0.806583  0.805582  0.892573   \n",
            "1  RandomForestClassifier   0.905233  0.904917  0.904781  0.994211   \n",
            "2           MultinomialNB   0.908816  0.906167  0.905985  0.957348   \n",
            "3    KNeighborsClassifier   0.888426  0.887500  0.887556  0.968952   \n",
            "4                     SVC   0.888788  0.886500  0.887129  0.991704   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[942, 72, 89, 9, 2, 2, 4, 4, 42, 11], [120, 9...  \n",
            "1  [[1060, 50, 38, 5, 0, 0, 0, 5, 14, 5], [21, 11...  \n",
            "2  [[1084, 41, 1, 26, 7, 2, 0, 0, 15, 1], [22, 11...  \n",
            "3  [[1037, 48, 49, 6, 0, 0, 1, 1, 25, 10], [17, 1...  \n",
            "4  [[1028, 51, 67, 3, 0, 0, 1, 3, 14, 10], [13, 1...  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0b705da7e3d0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_and_visualize_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-108cfb9fbe23>\u001b[0m in \u001b[0;36manalyze_and_visualize_results\u001b[0;34m(results_dict)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(visualise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhX3H-pbOexj",
        "outputId": "c14fc701-6183-437b-96e9-c60f5b0ccd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(results_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxlqxpgroF7b",
        "outputId": "2c8f0e85-d670-414d-8cc0-d72f7f24ae02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'PCA-10':                     Model  Precision    Recall  F1-Score   roc_auc  \\\n",
            "0  DecisionTreeClassifier   0.807018  0.806167  0.804799  0.892353   \n",
            "1  RandomForestClassifier   0.908967  0.908750  0.908641  0.994402   \n",
            "2           MultinomialNB   0.908816  0.906167  0.905985  0.957348   \n",
            "3    KNeighborsClassifier   0.889035  0.888083  0.888143  0.968738   \n",
            "4                     SVC   0.888450  0.886083  0.886735  0.991656   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[958, 67, 79, 13, 2, 3, 5, 1, 37, 12], [136, ...  \n",
            "1  [[1064, 51, 34, 5, 0, 0, 0, 4, 14, 5], [21, 11...  \n",
            "2  [[1084, 41, 1, 26, 7, 2, 0, 0, 15, 1], [22, 11...  \n",
            "3  [[1037, 47, 49, 6, 0, 0, 1, 1, 26, 10], [17, 1...  \n",
            "4  [[1028, 51, 67, 3, 0, 0, 1, 3, 14, 10], [13, 1...  ,\n",
            " 'PCA-15':                     Model  Precision    Recall  F1-Score   roc_auc  \\\n",
            "0  DecisionTreeClassifier   0.834103  0.833750  0.833335  0.907657   \n",
            "1  RandomForestClassifier   0.937822  0.937667  0.937636  0.996859   \n",
            "2           MultinomialNB   0.908816  0.906167  0.905985  0.957348   \n",
            "3    KNeighborsClassifier   0.929451  0.929333  0.929278  0.981614   \n",
            "4                     SVC   0.914303  0.913333  0.913677  0.994552   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[946, 69, 87, 16, 3, 11, 2, 5, 33, 5], [131, ...  \n",
            "1  [[1075, 52, 25, 5, 1, 1, 2, 1, 12, 3], [18, 11...  \n",
            "2  [[1084, 41, 1, 26, 7, 2, 0, 0, 15, 1], [22, 11...  \n",
            "3  [[1068, 41, 37, 6, 0, 0, 1, 0, 17, 7], [27, 11...  \n",
            "4  [[1064, 44, 52, 4, 0, 0, 2, 1, 6, 4], [18, 116...  ,\n",
            " 'PCA-20':                     Model  Precision    Recall  F1-Score   roc_auc  \\\n",
            "0  DecisionTreeClassifier   0.802314  0.803417  0.801700  0.890811   \n",
            "1  RandomForestClassifier   0.929069  0.928667  0.928675  0.996007   \n",
            "2           MultinomialNB   0.908816  0.906167  0.905985  0.957348   \n",
            "3    KNeighborsClassifier   0.895961  0.894750  0.894642  0.971705   \n",
            "4                     SVC   0.882848  0.879833  0.880742  0.989974   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[899, 97, 107, 14, 2, 6, 5, 2, 36, 9], [142, ...  \n",
            "1  [[1074, 53, 22, 9, 0, 0, 0, 2, 15, 2], [30, 11...  \n",
            "2  [[1084, 41, 1, 26, 7, 2, 0, 0, 15, 1], [22, 11...  \n",
            "3  [[1025, 68, 34, 10, 3, 0, 1, 2, 24, 10], [76, ...  \n",
            "4  [[1053, 50, 50, 10, 0, 0, 1, 1, 8, 4], [73, 10...  ,\n",
            " 'PCA-25':                     Model  Precision    Recall  F1-Score   roc_auc  \\\n",
            "0  DecisionTreeClassifier   0.789625  0.788583  0.788153  0.882580   \n",
            "1  RandomForestClassifier   0.920554  0.919917  0.919966  0.995361   \n",
            "2           MultinomialNB   0.908816  0.906167  0.905985  0.957348   \n",
            "3    KNeighborsClassifier   0.876873  0.874667  0.874717  0.964719   \n",
            "4                     SVC   0.868514  0.864583  0.865617  0.987898   \n",
            "\n",
            "                                    Confusion Matrix  \n",
            "0  [[930, 116, 57, 14, 2, 6, 2, 5, 36, 9], [208, ...  \n",
            "1  [[1081, 56, 10, 5, 1, 0, 0, 3, 16, 5], [42, 11...  \n",
            "2  [[1084, 41, 1, 26, 7, 2, 0, 0, 15, 1], [22, 11...  \n",
            "3  [[1020, 96, 8, 6, 4, 0, 0, 3, 26, 14], [78, 10...  \n",
            "4  [[1081, 47, 10, 9, 1, 0, 1, 3, 15, 10], [82, 1...  }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    roc_curve, roc_auc_score, auc\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function to load data from NPZ files\n",
        "def load_data(file_path):\n",
        "    data = np.load(file_path)\n",
        "    return data['arr_0']\n",
        "\n",
        "# Flatten the image data\n",
        "def flatten_data(data):\n",
        "    return data.reshape(data.shape[0], -1)\n",
        "\n",
        "# Initialize PCA with the desired number of components\n",
        "def apply_pca(data, n_components):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    return pca.fit_transform(data)\n",
        "\n",
        "# Train a classifier and return evaluation metrics\n",
        "def train_and_evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate ROC-AUC score\n",
        "    y_prob = classifier.predict_proba(X_test)\n",
        "\n",
        "    # Check the shape of y_prob\n",
        "    if y_prob.ndim == 1:\n",
        "        # If it's a 1D array, reshape it to a 2D array\n",
        "        y_prob = y_prob.reshape(-1, 1)\n",
        "\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "    return precision, recall, f1, confusion_matrix_result, roc_auc\n",
        "\n",
        "# Function to plot ROC curves\n",
        "def plot_roc_curves(fpr, tpr, roc_auc, class_names, n_classes):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    colors = ['darkorange', 'blue', 'green', 'red', 'purple', 'brown']\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Function to analyze and visualize results\n",
        "def analyze_and_visualize_results(results_dict):\n",
        "    for component_size, result_df in results_dict.items():\n",
        "        print(f\"Results for PCA-{component_size}:\")\n",
        "        print(result_df)\n",
        "\n",
        "        # Extract ROC data for visualization\n",
        "        n_classes = len(result_df)\n",
        "        fpr = {}\n",
        "        tpr = {}\n",
        "        roc_auc = {}\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_test, result_df['roc_auc'][i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Plot ROC curves\n",
        "        plot_roc_curves(fpr, tpr, roc_auc, class_names=[f'Class {i}' for i in range(n_classes)], n_classes=n_classes)\n",
        "\n",
        "# Load training and testing data\n",
        "train_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz')\n",
        "test_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz')\n",
        "\n",
        "# Load labels\n",
        "y_train = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz')\n",
        "y_test = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz')\n",
        "\n",
        "# Define a list of classifiers to experiment with\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(random_state=42, criterion='entropy'),\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    MultinomialNB(),\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(probability=True)\n",
        "]\n",
        "\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "# Experiment with different PCA component sizes\n",
        "component_sizes = [10, 15, 20, 25]\n",
        "\n",
        "for n_components in component_sizes:\n",
        "    X_train_pca = apply_pca(flatten_data(X_train), n_components)\n",
        "    X_test_pca = apply_pca(flatten_data(X_test), n_components)\n",
        "\n",
        "    results = []\n",
        "    for classifier in classifiers:\n",
        "        model_name = classifier.__class__.__name__\n",
        "\n",
        "        if model_name == 'MultinomialNB':\n",
        "            # Use the MultinomialNB classifier without PCA for this specific case\n",
        "            precision, recall, f1, confusion_matrix_result, roc_auc = train_and_evaluate_classifier(classifier, flatten_data(X_train), y_train, flatten_data(X_test), y_test)\n",
        "        else:\n",
        "            # For other classifiers, use PCA as before\n",
        "            precision, recall, f1, confusion_matrix_result, roc_auc = train_and_evaluate_classifier(classifier, X_train_pca, y_train, X_test_pca, y_test)\n",
        "\n",
        "        results.append([model_name, precision, recall, f1, roc_auc, confusion_matrix_result])\n",
        "\n",
        "    results_dict[f'PCA-{n_components}'] = pd.DataFrame(results, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'roc_auc', 'Confusion Matrix'])\n",
        "\n",
        "# Analyze and visualize the results\n",
        "analyze_and_visualize_results(results_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "XcoLPYnVJ4Ef",
        "outputId": "fc188985-bbd3-4921-e617-8534f2bbf531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a31a485b070e>\u001b[0m in \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mX_train_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mX_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a31a485b070e>\u001b[0m in \u001b[0;36mapply_pca\u001b[0;34m(data, n_components)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Train a classifier and return evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"arpack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"randomized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 )\n\u001b[1;32m    525\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    527\u001b[0m                 \u001b[0;34m\"n_components=%r must be between 0 and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_components=10 must be between 0 and min(n_samples, n_features)=4 with svd_solver='full'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    roc_curve, roc_auc_score, auc\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a sample dataset (you can replace this with your own data)\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a model (e.g., Decision Tree Classifier)\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate ROC-AUC and plot ROC curve\n",
        "y_prob = model.predict_proba(X_test)\n",
        "n_classes = len(np.unique(y_test))\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve((y_test == i).astype(int), y_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr[0], tpr[0], color='darkorange', lw=2, label='Class 0 (AUC = {:.2f})'.format(roc_auc[0]))\n",
        "plt.plot(fpr[1], tpr[1], color='blue', lw=2, label='Class 1 (AUC = {:.2f})'.format(roc_auc[1]))\n",
        "plt.plot(fpr[2], tpr[2], color='green', lw=2, label='Class 2 (AUC = {:.2f})'.format(roc_auc[2]))\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "classes = np.unique(y)\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print precision, recall, and F1-Score\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-Score:', f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "uIaHUbKaJOP1",
        "outputId": "d37dfe6e-22c8-407a-a385-40d925af77d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRY9e_2BJN4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54c4_UjJZQRo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "237608a7-0769-4fca-9531-96cf9e45ccf2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-40dcdb7e96de>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Function to load data from NPZ files\n",
        "def load_data(file_path):\n",
        "    data = np.load(file_path)\n",
        "    return data['arr_0']\n",
        "\n",
        "# Load training and testing data\n",
        "train_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz')\n",
        "test_data = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz')\n",
        "\n",
        "# Load labels\n",
        "y_train = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz')\n",
        "y_test = load_data('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz')\n",
        "\n",
        "# Flatten the image data\n",
        "def flatten_data(data):\n",
        "    return data.reshape(data.shape[0], -1)\n",
        "\n",
        "# Initialize PCA with the desired number of components\n",
        "def apply_pca(data, n_components):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    return pca.fit_transform(data)\n",
        "\n",
        "# Train a classifier and return evaluation metrics\n",
        "def train_and_evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return precision, recall, f1, confusion_matrix_result\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a list of classifiers to experiment with\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(random_state=42, criterion='entropy'),\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    # MultinomialNB(),\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(probability=True)\n",
        "]\n",
        "\n",
        "# Dictionary to store results\n",
        "results_dict = {}\n",
        "\n",
        "# Experiment with different PCA component sizes\n",
        "component_sizes = [10, 15, 20, 25]\n",
        "\n",
        "for n_components in component_sizes:\n",
        "    X_train_pca = apply_pca(flatten_data(X_train), n_components)\n",
        "    X_test_pca = apply_pca(flatten_data(X_test), n_components)\n",
        "\n",
        "    results = []\n",
        "    for classifier in classifiers:\n",
        "        model_name = classifier.__class__.__name__\n",
        "        precision, recall, f1, confusion_matrix_result = train_and_evaluate_classifier(classifier, X_train_pca, y_train, X_test_pca, y_test)\n",
        "        print(f\"{model_name} (PCA-{n_components}) - Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n",
        "        results.append([model_name, precision, recall, f1, confusion_matrix_result])\n",
        "\n",
        "    results_dict[f'PCA-{n_components}'] = pd.DataFrame(results, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix'])\n",
        "\n",
        "# Now you have results for different PCA component sizes stored in results_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyvz-lanZ-NA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "\n",
        "# Function to calculate ROC-AUC and plot ROC curve\n",
        "def calculate_roc_auc(classifier, X_test, y_test, model_name):\n",
        "    # Calculate ROC-AUC score\n",
        "    y_prob = classifier.predict_proba(X_test)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob[:, 1])\n",
        "\n",
        "    # Plot ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Create ROC-AUC plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Experiment with different PCA component sizes\n",
        "component_sizes = [10, 15, 20, 25]\n",
        "\n",
        "for n_components in component_sizes:\n",
        "    X_train_pca = apply_pca(flatten_data(X_train), n_components)\n",
        "    X_test_pca = apply_pca(flatten_data(X_test), n_components)\n",
        "\n",
        "    results = []\n",
        "    for classifier in classifiers:\n",
        "        model_name = classifier.__class__.__name__\n",
        "        precision, recall, f1, confusion_matrix_result = train_and_evaluate_classifier(classifier, X_train_pca, y_train, X_test_pca, y_test)\n",
        "\n",
        "        # Calculate ROC-AUC and plot ROC curve\n",
        "        calculate_roc_auc(classifier, X_test_pca, y_test, model_name)\n",
        "\n",
        "        print(f\"Model: {model_name} (PCA-{n_components})\")\n",
        "        print(f\"Precision: {precision}\")\n",
        "        print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-Score: {f1}\")\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix_result)\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        results.append([model_name, precision, recall, f1, confusion_matrix_result])\n",
        "\n",
        "    results_dict[f'PCA-{n_components}'] = pd.DataFrame(results, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "T62qCbFZ6Th5",
        "outputId": "d41b65c0-717f-4187-97be-03a1604d65db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier Precision: 0.9095503579007873 Recall: 0.9093333333333333 F1-Score: 0.9093780687122003\n",
            "RandomForestClassifier Precision: 0.9532792317041199 Recall: 0.9530833333333333 F1-Score: 0.9530315113888637\n",
            "KNeighborsClassifier Precision: 0.9630692891027466 Recall: 0.9628333333333333 F1-Score: 0.9628093850068585\n",
            "SVC Precision: 0.9613398570006022 Recall: 0.9610833333333333 F1-Score: 0.9610769732922906\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cdac721-1935-404a-94c5-309472487935\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.909550</td>\n",
              "      <td>0.909333</td>\n",
              "      <td>0.909378</td>\n",
              "      <td>[[1044, 70, 7, 16, 1, 1, 1, 3, 26, 8], [70, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.953279</td>\n",
              "      <td>0.953083</td>\n",
              "      <td>0.953032</td>\n",
              "      <td>[[1102, 60, 0, 5, 0, 0, 0, 3, 5, 2], [21, 1185...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.963069</td>\n",
              "      <td>0.962833</td>\n",
              "      <td>0.962809</td>\n",
              "      <td>[[1106, 58, 0, 4, 0, 0, 1, 0, 7, 1], [11, 1201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.961340</td>\n",
              "      <td>0.961083</td>\n",
              "      <td>0.961077</td>\n",
              "      <td>[[1115, 49, 0, 5, 0, 0, 0, 1, 4, 3], [11, 1197...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cdac721-1935-404a-94c5-309472487935')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cdac721-1935-404a-94c5-309472487935 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cdac721-1935-404a-94c5-309472487935');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b60edeb4-a7f7-4f14-9977-79baf7d1eaf9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b60edeb4-a7f7-4f14-9977-79baf7d1eaf9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b60edeb4-a7f7-4f14-9977-79baf7d1eaf9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                    Model  Precision    Recall  F1-Score  \\\n",
              "0  DecisionTreeClassifier   0.909550  0.909333  0.909378   \n",
              "1  RandomForestClassifier   0.953279  0.953083  0.953032   \n",
              "2    KNeighborsClassifier   0.963069  0.962833  0.962809   \n",
              "3                     SVC   0.961340  0.961083  0.961077   \n",
              "\n",
              "                                    Confusion Matrix  \n",
              "0  [[1044, 70, 7, 16, 1, 1, 1, 3, 26, 8], [70, 11...  \n",
              "1  [[1102, 60, 0, 5, 0, 0, 0, 3, 5, 2], [21, 1185...  \n",
              "2  [[1106, 58, 0, 4, 0, 0, 1, 0, 7, 1], [11, 1201...  \n",
              "3  [[1115, 49, 0, 5, 0, 0, 0, 1, 4, 3], [11, 1197...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the training and testing data from NPZ files\n",
        "train_data = np.load('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_train.npz')\n",
        "test_data = np.load('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/X_kannada_MNIST_test.npz')\n",
        "\n",
        "# Access the image and label arrays\n",
        "x_train = train_data['arr_0']\n",
        "x_test = test_data['arr_0']\n",
        "\n",
        "# Load the corresponding labels\n",
        "y_train = np.load('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_train.npz')['arr_0']\n",
        "y_test = np.load('/content/drive/MyDrive/data/Kannada_MNIST_datataset_paper/Kannada_MNIST_npz/Kannada_MNIST/y_kannada_MNIST_test.npz')['arr_0']\n",
        "\n",
        "\n",
        "# Assuming x_train has shape (num_samples, height, width)\n",
        "x_train_flattened = x_train.reshape(x_train.shape[0], -1)\n",
        "\n",
        "# Similarly, flatten the test data\n",
        "x_test_flattened = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Initialize PCA with the desired number of components (e.g., n_components=10)\n",
        "pca = PCA(n_components=10)\n",
        "\n",
        "# Fit and transform the training data\n",
        "x_train_pca = pca.fit_transform(x_train_flattened)\n",
        "\n",
        "# Transform the testing data using the same PCA model\n",
        "x_test_pca = pca.transform(x_test_flattened)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create a Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model on the PCA-reduced training data\n",
        "dt_classifier.fit(x_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the PCA-reduced test data\n",
        "dt_predictions = dt_classifier.predict(x_test_pca)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "def model_training_and_evaluation(x, y):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    classifiers = [\n",
        "        DecisionTreeClassifier(random_state=42,criterion='entropy'),\n",
        "        RandomForestClassifier(random_state=42),\n",
        "        # MultinomialNB(),\n",
        "        KNeighborsClassifier(),\n",
        "        SVC(probability=True)  # Probability=True for SVC\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for classifier in classifiers:\n",
        "        model_name = classifier.__class__.__name__\n",
        "\n",
        "        # Fit the classifier on the training data\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test data\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Calculate various evaluation metrics\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "        # roc_auc = roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1])\n",
        "        print(model_name, 'Precision:', precision, 'Recall:', recall, 'F1-Score:', f1)\n",
        "\n",
        "        # Append the results to the list\n",
        "        results.append([model_name, precision, recall, f1, confusion_matrix_result])\n",
        "\n",
        "    # Create a DataFrame from the results list\n",
        "    results_df = pd.DataFrame(results, columns=['Model', 'Precision', 'Recall', 'F1-Score', 'Confusion Matrix'])\n",
        "\n",
        "    return results_df\n",
        "model_training_and_evaluation(x_train_pca, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "loaucXIz80OT",
        "outputId": "34fa361a-785d-4152-8667-9baafc154444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Random Forest Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the training and testing data from NPZ files (if not already loaded)\n",
        "# (Code for data loading)\n",
        "\n",
        "# Define a list of PCA component sizes to experiment with\n",
        "component_sizes = [15, 20, 25, 30]\n",
        "\n",
        "# Function to perform model training and evaluation for different PCA component sizes\n",
        "def experiment_with_pca_sizes(x, y, component_sizes):\n",
        "    results_dict = {}  # Store results for each component size\n",
        "\n",
        "    for size in component_sizes:\n",
        "        # Initialize PCA with the current component size\n",
        "        pca = PCA(n_components=size)\n",
        "\n",
        "        # Fit and transform the training data\n",
        "        x_train_pca = pca.fit_transform(x)\n",
        "\n",
        "        # Transform the testing data using the same PCA model\n",
        "        x_test_pca = pca.transform(x_test_flattened)\n",
        "\n",
        "        # Perform model training and evaluation as before\n",
        "        results_df = model_training_and_evaluation(x_train_pca, y_train)\n",
        "\n",
        "        # Store the results for this component size\n",
        "        results_dict[size] = results_df\n",
        "\n",
        "    return results_dict\n",
        "\n",
        "# Function to perform hyperparameter tuning (GridSearchCV) for a given model\n",
        "def hyperparameter_tuning(model, param_grid, X_train, y_train):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "    return best_model\n",
        "\n",
        "# Define hyperparameter grids for models that need tuning\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "}\n",
        "\n",
        "param_grid_svc = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "}\n",
        "\n",
        "# Example usage\n",
        "best_models = {}\n",
        "for model_name, model in [('Random Forest', RandomForestClassifier(random_state=42)),\n",
        "                          ('SVM', SVC(probability=True))]:\n",
        "    best_model = hyperparameter_tuning(model, param_grid_rf if model_name == 'Random Forest' else param_grid_svc, x_train_pca, y_train)\n",
        "    best_models[model_name] = best_model\n",
        "    print(f'Best {model_name} Parameters:', best_model.get_params())\n",
        "\n",
        "# Once you've selected the best model and PCA configuration, you can proceed with final training and deployment (if needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylzQmuGB6Tc-"
      },
      "outputs": [],
      "source": [
        "model_training_and_evaluation(x_train_pca, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d8flZsv6TUM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC1nNlNh6TGD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyQEpWGTEnbp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wim7RVWzDgKk",
        "outputId": "73af6895-29e7-4f7c-dabe-5671087b2bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/data/Dig-MNIST.csv.zip\n",
            "replace /content/kannada/Dig-MNIST.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/drive/MyDrive/data/test.csv.zip\n",
            "replace /content/kannada/test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/drive/MyDrive/data/train.csv.zip\n",
            "replace /content/kannada/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/data/Dig-MNIST.csv.zip -d /content/kannada\n",
        "!unzip /content/drive/MyDrive/data/test.csv.zip -d /content/kannada\n",
        "!unzip /content/drive/MyDrive/data/train.csv.zip -d /content/kannada\n",
        "!cp /content/drive/MyDrive/data/sample_submission.csv /content/kannada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqAwCujoFslp"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/kannada/train.csv')\n",
        "test = pd.read_csv('/content/kannada/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P025FTibgjz"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your data into a pandas DataFrame, assuming the last column is the target variable\n",
        "# Replace 'your_data.csv' with the actual file path or data source\n",
        "data = pd.read_csv('/content/kannada/test.csv')\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.iloc[:, :-1]  # Select all columns except the last one as features\n",
        "y = data.iloc[:, -1]   # Select the last column as the target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a DecisionTreeClassifier instance\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpp4Rk4OW3uI"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66NOhmKH2cVW"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "train = pd.read_csv('/content/kannada/train.csv')\n",
        "test = pd.read_csv('/content/kannada/test.csv')\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pixel_columns = train.columns[1:]  # Exclude the label column\n",
        "\n",
        "# Fit and transform the training data\n",
        "scaler = StandardScaler()\n",
        "train[pixel_columns] = scaler.fit_transform(train[pixel_columns])\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "test[pixel_columns] = scaler.transform(test[pixel_columns])\n",
        "\n",
        "# Step 3: PCA Dimensionality Reduction\n",
        "n_components = 10  # Adjust as needed\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Fit PCA on the training data\n",
        "pca_train_result = pca.fit_transform(train[pixel_columns])\n",
        "\n",
        "# Transform both the training and test data\n",
        "pca_train_kannada = pd.DataFrame(data=pca_train_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "pca_test_kannada = pd.DataFrame(data=pca.transform(test[pixel_columns]), columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_train_kannada, train['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Model Selection and Training\n",
        "classifiers = [\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Naive Bayes', GaussianNB()),\n",
        "    ('K-NN', KNeighborsClassifier()),\n",
        "    ('SVM', SVC(probability=True))\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for clf_name, clf in classifiers:\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Step 5: Model Evaluation\n",
        "    y_pred = clf.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr')\n",
        "\n",
        "    results.append({\n",
        "        'Model': clf_name,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Confusion Matrix': confusion_matrix_result,\n",
        "        'ROC-AUC': roc_auc\n",
        "    })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP2nmLoOe4EJ",
        "outputId": "e25d56e0-9a1f-4a71-a889-8bdb388d183a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1.115892\n",
              "1        2.798259\n",
              "2        0.266585\n",
              "3       -1.633760\n",
              "4       -0.222263\n",
              "           ...   \n",
              "59995   -0.253884\n",
              "59996    0.589395\n",
              "59997    2.472629\n",
              "59998   -0.171209\n",
              "59999   -3.506399\n",
              "Name: PC10, Length: 60000, dtype: float64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VVMnEa4eXnxq",
        "outputId": "87f79506-4011-468f-c747-8e0418d31b7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5258be1b-8c9f-4d13-82b7-0aec1225c8b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "      <th>PC7</th>\n",
              "      <th>PC8</th>\n",
              "      <th>PC9</th>\n",
              "      <th>PC10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.552778</td>\n",
              "      <td>-0.120681</td>\n",
              "      <td>-5.763611</td>\n",
              "      <td>0.897525</td>\n",
              "      <td>1.414289</td>\n",
              "      <td>1.148793</td>\n",
              "      <td>-0.018409</td>\n",
              "      <td>-2.019826</td>\n",
              "      <td>-0.808528</td>\n",
              "      <td>-0.000730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.630848</td>\n",
              "      <td>-3.655261</td>\n",
              "      <td>-3.161163</td>\n",
              "      <td>2.607980</td>\n",
              "      <td>-2.931986</td>\n",
              "      <td>-2.684560</td>\n",
              "      <td>0.406554</td>\n",
              "      <td>-0.801375</td>\n",
              "      <td>-3.245672</td>\n",
              "      <td>1.458526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.539784</td>\n",
              "      <td>7.142207</td>\n",
              "      <td>-2.938186</td>\n",
              "      <td>-4.087031</td>\n",
              "      <td>0.375515</td>\n",
              "      <td>-1.513796</td>\n",
              "      <td>0.605609</td>\n",
              "      <td>-1.875907</td>\n",
              "      <td>-1.036667</td>\n",
              "      <td>-3.692768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.462688</td>\n",
              "      <td>-0.121346</td>\n",
              "      <td>2.374626</td>\n",
              "      <td>-2.267595</td>\n",
              "      <td>-2.586572</td>\n",
              "      <td>0.502477</td>\n",
              "      <td>-1.638726</td>\n",
              "      <td>-3.179026</td>\n",
              "      <td>-0.637139</td>\n",
              "      <td>1.645156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.007387</td>\n",
              "      <td>-1.917589</td>\n",
              "      <td>-2.993255</td>\n",
              "      <td>0.820359</td>\n",
              "      <td>3.762122</td>\n",
              "      <td>2.869428</td>\n",
              "      <td>2.157103</td>\n",
              "      <td>0.977333</td>\n",
              "      <td>-2.097105</td>\n",
              "      <td>-3.021532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>-0.210793</td>\n",
              "      <td>-3.934400</td>\n",
              "      <td>-2.461354</td>\n",
              "      <td>3.233459</td>\n",
              "      <td>-2.605268</td>\n",
              "      <td>-4.910166</td>\n",
              "      <td>2.867573</td>\n",
              "      <td>-0.967951</td>\n",
              "      <td>1.721017</td>\n",
              "      <td>-0.212769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>-3.662426</td>\n",
              "      <td>-3.123323</td>\n",
              "      <td>-0.208089</td>\n",
              "      <td>2.128891</td>\n",
              "      <td>-5.904626</td>\n",
              "      <td>-3.476368</td>\n",
              "      <td>4.405775</td>\n",
              "      <td>-0.071496</td>\n",
              "      <td>-0.566359</td>\n",
              "      <td>-1.321411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>0.112222</td>\n",
              "      <td>-1.876772</td>\n",
              "      <td>-4.107844</td>\n",
              "      <td>-2.359335</td>\n",
              "      <td>-1.131468</td>\n",
              "      <td>-0.730925</td>\n",
              "      <td>-0.614526</td>\n",
              "      <td>-2.355505</td>\n",
              "      <td>2.276210</td>\n",
              "      <td>2.481005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>9.048037</td>\n",
              "      <td>-1.805751</td>\n",
              "      <td>9.290153</td>\n",
              "      <td>-2.406830</td>\n",
              "      <td>-2.865510</td>\n",
              "      <td>-0.570998</td>\n",
              "      <td>1.306450</td>\n",
              "      <td>2.018230</td>\n",
              "      <td>-0.580567</td>\n",
              "      <td>-0.613974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>2.335557</td>\n",
              "      <td>0.247411</td>\n",
              "      <td>-4.293116</td>\n",
              "      <td>-0.262361</td>\n",
              "      <td>0.753712</td>\n",
              "      <td>1.799784</td>\n",
              "      <td>0.638449</td>\n",
              "      <td>-1.987677</td>\n",
              "      <td>-0.683483</td>\n",
              "      <td>-0.090699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5258be1b-8c9f-4d13-82b7-0aec1225c8b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5258be1b-8c9f-4d13-82b7-0aec1225c8b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5258be1b-8c9f-4d13-82b7-0aec1225c8b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf527d50-d90a-424d-a556-cbc7c85b8365\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf527d50-d90a-424d-a556-cbc7c85b8365')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf527d50-d90a-424d-a556-cbc7c85b8365 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
              "0     2.552778 -0.120681 -5.763611  0.897525  1.414289  1.148793 -0.018409   \n",
              "1    -1.630848 -3.655261 -3.161163  2.607980 -2.931986 -2.684560  0.406554   \n",
              "2    -1.539784  7.142207 -2.938186 -4.087031  0.375515 -1.513796  0.605609   \n",
              "3     8.462688 -0.121346  2.374626 -2.267595 -2.586572  0.502477 -1.638726   \n",
              "4     4.007387 -1.917589 -2.993255  0.820359  3.762122  2.869428  2.157103   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4995 -0.210793 -3.934400 -2.461354  3.233459 -2.605268 -4.910166  2.867573   \n",
              "4996 -3.662426 -3.123323 -0.208089  2.128891 -5.904626 -3.476368  4.405775   \n",
              "4997  0.112222 -1.876772 -4.107844 -2.359335 -1.131468 -0.730925 -0.614526   \n",
              "4998  9.048037 -1.805751  9.290153 -2.406830 -2.865510 -0.570998  1.306450   \n",
              "4999  2.335557  0.247411 -4.293116 -0.262361  0.753712  1.799784  0.638449   \n",
              "\n",
              "           PC8       PC9      PC10  \n",
              "0    -2.019826 -0.808528 -0.000730  \n",
              "1    -0.801375 -3.245672  1.458526  \n",
              "2    -1.875907 -1.036667 -3.692768  \n",
              "3    -3.179026 -0.637139  1.645156  \n",
              "4     0.977333 -2.097105 -3.021532  \n",
              "...        ...       ...       ...  \n",
              "4995 -0.967951  1.721017 -0.212769  \n",
              "4996 -0.071496 -0.566359 -1.321411  \n",
              "4997 -2.355505  2.276210  2.481005  \n",
              "4998  2.018230 -0.580567 -0.613974  \n",
              "4999 -1.987677 -0.683483 -0.090699  \n",
              "\n",
              "[5000 rows x 10 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_test_kannada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P8LMNUd6EbfI",
        "outputId": "46894bd3-dd77-4da3-da4f-cb68d43b52ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04dd1a0c-5406-4c9c-bf89-be64ad6cbebb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>ROC-AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.901604</td>\n",
              "      <td>0.901500</td>\n",
              "      <td>0.901471</td>\n",
              "      <td>[[1072, 57, 2, 13, 0, 2, 1, 4, 26, 0], [46, 11...</td>\n",
              "      <td>0.945134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.949428</td>\n",
              "      <td>0.949250</td>\n",
              "      <td>0.949299</td>\n",
              "      <td>[[1105, 50, 1, 7, 0, 0, 1, 0, 10, 3], [14, 118...</td>\n",
              "      <td>0.997802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.847608</td>\n",
              "      <td>0.842250</td>\n",
              "      <td>0.842268</td>\n",
              "      <td>[[1021, 80, 2, 22, 3, 2, 0, 2, 42, 3], [21, 10...</td>\n",
              "      <td>0.984055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>K-NN</td>\n",
              "      <td>0.959478</td>\n",
              "      <td>0.959333</td>\n",
              "      <td>0.959340</td>\n",
              "      <td>[[1116, 48, 0, 6, 0, 0, 0, 0, 5, 2], [11, 1202...</td>\n",
              "      <td>0.992701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.954825</td>\n",
              "      <td>0.954667</td>\n",
              "      <td>0.954688</td>\n",
              "      <td>[[1115, 44, 0, 7, 0, 0, 1, 0, 8, 2], [9, 1195,...</td>\n",
              "      <td>0.998433</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04dd1a0c-5406-4c9c-bf89-be64ad6cbebb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04dd1a0c-5406-4c9c-bf89-be64ad6cbebb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04dd1a0c-5406-4c9c-bf89-be64ad6cbebb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-587d8d31-e677-4895-9ce9-e6d0bcc352a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-587d8d31-e677-4895-9ce9-e6d0bcc352a2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-587d8d31-e677-4895-9ce9-e6d0bcc352a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Model  Precision    Recall  F1-Score  \\\n",
              "0  Decision Tree   0.901604  0.901500  0.901471   \n",
              "1  Random Forest   0.949428  0.949250  0.949299   \n",
              "2    Naive Bayes   0.847608  0.842250  0.842268   \n",
              "3           K-NN   0.959478  0.959333  0.959340   \n",
              "4            SVM   0.954825  0.954667  0.954688   \n",
              "\n",
              "                                    Confusion Matrix   ROC-AUC  \n",
              "0  [[1072, 57, 2, 13, 0, 2, 1, 4, 26, 0], [46, 11...  0.945134  \n",
              "1  [[1105, 50, 1, 7, 0, 0, 1, 0, 10, 3], [14, 118...  0.997802  \n",
              "2  [[1021, 80, 2, 22, 3, 2, 0, 2, 42, 3], [21, 10...  0.984055  \n",
              "3  [[1116, 48, 0, 6, 0, 0, 0, 0, 5, 2], [11, 1202...  0.992701  \n",
              "4  [[1115, 44, 0, 7, 0, 0, 1, 0, 8, 2], [9, 1195,...  0.998433  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(results)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "Iel6b3C2EJh8",
        "outputId": "a5a0de6d-ebed-445e-e0c8-fa7d1a96299f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Model  Precision    Recall  F1-Score  \\\n",
            "0  Decision Tree   0.903878  0.903750  0.903706   \n",
            "1  Random Forest   0.950198  0.950000  0.950065   \n",
            "2    Naive Bayes   0.849229  0.843833  0.843942   \n",
            "3           K-NN   0.959567  0.959417  0.959431   \n",
            "4            SVM   0.954423  0.954250  0.954274   \n",
            "\n",
            "                                    Confusion Matrix   ROC-AUC  \n",
            "0  [[1081, 51, 3, 12, 1, 1, 1, 2, 23, 2], [40, 11...  0.946367  \n",
            "1  [[1112, 48, 0, 6, 0, 0, 1, 1, 7, 2], [17, 1185...  0.998019  \n",
            "2  [[1022, 79, 2, 22, 3, 1, 0, 3, 43, 2], [22, 10...  0.984226  \n",
            "3  [[1116, 48, 0, 6, 0, 0, 0, 0, 5, 2], [11, 1202...  0.992645  \n",
            "4  [[1114, 46, 0, 7, 0, 0, 1, 0, 7, 2], [8, 1194,...  0.998439  \n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 6: Display Model Evaluation Results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Step 7: Visualize Model Performance (example: F1-Score vs. Model)\n",
        "plt.figure(figsize=(10, 6))\n",
        "for model in classifiers:\n",
        "    model_name = model[0]\n",
        "    model_results = results_df[results_df['Model'] == model_name]\n",
        "    plt.plot(model_results['Model'], model_results['F1-Score'], label=model_name)\n",
        "\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "plt.title('Model Performance (F1-Score)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wQDp36zZDR8h",
        "outputId": "7558b7ab-734a-45f9-bb88-20a0473344e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9da57b7b-94d4-42f1-b165-ae079f7748a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>ROC-AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.903128</td>\n",
              "      <td>0.902917</td>\n",
              "      <td>0.902942</td>\n",
              "      <td>[[1082, 45, 3, 14, 0, 1, 0, 1, 28, 3], [53, 11...</td>\n",
              "      <td>0.945937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.950099</td>\n",
              "      <td>0.949917</td>\n",
              "      <td>0.949958</td>\n",
              "      <td>[[1108, 49, 1, 7, 0, 0, 1, 0, 9, 2], [14, 1191...</td>\n",
              "      <td>0.998002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.848313</td>\n",
              "      <td>0.842917</td>\n",
              "      <td>0.843017</td>\n",
              "      <td>[[1018, 83, 2, 22, 3, 1, 0, 3, 42, 3], [22, 10...</td>\n",
              "      <td>0.984221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>K-NN</td>\n",
              "      <td>0.958894</td>\n",
              "      <td>0.958750</td>\n",
              "      <td>0.958759</td>\n",
              "      <td>[[1116, 48, 0, 5, 0, 0, 0, 0, 6, 2], [11, 1202...</td>\n",
              "      <td>0.992688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.953504</td>\n",
              "      <td>0.953333</td>\n",
              "      <td>0.953364</td>\n",
              "      <td>[[1114, 46, 0, 7, 0, 0, 1, 0, 7, 2], [10, 1194...</td>\n",
              "      <td>0.998417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9da57b7b-94d4-42f1-b165-ae079f7748a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9da57b7b-94d4-42f1-b165-ae079f7748a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9da57b7b-94d4-42f1-b165-ae079f7748a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0328aaaa-fcf1-486c-ab66-398e21bbae26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0328aaaa-fcf1-486c-ab66-398e21bbae26')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0328aaaa-fcf1-486c-ab66-398e21bbae26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Model  Precision    Recall  F1-Score  \\\n",
              "0  Decision Tree   0.903128  0.902917  0.902942   \n",
              "1  Random Forest   0.950099  0.949917  0.949958   \n",
              "2    Naive Bayes   0.848313  0.842917  0.843017   \n",
              "3           K-NN   0.958894  0.958750  0.958759   \n",
              "4            SVM   0.953504  0.953333  0.953364   \n",
              "\n",
              "                                    Confusion Matrix   ROC-AUC  \n",
              "0  [[1082, 45, 3, 14, 0, 1, 0, 1, 28, 3], [53, 11...  0.945937  \n",
              "1  [[1108, 49, 1, 7, 0, 0, 1, 0, 9, 2], [14, 1191...  0.998002  \n",
              "2  [[1018, 83, 2, 22, 3, 1, 0, 3, 42, 3], [22, 10...  0.984221  \n",
              "3  [[1116, 48, 0, 5, 0, 0, 0, 0, 6, 2], [11, 1202...  0.992688  \n",
              "4  [[1114, 46, 0, 7, 0, 0, 1, 0, 7, 2], [10, 1194...  0.998417  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmle1Sl92pR3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pixel_columns = train.columns[1:]  # Exclude the label column\n",
        "\n",
        "# Fit and transform both train and test data using the same scaler\n",
        "scaler = StandardScaler()\n",
        "train[pixel_columns] = scaler.fit_transform(train[pixel_columns])\n",
        "test[pixel_columns] = scaler.transform(test[pixel_columns])\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_components = 10  # Adjust as needed\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Fit PCA on the training data and transform both train and test data\n",
        "pca_train_result = pca.fit_transform(train[pixel_columns])\n",
        "pca_test_result = pca.transform(test[pixel_columns])\n",
        "\n",
        "# Create DataFrames for the PCA results\n",
        "pca_train_kannada = pd.DataFrame(data=pca_train_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "pca_test_df = pd.DataFrame(data=pca_test_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "\n",
        "y_train_kannada=pca_train_kannada['PC1']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Perform the split once\n",
        "pca_train_kannada, pca_test_df, y_train_kannada, y_test_kannada = train_test_split(pca_train_kannada, y_train_kannada, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "YabR1JnwHwj-",
        "outputId": "a552cec7-bd20-415e-f592-f937f788e9f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-28558548-7d2a-4e32-9af1-c7c6ad50def8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28558548-7d2a-4e32-9af1-c7c6ad50def8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28558548-7d2a-4e32-9af1-c7c6ad50def8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28558548-7d2a-4e32-9af1-c7c6ad50def8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f2648db-abab-456d-9033-55b15b32135f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f2648db-abab-456d-9033-55b15b32135f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f2648db-abab-456d-9033-55b15b32135f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0          0       0       0       0       0       0       0       0       0   \n",
              "1          1       0       0       0       0       0       0       0       0   \n",
              "2          2       0       0       0       0       0       0       0       0   \n",
              "3          3       0       0       0       0       0       0       0       0   \n",
              "4          4       0       0       0       0       0       0       0       0   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "59995      5       0       0       0       0       0       0       0       0   \n",
              "59996      6       0       0       0       0       0       0       0       0   \n",
              "59997      7       0       0       0       0       0       0       0       0   \n",
              "59998      8       0       0       0       0       0       0       0       0   \n",
              "59999      9       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0           0  ...         0         0         0         0         0   \n",
              "1           0  ...         0         0         0         0         0   \n",
              "2           0  ...         0         0         0         0         0   \n",
              "3           0  ...         0         0         0         0         0   \n",
              "4           0  ...         0         0         0         0         0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "59995       0  ...         0         0         0         0         0   \n",
              "59996       0  ...         0         0         0         0         0   \n",
              "59997       0  ...         0         0         0         0         0   \n",
              "59998       0  ...         0         0         0         0         0   \n",
              "59999       0  ...         0         0         0         0         0   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0             0         0         0         0         0  \n",
              "1             0         0         0         0         0  \n",
              "2             0         0         0         0         0  \n",
              "3             0         0         0         0         0  \n",
              "4             0         0         0         0         0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "59995         0         0         0         0         0  \n",
              "59996         0         0         0         0         0  \n",
              "59997         0         0         0         0         0  \n",
              "59998         0         0         0         0         0  \n",
              "59999         0         0         0         0         0  \n",
              "\n",
              "[60000 rows x 785 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4mWjsr0KxhA"
      },
      "source": [
        "Before passing your data to PCA (Principal Component Analysis), it's important to preprocess the data appropriately. PCA is a dimensionality reduction technique that works well when the data is centered (mean-centered) and has a consistent scale (standardized). Here are the steps to prepare your data for PCA:\n",
        "\n",
        "1. **Separate Labels and Features:**\n",
        "   - The 'label' column (e.g., 'label') contains the class labels (assuming it's a classification problem), while the 'pixel' columns contain the pixel values.\n",
        "\n",
        "2. **Normalize the Pixel Values:**\n",
        "   - PCA is sensitive to the scale of features. To ensure that all pixel values have the same scale, you should normalize them. This typically involves scaling pixel values to have a mean of 0 and a standard deviation of 1 (z-score normalization).\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "   # Assuming your data is in a DataFrame called 'df'\n",
        "   pixel_columns = df.columns[1:]  # Exclude the label column\n",
        "   scaler = StandardScaler()\n",
        "   df[pixel_columns] = scaler.fit_transform(df[pixel_columns])\n",
        "   ```\n",
        "\n",
        "3. **Center the Data:**\n",
        "   - PCA assumes that the data is centered, meaning that the mean of each feature (pixel in this case) is 0. Ensure that your data is centered by subtracting the mean from each feature.\n",
        "\n",
        "   ```python\n",
        "   # Center the data by subtracting the mean\n",
        "   df[pixel_columns] = df[pixel_columns] - df[pixel_columns].mean()\n",
        "   ```\n",
        "\n",
        "4. **Apply PCA:**\n",
        "   - Now that your data is properly preprocessed, you can apply PCA to reduce its dimensionality. You can use libraries like scikit-learn to perform PCA.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.decomposition import PCA\n",
        "\n",
        "   # Specify the number of components you want to retain\n",
        "   n_components = 10  # Adjust this based on your specific needs\n",
        "   pca = PCA(n_components=n_components)\n",
        "\n",
        "   # Fit and transform the data\n",
        "   pca_result = pca.fit_transform(df[pixel_columns])\n",
        "\n",
        "   # Create a DataFrame with the PCA results\n",
        "   pca_df = pd.DataFrame(data=pca_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "\n",
        "   # Combine the label column with the PCA results if needed\n",
        "   pca_df['label'] = df['label']\n",
        "   ```\n",
        "\n",
        "5. **Optional: Visualization and Analysis:**\n",
        "   - You can visualize the results of PCA to understand how much variance is explained by each principal component and make decisions about the number of components to retain.\n",
        "\n",
        "Now, you have a dataset where most of the variance is captured by a reduced number of principal components (PCs). You can use this reduced-dimensional data for further analysis or machine learning tasks. Adjust the number of components based on your specific requirements and the amount of variance you want to retain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R4tu7U8J37A"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pixel_columns = train.columns[1:]  # Exclude the label column\n",
        "pixel_columns = test.columns[1:]\n",
        "scaler = StandardScaler()\n",
        "train[pixel_columns] = scaler.fit_transform(train[pixel_columns])\n",
        "test[pixel_columns] = scaler.fit_transform(test[pixel_columns])\n",
        "\n",
        "# Center the data by subtracting the mean\n",
        "train[pixel_columns] = train[pixel_columns] - train[pixel_columns].mean()\n",
        "test[pixel_columns] = test[pixel_columns] - test[pixel_columns].mean()\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Specify the number of components you want to retain\n",
        "n_components = 10  # Adjust this based on your specific needs\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Fit and transform the data\n",
        "pca_train_result = pca.fit_transform(train[pixel_columns])\n",
        "pca_test_result = pca.fit_transform(test[pixel_columns])\n",
        "\n",
        "# Create a DataFrame with the PCA results\n",
        "pca_train_kannada = pd.DataFrame(data=pca_train_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "pca_test_df = pd.DataFrame(data=pca_test_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "# # Combine the label column with the PCA results if needed\n",
        "# pca_df['label'] = df['label']\n",
        "\n",
        "y_train_kannada=pca_train_kannada['PC1']\n",
        "\n",
        "y_test_kannada=pca_test_df['PC1']\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pca_train_kannada,pca_test_df,y_train_kannada,y_test_kannada = train_test_split(pca_train_kannada,y_train_kannada,test_size=0.2,random_state=42)\n",
        "models = [LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
        "train_accuracies = []\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "train_f1s = []\n",
        "test_accuracies = []\n",
        "test_precisions = []\n",
        "test_recalls = []\n",
        "test_f1s = []\n",
        "for model in models:\n",
        "  model.fit(pca_train_kannada,y_train_kannada)\n",
        "  train_pred = model.predict(pca_train_kannada)\n",
        "  test_pred = model.predict(pca_test_df)\n",
        "  print(type(model).__name__)\n",
        "  print(\"*******Train************\")\n",
        "  print(\"Accuracy: \",accuracy_score(y_train_kannada,train_pred))\n",
        "  print(\"Precision: \",precision_score(y_train_kannada,train_pred))\n",
        "  print(\"Recall: \",recall_score(y_train_kannada,train_pred))\n",
        "  print(\"F1 Score: \",f1_score(y_train_kannada,train_pred))\n",
        "  train_accuracies.append(accuracy_score(y_train_kannada,train_pred))\n",
        "  train_precisions.append(precision_score(y_train_kannada,train_pred))\n",
        "  train_recalls.append(recall_score(y_train_kannada,train_pred))\n",
        "  train_f1s.append(f1_score(y_train_kannada,train_pred))\n",
        "\n",
        "  print(\"*******Test************\")\n",
        "  print(\"Accuracy: \",accuracy_score(y_test_kannada,test_pred))\n",
        "  print(\"Precision: \",precision_score(y_test_kannada,test_pred))\n",
        "  print(\"Recall: \",recall_score(y_test_kannada,test_pred))\n",
        "  print(\"F1 Score: \",f1_score(y_test_kannada,test_pred))\n",
        "  test_accuracies.append(accuracy_score(y_test_kannada,test_pred))\n",
        "  test_precisions.append(precision_score(y_test_kannada,test_pred))\n",
        "  test_recalls.append(recall_score(y_test_kannada,test_pred))\n",
        "  test_f1s.append(f1_score(y_test_kannada,test_pred))\n",
        "  print(\"\\n \\n\")\n",
        "train_df = pd.DataFrame()\n",
        "train_df['Accuracy'] =  train_accuracies\n",
        "train_df['Precision'] =  train_precisions\n",
        "train_df['Recall'] =  train_recalls\n",
        "train_df['F1 Score'] =  train_f1s\n",
        "train_df['Mechanism'] = \"Train\"\n",
        "train_df['Model'] = ['Logistic Regression','KNN','DT']\n",
        "\n",
        "test_df = pd.DataFrame()\n",
        "test_df['Accuracy'] =  test_accuracies\n",
        "test_df['Precision'] =  test_precisions\n",
        "test_df['Recall'] =  test_recalls\n",
        "test_df['F1 Score'] =  test_f1s\n",
        "test_df['Mechanism'] = \"Test\"\n",
        "test_df['Model'] = ['Logistic Regression','KNN','DT']\n",
        "\n",
        "result_df = pd.concat([train_df, test_df])\n",
        "for metric in ['Accuracy','Precision','Recall','F1 Score']:\n",
        "  sns.lineplot(data =result_df,x ='Model',y = metric,hue=\"Mechanism\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsDGO2bYKMoP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUNwy3RELczh"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Specify the number of components you want to retain\n",
        "n_components = 10  # Adjust this based on your specific needs\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Fit and transform the data\n",
        "pca_train_result = pca.fit_transform(train[pixel_columns])\n",
        "pca_test_result = pca.fit_transform(test[pixel_columns])\n",
        "\n",
        "# Create a DataFrame with the PCA results\n",
        "pca_train_kannada = pd.DataFrame(data=pca_train_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "pca_test_df = pd.DataFrame(data=pca_test_result, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
        "# # Combine the label column with the PCA results if needed\n",
        "# pca_df['label'] = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWhlSjJLMAZD"
      },
      "outputs": [],
      "source": [
        "y_train_kannada=pca_train_kannada['PC1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CogfkL36Ojaa"
      },
      "outputs": [],
      "source": [
        "y_test_kannada=pca_test_df['PC1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUUTGXyOvP7j",
        "outputId": "91b48c97-0b0f-48ac-9ee9-393f50b826ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        -4.287227\n",
              "1        -2.037585\n",
              "2         1.819231\n",
              "3         2.814400\n",
              "4         0.963072\n",
              "           ...    \n",
              "59995     0.536844\n",
              "59996     5.498089\n",
              "59997    11.020907\n",
              "59998    -9.187966\n",
              "59999    -9.774109\n",
              "Name: PC1, Length: 60000, dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "01r1JGrSfmnB",
        "outputId": "142ff24a-75eb-47a0-fb0e-b628f3594cf1"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-590794e2f123>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_f1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_train_kannada\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_kannada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_train_kannada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_test_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         )\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     ]:\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "pca_train_kannada,pca_test_df,y_train_kannada,y_test_kannada = train_test_split(pca_train_kannada,y_train_kannada,test_size=0.2,random_state=42)\n",
        "models = [LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
        "train_accuracies = []\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "train_f1s = []\n",
        "test_accuracies = []\n",
        "test_precisions = []\n",
        "test_recalls = []\n",
        "test_f1s = []\n",
        "for model in models:\n",
        "  model.fit(pca_train_kannada,y_train_kannada)\n",
        "  train_pred = model.predict(pca_train_kannada)\n",
        "  test_pred = model.predict(pca_test_df)\n",
        "  print(type(model).__name__)\n",
        "  print(\"*******Train************\")\n",
        "  print(\"Accuracy: \",accuracy_score(y_train_kannada,train_pred))\n",
        "  print(\"Precision: \",precision_score(y_train_kannada,train_pred))\n",
        "  print(\"Recall: \",recall_score(y_train_kannada,train_pred))\n",
        "  print(\"F1 Score: \",f1_score(y_train_kannada,train_pred))\n",
        "  train_accuracies.append(accuracy_score(y_train_kannada,train_pred))\n",
        "  train_precisions.append(precision_score(y_train_kannada,train_pred))\n",
        "  train_recalls.append(recall_score(y_train_kannada,train_pred))\n",
        "  train_f1s.append(f1_score(y_train_kannada,train_pred))\n",
        "\n",
        "  print(\"*******Test************\")\n",
        "  print(\"Accuracy: \",accuracy_score(y_test_kannada,test_pred))\n",
        "  print(\"Precision: \",precision_score(y_test_kannada,test_pred))\n",
        "  print(\"Recall: \",recall_score(y_test_kannada,test_pred))\n",
        "  print(\"F1 Score: \",f1_score(y_test_kannada,test_pred))\n",
        "  test_accuracies.append(accuracy_score(y_test_kannada,test_pred))\n",
        "  test_precisions.append(precision_score(y_test_kannada,test_pred))\n",
        "  test_recalls.append(recall_score(y_test_kannada,test_pred))\n",
        "  test_f1s.append(f1_score(y_test_kannada,test_pred))\n",
        "  print(\"\\n \\n\")\n",
        "train_df = pd.DataFrame()\n",
        "train_df['Accuracy'] =  train_accuracies\n",
        "train_df['Precision'] =  train_precisions\n",
        "train_df['Recall'] =  train_recalls\n",
        "train_df['F1 Score'] =  train_f1s\n",
        "train_df['Mechanism'] = \"Train\"\n",
        "train_df['Model'] = ['Logistic Regression','KNN','DT']\n",
        "\n",
        "test_df = pd.DataFrame()\n",
        "test_df['Accuracy'] =  test_accuracies\n",
        "test_df['Precision'] =  test_precisions\n",
        "test_df['Recall'] =  test_recalls\n",
        "test_df['F1 Score'] =  test_f1s\n",
        "test_df['Mechanism'] = \"Test\"\n",
        "test_df['Model'] = ['Logistic Regression','KNN','DT']\n",
        "\n",
        "result_df = pd.concat([train_df, test_df])\n",
        "for metric in ['Accuracy','Precision','Recall','F1 Score']:\n",
        "  sns.lineplot(data =result_df,x ='Model',y = metric,hue=\"Mechanism\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp28zMl6dWBS"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a function for evaluating a classifier\n",
        "def evaluate_classifier(classifier, X_train, y_train, X_test, y_test):\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Compute ROC curve and ROC-AUC score for binary classification (assuming 2 classes)\n",
        "    if len(np.unique(y_train)) == 2:\n",
        "        y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show()\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Classifier: {classifier.__class__.__name__}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1-Score: {f1:.2f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print()\n",
        "\n",
        "# Define the classifiers to be used\n",
        "classifiers = [\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    GaussianNB(),\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(probability=True, random_state=42)\n",
        "]\n",
        "\n",
        "# Assuming you have your training and testing labels as y_train and y_test\n",
        "for classifier in classifiers:\n",
        "    evaluate_classifier(classifier, pca_train_df, y_train, pca_test_df, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "c-w-TomZVegn",
        "outputId": "64a70a30-f37a-4f67-cb35-303c21e69d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Component Size: 10\n",
            "Classifier: Decision Tree\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n",
            "Confusion Matrix:\n",
            "[[12000]]\n",
            "\n",
            "Component Size: 10\n",
            "Classifier: Random Forest\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n",
            "Confusion Matrix:\n",
            "[[12000]]\n",
            "\n",
            "Component Size: 10\n",
            "Classifier: Naive Bayes\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n",
            "Confusion Matrix:\n",
            "[[12000]]\n",
            "\n",
            "Component Size: 10\n",
            "Classifier: K-NN\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n",
            "Confusion Matrix:\n",
            "[[12000]]\n",
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0a2d4f9141cf>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclassifier_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         sample_weight = np.asarray(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    750\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your image dataset (assuming it's a CSV file with pixels and labels)\n",
        "# data = pd.read_csv('your_image_data.csv')\n",
        "\n",
        "# Separate the features (pixels) and labels\n",
        "X = train.iloc[:, :-1]  # Features (pixels)\n",
        "y = train.iloc[:, -1]  # Labels\n",
        "\n",
        "# Initialize component sizes to experiment with\n",
        "component_sizes = [10, 15, 20, 25, 30]\n",
        "\n",
        "for n_components in component_sizes:\n",
        "    # Perform PCA to reduce dimensions\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train various classifiers\n",
        "    classifiers = {\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "        \"Naive Bayes\": GaussianNB(),\n",
        "        \"K-NN\": KNeighborsClassifier(),\n",
        "        \"SVM\": SVC(probability=True, random_state=42)\n",
        "    }\n",
        "\n",
        "    for classifier_name, classifier in classifiers.items():\n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Compute ROC curve and ROC-AUC score for binary classification (assuming 2 classes)\n",
        "        if len(np.unique(y)) == 2:\n",
        "            le = LabelEncoder()\n",
        "            y_test_encoded = le.fit_transform(y_test)\n",
        "            y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
        "            fpr, tpr, _ = roc_curve(y_test_encoded, y_pred_proba)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "\n",
        "            # Plot ROC curve\n",
        "            plt.figure()\n",
        "            plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "            plt.xlim([0.0, 1.0])\n",
        "            plt.ylim([0.0, 1.05])\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('Receiver Operating Characteristic')\n",
        "            plt.legend(loc='lower right')\n",
        "            plt.show()\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Component Size: {n_components}\")\n",
        "        print(f\"Classifier: {classifier_name}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-Score: {f1:.2f}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "mhLFzYVhaXLu",
        "outputId": "cb1852ee-3030-4a5a-979e-7277475da09f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-faae8d268756>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "# Separate the features (pixels) and labels\n",
        "X = train.iloc[:, :-1]  # Features (pixels)\n",
        "y = train.iloc[:, -1]  # Labels\n",
        "# create a validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "train_pred = model.predict(x_train)\n",
        "test_pred = model.predict(x_test)\n",
        "print(\"******Train************\")\n",
        "print(\"Accuracy: \",accuracy_score(y_train,train_pred))\n",
        "print(\"Precision: \",precision_score(y_train,train_pred))\n",
        "print(\"Recall: \", recall_score(y_train,train_pred))\n",
        "print(\"F1 score: \",f1_score(y_train,train_pred))\n",
        "print(\"******Test************\")\n",
        "print(\"Accuracy: \",accuracy_score(y_test,test_pred))\n",
        "print(\"Precision: \",precision_score(y_test,test_pred))\n",
        "print(\"Recall: \", recall_score(y_test,test_pred))\n",
        "print(\"F1 score: \",f1_score(y_test,test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "19Oe3SiCVc8I",
        "outputId": "898a3e06-b439-43d3-d418-ead8e6b892e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Decision Trees:\n",
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bbe7a673cd27>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Evaluate each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decision Trees\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Naive Bayes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bbe7a673cd27>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_name, predictions)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Classification Report for {model_name}:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Confusion Matrix for {model_name}:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [12000, 54000]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define your target labels (assuming they are stored in 'y_train' and 'y_test')\n",
        "# Separate the features (pixels) and labels\n",
        "X = train.iloc[:, :-1]  # Features (pixels)\n",
        "y = train.iloc[:, -1]  # Labels\n",
        "# create a validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(x_train, y_train)\n",
        "dt_predictions = dt_classifier.predict(x_train)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(x_train, y_train)\n",
        "rf_predictions = rf_classifier.predict(x_train)\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(x_train, y_train)\n",
        "nb_predictions = nb_classifier.predict(x_train)\n",
        "\n",
        "# K-Nearest Neighbors Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(x_train, y_train)\n",
        "knn_predictions = knn_classifier.predict(x_train)\n",
        "\n",
        "# # Support Vector Machine Classifier\n",
        "# svm_classifier = SVC(probability=True)  # probability=True to compute ROC-AUC later\n",
        "# svm_classifier.fit(x_train, y_train)\n",
        "# svm_predictions = svm_classifier.predict(x_train)\n",
        "\n",
        "# Model Evaluation\n",
        "def evaluate_model(model_name, predictions):\n",
        "    print(f\"Classification Report for {model_name}:\\n\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "    print(f\"Confusion Matrix for {model_name}:\\n\")\n",
        "    print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "    # # ROC-AUC Score\n",
        "    # if model_name == \"Support Vector Machine\":\n",
        "    #     y_prob = svm_classifier.predict_proba(pca_test_df)\n",
        "    #     auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "    # else:\n",
        "    # auc_score = roc_auc_score(y_test, predictions, multi_class='ovr')\n",
        "\n",
        "    # print(f\"ROC-AUC Score for {model_name}: {auc_score}\\n\")\n",
        "\n",
        "    # ROC Curve (for binary classification or one-vs-rest in multiclass)\n",
        "    if len(y_test.unique()) == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
        "        # Plot ROC curve if needed\n",
        "\n",
        "# Evaluate each model\n",
        "evaluate_model(\"Decision Trees\", dt_predictions)\n",
        "evaluate_model(\"Random Forest\", rf_predictions)\n",
        "evaluate_model(\"Naive Bayes\", nb_predictions)\n",
        "evaluate_model(\"K-Nearest Neighbors\", knn_predictions)\n",
        "# evaluate_model(\"Support Vector Machine\", svm_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c69JagX5UkQS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load your PCA-transformed data (assuming it's in a DataFrame called 'data')\n",
        "# You should also load the labels (target) if they are not included in the 'data' DataFrame\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "dt_predictions = dt_classifier.predict(X_test)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "rf_predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "nb_predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "# K-Nearest Neighbors Classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "knn_predictions = knn_classifier.predict(X_test)\n",
        "\n",
        "# Support Vector Machine Classifier\n",
        "svm_classifier = SVC(probability=True)  # probability=True to compute ROC-AUC later\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "def evaluate_model(model_name, predictions):\n",
        "    print(f\"Classification Report for {model_name}:\\n\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "    print(f\"Confusion Matrix for {model_name}:\\n\")\n",
        "    print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "    # ROC-AUC Score\n",
        "    if model_name == \"Support Vector Machine\":\n",
        "        y_prob = svm_classifier.predict_proba(X_test)\n",
        "        auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "    else:\n",
        "        auc_score = roc_auc_score(y_test, predictions, multi_class='ovr')\n",
        "\n",
        "    print(f\"ROC-AUC Score for {model_name}: {auc_score}\\n\")\n",
        "\n",
        "    # ROC Curve (for binary classification or one-vs-rest in multiclass)\n",
        "    if len(y_test.unique()) == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])\n",
        "        # Plot ROC curve if needed\n",
        "\n",
        "# Evaluate each model\n",
        "evaluate_model(\"Decision Trees\", dt_predictions)\n",
        "evaluate_model(\"Random Forest\", rf_predictions)\n",
        "evaluate_model(\"Naive Bayes\", nb_predictions)\n",
        "evaluate_model(\"K-Nearest Neighbors\", knn_predictions)\n",
        "evaluate_model(\"Support Vector Machine\", svm_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EtqrBNaStXr"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the models\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "random_forest = RandomForestClassifier()\n",
        "naive_bayes = GaussianNB()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "svm_classifier = SVC()\n",
        "\n",
        "# Fit the models\n",
        "decision_tree.fit(X_train_pca, y_train)\n",
        "random_forest.fit(X_train_pca, y_train)\n",
        "naive_bayes.fit(X_train_pca, y_train)\n",
        "knn_classifier.fit(X_train_pca, y_train)\n",
        "svm_classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Evaluate the models\n",
        "decision_tree_score = decision_tree.score(X_test_pca, y_test)\n",
        "random_forest_score = random_forest.score(X_test_pca, y_test)\n",
        "naive_bayes_score = naive_bayes.score(X_test_pca, y_test)\n",
        "knn_classifier_score = knn_classifier.score(X_test_pca, y_test)\n",
        "svm_classifier_score = svm_classifier.score(X_test_pca, y_test)\n",
        "\n",
        "# Display the results\n",
        "print(\"Decision Tree Accuracy:\", decision_tree_score)\n",
        "print(\"Random Forest Accuracy:\", random_forest_score)\n",
        "print(\"Naive Bayes Accuracy:\", naive_bayes_score)\n",
        "print(\"K-NN Classifier Accuracy:\", knn_classifier_score)\n",
        "print(\"SVM Classifier Accuracy:\", svm_classifier_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tox8qAIIuH-H",
        "outputId": "531edc2b-7d72-45da-86bb-9fa7df335d59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<numpy.lib.npyio.NpzFile at 0x7921124aefb0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with your dataset file)\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# Define categorical and numerical columns (customize this based on your dataset)\n",
        "categorical_cols = ['categorical_feature1', 'categorical_feature2']\n",
        "numerical_cols = ['numerical_feature1', 'numerical_feature2']\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values with mean imputation\n",
        "    ('scaler', StandardScaler())  # Standardize numerical features\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values with mode imputation\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Define the machine learning model you want to use (e.g., RandomForestClassifier)\n",
        "# model = RandomForestClassifier()\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "# clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "#                       ('model', model)])\n",
        "\n",
        "# Split data into train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing of training data, fit model\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "# preds = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "\n",
        "# You can uncomment and customize the remaining code based on your specific needs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeJ6xzOYtBzT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuUJXOSGaCUO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Us5eX9aB_Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbWyuBsCtGME"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F_7FiBvf_PMZXcXhxVf1ET4xEgJ61PrU",
      "authorship_tag": "ABX9TyOhkTaPCks6LxLveyWbEK0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}